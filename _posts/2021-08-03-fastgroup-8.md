---
title: Log8- Learning FastBook along with Study Group
type: post
published: True
tags: [fastbook, myself, ML, Deep learning]
readtime: true
cover-img: "/img/fastgroup-share.jpg"
share-img: "/img/fastgroup-share.jpg"
---

So, let's start another week of learning logs from week8.

## Difference between cross-entropy and binary cross-entropy?

- In this chapter we learn that difference between various loss functions can lead to different utility functions as a whole.
- The question of loss function, which is used to optimise our model is very critical
- We can't use Cross Entropy loss for multi-label image classification, why according to book:

![image](https://user-images.githubusercontent.com/24592806/127781469-28d1eb35-f899-4579-9495-cd62e3a0917e.png)

If you forgot, what is cross entropy loss I highly recommend to check [Ravi Mishra's blogpost on Understanding Cross Entropy](https://ravimashru.dev/blog/2021-07-18-understanding-cross-entropy-loss/)

- Cross Entropy can also be explained using Excel as shown in [Jeremy lesson](https://www.youtube.com/watch?v=CJKnDu2dxOE&t=7482s)

Let me just breifly summarise, what jeremy said. Using Excel, for a Cat, we have the true labels whether it's a cat or not. Also 
our ML model after training predicts. Based on these difference, when predicting the correct thing very confidently we are giving our model
a low loss value, while predicting the correct thing wrong should be penalised with a high loss value.

![image](https://user-images.githubusercontent.com/24592806/128454662-831c4066-95a4-4422-b2dd-3233732a2b8a.png)

So cross entropy loss is basically whether it is a cat multiplied by log of cat activation + whether it's a dog * (log of dog activation)

If it's a cat, take log of catiness, else it it's a dog, take log of doginess ie 1 - log of catiness. All this works if it's adding upto 1 only, the probability
predictions.

The correct activation function to use is softmax, all of activations add upto 1. All activations are greater than 0 as well

e power/ (sum of e numbers)

- In Pytorch, softmax + cross entropy loss is nn.crossEntropy

https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html

![image](https://user-images.githubusercontent.com/24592806/127782856-66b72af4-57a9-45fa-b0ed-7487997b4b5a.png)

- The fundamental thing is loss needs to keep increasing, if it's a simple sigmoid + log + nll. The error is not increasing
- The error is increasing only when it's BCE loss

- Note: Use the multi-label classification approach in your "multiclassification problems" where you want your model to be able to result in None (which is probably a more common real world use case) 

- In the book Jeremy Howards, have described the loss used in binary cross entropy, as using a sigmoid and then calculating the prediction similar to MNIST loss
which we used in chapter 4.

```
def binary_cross_entropy(inputs, targets):
  inputs = inputs.sigmoid()
  return - torch.where(targets==1, inputs,  1- inputs).log().mean()
```

> Try to explain it to other as simple as possible



## Then regression problem

Let's look more about the dataset used in this regression problem that is [BIWI Kinect Head Pose Dtaset](https://icu.ee.ethz.ch/research/datsets.html).
In the readme of dataset more details about dataset is mentioned:

```
The database contains 24 sequences acquired with a Kinect sensor. 20 people (some were recorded twice - 6 women and 14 men)
were recorded while turning their heads, sitting in front of the sensor, at roughly one meter of distance.

For each sequence, the corresponding .obj file represents a head template deformed to match the neutral face of that specific person.
In each folder, two .cal files contain calibration information for the depth and the color camera, e.g., the intrinsic camera matrix
of the depth camera and the global rotation and translation to the rgb camera.

For each frame, a _rgb.png and a _depth.bin files are provided, containing color and depth data. The depth (in mm) is already
segmented (the background is removed using a threshold on the distance) and the binary files compressed (an example c code is
provided to show how to read the depth data into memory). The _pose.txt files contain the ground truth information, i.e., the
location of the center of the head in 3D and the head rotation, encoded as a 3x3 rotation matrix.
```

- How is the dataset being loaded?

- Look at numpy problems

- The fundamental difference is MSE loss (Mean squared loss)

### Questions to myself when writing?

1. What is difference b/w softmax and sigmoid?
2. What is get_image_files?


```
def get_image_files(path, recurse=True, folders=None):
    "Get image files in `path` recursively, only in `folders`, if specified."
    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)
```
   
```
def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):
    "Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified."
    path = Path(path)
    folders=L(folders)
    extensions = setify(extensions)
    extensions = {e.lower() for e in extensions}
    if recurse:
        res = []
        for i,(p,d,f) in enumerate(os.walk(path, followlinks=followlinks)): # returns (dirpath, dirnames, filenames)
            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]
            else:                         d[:] = [o for o in d if not o.startswith('.')]
            if len(folders) !=0 and i==0 and '.' not in folders: continue
            res += _get_files(p, f, extensions)
    else:
        f = [o.name for o in os.scandir(path) if o.is_file()]
        res = _get_files(path, f, extensions)
    return L(res)
```

In this get_files, we are passing image_extensions which is defined as following:

```
import mimetypes

image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))
```

![image](https://user-images.githubusercontent.com/24592806/128119066-1a898e9f-1fd8-4e90-9cb4-25b5591af430.png)


For the BIWI Dataset, the output of `get_image_files` and `get_files` is as following:

![image](https://user-images.githubusercontent.com/24592806/128119162-41abebab-dda4-4d8b-b781-2d81d501b8aa.png)



