---
title: Log8- Learning FastBook along with Study Group
type: post
published: True
tags: [fastbook, myself, ML, Deep learning]
readtime: true
cover-img: "/img/fastgroup-share.jpg"
share-img: "/img/fastgroup-share.jpg"
---

So, let's start another week of learning logs from week8.

## Difference between cross-entropy and binary cross-entropy?

- In this chapter we learn that difference between various loss functions can lead to different utility functions as a whole.
- The question of loss function, which is used to optimise our model is very critical
- We can't use Cross Entropy loss, why according to book:

![image](https://user-images.githubusercontent.com/24592806/127781469-28d1eb35-f899-4579-9495-cd62e3a0917e.png)

If you forgot, what is cross entropy loss I highly recommend to check [Ravi Mishra's blogpost on Understanding Cross Entropy](https://ravimashru.dev/blog/2021-07-18-understanding-cross-entropy-loss/)

![image](https://user-images.githubusercontent.com/24592806/127782856-66b72af4-57a9-45fa-b0ed-7487997b4b5a.png)

- The fundamental thing is loss needs to keep increasing, if it's a simple sigmoid + log + nll. The error is not increasing
- The error is increasing only when it's BCE loss

- Note: Use the multi-label classification approach in your "multiclassification problems" where you want your model to be able to result in None (which is probably a more common real world use case) 

- In the book Jeremy Howards, have described the loss used in binary cross entropy, as using a sigmoid and then calculating the prediction similar to MNIST loss
which we used in chapter 4.

```
def binary_cross_entropy(inputs, targets):
  inputs = inputs.sigmoid()
  return - torch.where(targets==1, inputs,  1- inputs).log().mean()
```

> Try to explain it to other as simple as possible



## Then regression problem

Let's look more about the dataset used in this regression problem that is BIWI Kinect Head Pose Dtaset. In the readme of dataset
more details about dataset is mentioned:

```
The database contains 24 sequences acquired with a Kinect sensor. 20 people (some were recorded twice - 6 women and 14 men)
were recorded while turning their heads, sitting in front of the sensor, at roughly one meter of distance.

For each sequence, the corresponding .obj file represents a head template deformed to match the neutral face of that specific person.
In each folder, two .cal files contain calibration information for the depth and the color camera, e.g., the intrinsic camera matrix
of the depth camera and the global rotation and translation to the rgb camera.

For each frame, a _rgb.png and a _depth.bin files are provided, containing color and depth data. The depth (in mm) is already
segmented (the background is removed using a threshold on the distance) and the binary files compressed (an example c code is
provided to show how to read the depth data into memory). The _pose.txt files contain the ground truth information, i.e., the
location of the center of the head in 3D and the head rotation, encoded as a 3x3 rotation matrix.
```

- How is the dataset being loaded?

- Look at numpy problems

- The fundamental difference is MSE loss (Mean squared loss)

### Questions to myself when writing?

1. What is difference b/w softmax and sigmoid?
