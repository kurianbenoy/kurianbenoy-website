---
aliases:
- /2020/01/08/Aws-Reinvent_recap
author: Kurian Benoy
date: '2020-01-08'
layout: post
title: Attending an Aws meetup

---

I recently attended AWS re: Invent reCap organised by AWS User Group Kochi. One of the exciting announcements during the program was about AWS Inferentia chips which is being developed by Annapurna Labs(which unlike it's name is an Israel based company).


For more and more machine learning models now high performance and low bandwidth is a necessary requirement. With the support of having neural cores, support for INT8, BF16 datatypes it's able to lower the computation cost needed for deploying these models. Almost 90% of ML compute resources is used for interference, with this new chip and release of Amazon EC2 Inf1 instances. Using EC2 Inf1 instances you can have the fastest and lowest inferencing for all ML models in Applications like Speech recognition, Image processing, object detection etc.


Right Amazon EC2 Inf1 is used by Alexa team to considerably reduce their computation for answering all kinds of voice queries which was earlier used by GPU systems.

I recently attended AWS re:Invent reCap session by Suman Debnath at AWS User Group Kochi. One of the exciting announcements during the program was about AWS Inferentia chips which is being developed by Annapurna Labs(an Israel based company).


For more and more machine learning applications now high performance and low bandwidth is a necessary hardware requirement. Inferentia chips with neural cores, support for INT8, BF16 datatypes is able to lower the computation cost needed for deploying these models(which are used inference). Almost 90% of ML compute resources is used for interference(that is squeezing the result for your input from ML model already build). Amazon EC2 Inf1 instances which leverage the power AWS Inferentia chips you can have the fastest and lowest inferencing for all  Applications like Speech recognition, Image processing, object detection etc.


Right now Amazon EC2 Inf1 is already being used by Alexa team to considerably reduce their computation for answering all kinds of voice queries which was earlier using GPU powered systems.


#machinelearning #aws #datascience #reinvent2019

Got some AWS goodies and got connected with AWS speaker Sumanth Debnath
