---
aliases:
- /2021/07/28/fastgroup-7
categories:
- fastbook
- myself
- ML
- Deep learning
cover-img: /img/pexels-fauxels-3184418720.jpg
date: '2021-07-28'
layout: post
published: true
readtime: true
share-img: /img/pexels-fauxels-3184418720.jpg
title: Log7- Learning FastBook along with Study Group

---

![](/posts/images/pexels-fauxels-3184418720.jpg)

In week 7, we covered the second half of lesson 5 and started with lesson 6 on Other Computer Vision problems like Multi-Label classification.
We have covered so far almost 25% of the FastBook aka. Deep Learning for Coders.

Last week, I wrote about what is covered in rest of lesson 5. Some of the new things which Aman introduced was:

- The valley function in fastai, which is available in latest version to get the exact learning rate to be passed.

![image](https://user-images.githubusercontent.com/24592806/127098208-2834b83f-6245-41f6-b1f0-2a64f27c24a3.png)


- More scheduling algorithms were mentioned like Torch optimizers.

- I tried working on these applying techniques in a different dataset consisting of images of various painters in [Kaggle](https://www.kaggle.com/c/dsnet-kaggledays-hackathon).
The notebook used for [training can be found here](https://www.kaggle.com/kurianbenoy/fastai-classifying-artists-image):

The chapter 6 consists of discussion other Computer Vision problems like Multi-label classification, Regression. During the session we
covered more about loading dataset for multi-label classification.

We used PASCAL 2007 dataset for this task, which is consisting of images and tabular data with the labels, filename and whether it's part of validation datset.

![image](https://user-images.githubusercontent.com/24592806/127386125-c9f4cee4-21c8-44e5-b25f-49dbe630c014.png)

Aman during the lesson explained the difference between lambda functions and normal funcitons with a simple example. To check out more
about [lambda functions checkout this article from RealPython](https://realpython.com/python-lambda/).

![image](https://user-images.githubusercontent.com/24592806/127386558-1e469f3a-4208-4b8a-bb51-b8803654be19.png)

- Next we can create a Datablock, based on the input dataset. With training file path as independendent variable, and labelled list as dependent variable.

When looking into Pytorch and fast.ai, there are two classes for representing datasets:

1. Datasets - a collection that returns a tuple of independent and dependent variables for a single item. In fastai it returns
an iterator for bringing your training and validation dataset.

2. DataLoaders - a iterator which provides stream of mini-batches where each mini-batches is a couple of batch of independent variables and dependent variables.

![image](https://user-images.githubusercontent.com/24592806/127388520-3af22116-08ea-416e-bbdc-04dd75532a89.png)

This week I tried more about learning Pytorch Datasets and Dataloaders [based on this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). 
The details can be found in week 6 training notebook.


We used a Mulicategory block this time and used one hot encoding technique to identify where is the correct category for each labelled image.
Using a splitter for training and validation splitting, the dataset was finally loaded as follows:

![image](https://user-images.githubusercontent.com/24592806/127388600-ac2004f0-8a8d-4060-a88d-fc06017eb8fb.png)

The full notebook of [week 6 can be found here](https://gist.github.com/kurianbenoy/7aed9bc9858772d843dfdbaed410255b)

The full session recording can be viewed in the below link and thanks for reading üôè.

[![IMAGE ALT TEXT](http://img.youtube.com/vi/NI109pZgXPU/0.jpg)](https://youtu.be/NI109pZgXPU "Session Recordings of Week 7")

### Interesting Article Links

- [Nitron Open-Source GPU Programming for Neural Networks](https://www.openai.com/blog/triton/)
- [Methods for automating lr finders](https://www.novetta.com/2021/03/learning-rate/)
