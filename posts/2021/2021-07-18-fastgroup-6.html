<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-07-18">

<title>Kurian Benoy - Log6- Learning FastBook along with Study Group</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Kurian Benoy</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../talks.html">
 <span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://til.kurianbenoy.com/">
 <span class="menu-text">TIL</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/kurianbenoy"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/kurianbenoy2"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kurianbenoy"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../blog.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Log6- Learning FastBook along with Study Group</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">fastbook</div>
                <div class="quarto-category">myself</div>
                <div class="quarto-category">ML</div>
                <div class="quarto-category">Deep learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 18, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p><img src="../../posts/images/fastgroup-share.jpg" class="img-fluid"></p>
<p>So as always, let‚Äôs start with a quick recap of what was covered during the session:</p>
<blockquote class="blockquote">
<p>TLDR: Covered Chapter 5 of Deep Learning for Coders book, includes secret recipes to build a great ML model.</p>
</blockquote>
<ul>
<li>We started with PETs dataset. This time we were classifying Breed of Cat/Dog using fastai image classifier.</li>
<li>The dataset followed a particular heuristics, which represented Species with the capital case as Cats and smaller case as Dogs. For the breeds also a similar pattern is there:</li>
</ul>
<p><code>Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_157.jpg')</code> - The breed can be obtained using the regex patterns. It‚Äôs recommended to read a regex tutorial and solve it with a regex problem set. <code>re.findall(r''(.+)_\d+.jpg)</code> - Most functions and methods in fastai return a special collection class called L(part of fastai core library) - Datablock used for loading pets breed classifier</p>
<pre><code>pets = DataBlock(blocks=(ImageBlock, CategoryBlock),
                 get_items=get_image_files,
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),
                 batch_tfms=aug_transforms(size=224, min_scale=0.75)
)
dls = pets.dataloaders(path/"images")</code></pre>
<section id="what-is-presizing" class="level3">
<h3 class="anchored" data-anchor-id="what-is-presizing"><em>What is Presizing?</em></h3>
<ul>
<li>It‚Äôs a technique in which we transform input image into a larger size image, and then use augmentation techniques like Random cropping to get the full picture of what we are trying to classify.</li>
<li>Usually for transforming images to larger sizes like Resize operation we use a CPU(Central Processing Unit). Then process of augmentation techniques like cropping, RandomResizing is usually done with a GPU(Graphics process units) because it requires uniform size images.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126095655-33e269f0-2841-472c-aedc-39489bc34cf3.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ul>
<li>In practice, according to <a href="https://wandb.ai/aarora">Aman Arora</a> we spend a lot of time loading data correctly when working with a new dataset. This is where some errors come.</li>
<li>When errors come in our data block, use the <code>summary method in DataBlock</code></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126096059-a4570b1d-853a-44a4-b211-85e8924cdb70.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ul>
<li>Now when training our model, across a few epochs(doing a complete pass of data). The learn.fine_tune() method shows average loss over the training dataset and loss of validation set. What is this loss function used, is it the loss function we learned in chapter 4?</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126096364-f189e555-f125-400b-8648-890fb8e125f2.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ul>
<li>By default, fastai chooses the appropriate loss function based on Datablock type. Generally for an image dataset, with a categorical outcome we usually use <strong>cross-entropy loss</strong></li>
</ul>
</section>
<section id="what-is-cross-entropy-loss" class="level3">
<h3 class="anchored" data-anchor-id="what-is-cross-entropy-loss">What is Cross Entropy Loss?</h3>
<p>Let‚Äôs look it step by step. Let‚Äôs first view the <em>activations and labels of our data loader</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126096724-3220e5f0-27ba-458f-8980-fa7c72a55ccd.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ul>
<li>We can see our pets are converted into associated tensor values representing the category into 0-37 values in tensor.</li>
<li>The prediction probabilities sum all add up to 1</li>
</ul>
<p><em>What is Softmax function?</em></p>
<ul>
<li>When we were classifying 3s and 7s in MNIST dataset, it was a binary classification problem, with the target being a boolean value. We used the sigmoid function</li>
<li>Cross-Entropy loss is being used because of two benefits:</li>
</ul>
<ol type="1">
<li>It works when our dependant variables(like classifying pet breeds) with more than two categories</li>
<li>It results in a faster and reliable training</li>
</ol>
<ul>
<li>Now for classifying 3s and 7s, it is reliable for a set of random activations to be substracted with the difference of activation for three and seven. After calculating the sigmoid function of their difference.</li>
</ul>
<p><code>(acts[:, 0] - acts[:, 1]).sigmoid()</code></p>
<ul>
<li>The softmax function is represented in the formula as below. Obviously there is a PyTorch function for it</li>
</ul>
<pre><code>def softmax(x):
  return (exp(x) /exp(x).sum(dim=1, keepdim=True))</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126097349-af9247e6-5461-4562-99c6-c2191783853d.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p><em>What is log-likelihood loss</em></p>
<ul>
<li>We need to calculate the loss for each no like mnist_loss(target=1, 1-inputs). Yet for multiple categories, we need a better method</li>
<li>For this, we use the log-likelihood loss method. When considering things in log scale, a 99.99% and 99.9% is usually 10 times larger, even though in absolute terms it seems small.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126097580-613dcdaa-6628-4b69-8c9b-b08163b01078.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p><em>Combining</em></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126097634-9f150ecf-b77b-4a60-af68-0fdfc0382fe7.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ul>
<li>Softmax + Negative Log Likelihood = Cross Entropy Loss</li>
<li>Most of the time, we calculate with torch methods like <code>nn.CrossEntropyLoss(reduction='none')(acts, targ)</code>.</li>
</ul>
</section>
<section id="model-interpretation-result" class="level3">
<h3 class="anchored" data-anchor-id="model-interpretation-result">Model Interpretation result</h3>
<ul>
<li>The wrong results, and where our model has been wrong can‚Äôt be often spotted merely with help of metrics like accuracy.</li>
<li>So we use a confusion matrix and plot the function with top losses.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126098073-5a3a8e9f-5a79-4d9e-a4ca-52bcb24d0adb.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
</section>
<section id="learning-rate-finder-and-freezing-pre-trained-layers" class="level3">
<h3 class="anchored" data-anchor-id="learning-rate-finder-and-freezing-pre-trained-layers">Learning rate finder and freezing pre-trained layers</h3>
<ul>
<li>Using a learning rate finder developed by <a href="https://arxiv.org/abs/1803.09820">Leslie Smith</a>, we can find the minimum step and maximum steep point of learning rate</li>
<li>To find the appropriate learning rate, using at some point of the middle of lr_rate_finder() is a food idea. But always remember to use logarithmic scale even here to calculate learning rate finder</li>
<li>When we are using models with transfer learning, they are not trained for the specific model which we are trying to classify.</li>
<li>For this, we freeze the last layers and train again</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126098417-536b1069-a3df-468d-8859-cbf42ebd7317.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ul>
<li>Fastai <code>fine_tune</code> method under the hood:</li>
</ul>
<ol type="1">
<li>Trains randomly for added layers initially for certain epochs</li>
<li>Unfreeze all the layers, then train again</li>
</ol>
</section>
<section id="discriminative-learning-rate-and-rest-of-portions" class="level3">
<h3 class="anchored" data-anchor-id="discriminative-learning-rate-and-rest-of-portions">Discriminative learning rate, and rest of portions</h3>
<ul>
<li>First, train the model with a slow learning rate, and then later train faster. This is the fundamental premise</li>
<li>Early stopping is a not good method as mentioned in the book below</li>
</ul>
<blockquote class="blockquote">
<p>Before the days of 1cycle training it was very common to save the model at the end of each epoch, and then select whichever model had the best accuracy out of all of the models saved in each epoch. This is known as <em>early stopping</em>. However, this is very unlikely to give you the best answer, because those epochs in the middle occur before the learning rate has had a chance to reach the small values, where it can really find the best result. Therefore, if you find that you have overfitted, what you should do is retrain your model from scratch, and this time select a total number of epochs based on where your previous best results were found.</p>
</blockquote>
<ul>
<li>Using lr_max, with slice method to train the last layers with a faster speed</li>
<li>We can improve models with deeper architecture like Resnet 34, 50, 101, 152 etc. There are new techniques now like EfficentNet, Transformers, which can give a better accuracy now.</li>
<li>Then it‚Äôs a good idea to train with half-precision floating points, which speeds up the training process considerably</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126098914-56e1d5de-359c-479e-8344-8333f32e6c79.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://youtu.be/bvtr_1TN6MI" title="Session Recordings of Week 6"><img src="http://img.youtube.com/vi/bvtr_1TN6MI/0.jpg" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">IMAGE ALT TEXT</figcaption><p></p>
</figure>
</div>
<p>Also at the end of the session, <a href="https://github.com/amaarora"><span class="citation" data-cites="Aman">@Aman</span> Arora</a> shared four blog post ideas:</p>
<ol type="1">
<li>Write about what <code>untar_data</code> method is doing under the hood?</li>
<li>Write about what is <code>fastai foundation class L</code> is doing. What are the unique features of this special list part of fastai core library?</li>
<li>Write about <code>regex</code> which is a pretty useful library, and write on what all the cool things you can do with it.</li>
<li>Write about <code>cross_entropy_loss</code> .</li>
</ol>
<p>My work logs, trying out things mentioned in Chapter 5 can be found <a href="https://www.kaggle.com/kurianbenoy/fastbook-ch5/">in this Kaggle notebook</a>.</p>
<p>I also got a chance to try out the fastai tool for graphic visualisation <code>fastdott</code>, which is pretty cool.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/24592806/126546857-c784e73d-f67c-4013-ad51-ebfe4ae03c6b.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p>Thanks everyone for reading üôè</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
I have been attending FastBook reading group sessions hosted by wonderful <a href="https://twitter.com/amaarora?ref_src=twsrc%5Etfw"><span class="citation" data-cites="amaarora">@amaarora</span></a> and <a href="https://twitter.com/weights_biases?ref_src=twsrc%5Etfw"><span class="citation" data-cites="weights_biases">@weights_biases</span></a> team. This week we dived into some fastai techniques to improving accuracy and dived deep into cross entropy loss.<a href="https://t.co/ElnfdAoqNE">https://t.co/ElnfdAoqNE</a>
</p>
‚Äî Kurian Benoy (<span class="citation" data-cites="kurianbenoy2">@kurianbenoy2</span>) <a href="https://twitter.com/kurianbenoy2/status/1417928171870064641?ref_src=twsrc%5Etfw">July 21, 2021</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>