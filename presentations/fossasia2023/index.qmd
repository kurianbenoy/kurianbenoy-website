---
title: OpenAI Whisper and it's amazing power to do finetuning.
author: Kurian Benoy
subtitle: FOSSASIA Summit, Singapore
date: 2023-04-15
date-format: full
format:
  revealjs:
    theme: solarized
    footer: "[kurianbenoy.com/presentations/fossasia2023/index.html](https://kurianbenoy.com/presentations/fossasia2023/index.html)"
    slide-number: true
---

## Outline

- OpenAI Whisper(under appreciated model) - 1littecoder video
- Why it's awesome(whisper.cpp, long form transcription, lot of languages, whisper_normalizer)
- What is fine tuning? (Jeremy way of explaining)
- Fine tuning whisper in my language
- Results on fine tuning
- You can also achieve SOTA in your language

## Outline

- OpenAI Whisper and it's awesome features
- What is fine-tuning and how to fine-tune Whisper?
- Results on fine-tuning whisper in Malayalam(my mother tounge)
- Conclusion

## $whoami

- ML Engineer & Team Lead @ Sentient.io
- Volunteer @ Swathanthra Malayalam Computing(SMC)
- Open-source enthusiast


## OpenAI Whisper {background-color="black" }

Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.

::: aside
The name Whisper comes from abbrevation WSPR, which stands for Web-scale Supervised Pretraining for Speech Recognition.
:::


## About model

A Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.

## Whisper Models {.scrollable}

There are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. 


|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |
|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|
|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |
|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |
| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |
| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |
| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |

## Whisper Models

Below are the names of the available models and their approximate memory requirements and relative speed. Large itself has two version: large-v1 and large-v2.

The `.en` models for English-only applications tend to perform better, especially for the `tiny.en` and `base.en` models. We observed that the difference becomes less significant for the `small.en` and `medium.en` models.

::: {.notes}
Rewrite this.
:::

## OpenAI Whisper Features

::: {.notes}
- English Speech Recognition
- Multi-lingual speech recognition
- Support for multiple tasks
- Can run in almost any devices with whisper.cpp
- Awesome community plugins
:::

## English Speech Recognition

![Whisper is competitive with state of art commercial and open source systems](./Whisper_english.png)

## Multi-lingual Speech recognition

- Whisper supports 99 languages
- It really supports just 57 languages really well though, as these languages are provided in OpenAI Whisper API.

::: {.notes}
Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Maori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh.
:::

## Multiple tasks

- Like Language recognition
- Translation of audio from X-> en

## Runs in almost any device

- Whisper.cpp developed by  Georgi Gerganov 
- https://github.com/ggerganov/whisper.cpp

## Awesome community plugins

- Word-level time stamps with [whisperX](https://github.com/m-bain/whisperX)
- Fine-Tune Whisper is achieving SOTA in lot of languages
- [Speaker diarization](https://huggingface.co/spaces/dwarkesh/whisper-speaker-recognition)
- [Audio classification using OpenAIâ€™s Whisper](https://github.com/jumon/zac)

::: {.notes}
[Thanks to Ramsri Goutham](https://ramsrigoutham.medium.com/openais-whisper-7-must-know-libraries-and-add-ons-built-on-top-of-it-10825bd08f76)
:::

## What is fine tuning? {background-color="black" }

Given a pre-trained model, which is a large model which is trained
on a very specific task. If we want to fit it into our specific dataset we will train
and use the pre-trained model to build a new model which works very well for our task.

![Steps in finetuning](https://raw.githubusercontent.com/fastai/fastbook/823b69e00aa1e1c1a45fe88bd346f11e8f89c1ff/images/att_00027.png)

## Fine tuning is still relevant

{{< tweet waydegilliam 1641228571611123712 >}}

## Why fine-tune Whisper?

Whisper is developed as a robust speech recognition system which is
intented to work in out of distribution dataset. While most of previous
approaches relied on training in a few open-source dataset and using them.

If we are working on a language/dataset domain where the out-of distribution
Whisper model doesn't give good result we can use whisper to get good
results.

## What are steps for fine-tuning Whisper?

[Well explained in this article](https://huggingface.co/blog/fine-tune-whisper)

## Fine tuning whisper in Malayalam {background-color="black" }

The base-whisper model was trained on Malayalam:

- but just half an hour dataset was used to train the model

## Results in Common Voice dataset

## Results in MSC dataset

## Result improvement from whisper base model

## Conclusion {background-color="black" }



