---
title: OpenAI Whisper and it's amazing power to do finetuning.
author: Kurian Benoy
subtitle: FOSSASIA Summit, Singapore
date: 2023-04-15
date-format: full
comments: false
format:
  revealjs:
    theme: solarized
    footer: "[kurianbenoy.com/presentations/fossasia2023/index.html](https://kurianbenoy.com/presentations/fossasia2023/index.html)"
    slide-number: true
---

## Outline

- OpenAI Whisper and it's awesome features
- Fine-tuning and how to fine-tune Whisper?
- Results on fine-tuning whisper in Malayalam(my mother tounge)
- Conclusion

::: {.notes}
Originial Idea
- OpenAI Whisper(under appreciated model) - 1littecoder video
- Why it's awesome(whisper.cpp, long form transcription, lot of languages, whisper_normalizer)
- What is fine tuning? (Jeremy way of explaining)
- Fine tuning whisper in my language
- Results on fine tuning
- You can also achieve SOTA in your language
:::

## $whoami

- ML Engineer & Team Lead @ Sentient.io
- Volunteer @ Swathanthra Malayalam Computing(SMC)
- Open-source enthusiast
- Not affiliated to OpenAI

## OpenAI Whisper

![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/OpenAI_Logo.svg/1024px-OpenAI_Logo.svg.png){width=500 fig-align="center"}

- Whisper is the most `under-rated models` released by OpenAI.
- It open-sourced on September 21, 2022 by releasing the inference code and pre-trained model weights.

::: aside
According to [research paper](https://cdn.openai.com/papers/whisper.pdf) pp.2, the name Whisper is an abbrevation for WSPR:

`Web-scale Supervised Pretraining for Speech Recognition`.
:::

## About OpenAI Whisper Model

- The model is robust general purpose speech recognition system aka ASR.
- It is trained on large dataset of 680,000 hours of audio recordings
- Whisper is a computer program which can listen to people talking and write down what they say
- Whisper can understand people speaking different languages and can even translate what they say into English

::: {.notes}
Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.

A Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.
:::

## Whisper Models {.scrollable}


|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |
|------:|----------:|------------------:|:------------------:|:-------------:|:--------------:|
|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |
|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |
| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |
| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |
| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |


::: {.notes}
Below are the names of the available models and their approximate memory requirements and relative speed. Large itself has two version: large-v1 and large-v2.

The `.en` models for English-only applications tend to perform better, especially for the `tiny.en` and `base.en` models. We observed that the difference becomes less significant for the `small.en` and `medium.en` models.
:::

## OpenAI Whisper Features

::: {.notes}
- English Speech Recognition
- Multi-lingual speech recognition
- Support for multiple tasks
- Can run in almost any devices with whisper.cpp
- Awesome community plugins
:::

## English Speech Recognition

![Whisper is competitive with state of art commercial and open source systems](./Whisper_english.png)

## Multi-lingual Speech recognition

- Whisper supports 99 languages
- It really supports just 57 languages really well though, as these languages are provided in OpenAI Whisper API.

::: {.notes}
Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Maori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh.
:::

## Multiple tasks

- Like Language recognition
- Translation of audio from X-> en

## Runs in almost any device

- Since Whisper followed the open source route, [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) developed by  Georgi Gerganov which is a port of Port of OpenAI's Whisper model in C/C++.
- It supports the below platforms:

1. Mac OS (Intel and ARM)
2. iOS
3. Android
4. Linux/Free BSD
5. Web Assembly
6. Windows
7. Raspberry Pi

## Awesome community plugins

- Word-level time stamps with [whisperX](https://github.com/m-bain/whisperX)
- Fine-Tune Whisper is achieving SOTA in lot of languages
- [Speaker diarization](https://huggingface.co/spaces/dwarkesh/whisper-speaker-recognition)
- [Audio classification using OpenAIâ€™s Whisper](https://github.com/jumon/zac)

::: {.notes}
[Thanks to Ramsri Goutham](https://ramsrigoutham.medium.com/openais-whisper-7-must-know-libraries-and-add-ons-built-on-top-of-it-10825bd08f76)
:::

## What is fine tuning?

Given a pre-trained model, which is a large model which is trained
on a very specific task. If we want to fit it into our specific dataset we will train
and use the pre-trained model to build a new model which works very well for our task.

![Steps in finetuning](https://raw.githubusercontent.com/fastai/fastbook/823b69e00aa1e1c1a45fe88bd346f11e8f89c1ff/images/att_00027.png)

## Fine tuning is still relevant

{{< tweet waydegilliam 1641228571611123712 >}}

## Why fine-tune Whisper?

Whisper is developed as a robust speech recognition system which is
intented to work in out of distribution dataset. While most of previous
approaches relied on training in a few open-source dataset and using them.

If we are working on a language/dataset domain where the out-of distribution
Whisper model doesn't give good result we can use whisper to get good
results.

## What are steps for fine-tuning Whisper?

[Well explained in this article](https://huggingface.co/blog/fine-tune-whisper)

## Fine tuning whisper in Malayalam

The base-whisper model was trained on Malayalam:

- but just half an hour dataset was used to train the model

::: {.notes}
Thanks to Whisper event.
:::

## Results in Common Voice dataset

::: {.notes}
Thennal model got the best results:

11.560000 WER, then rest of models got 21-40+ models. 
:::

## Results in MSC dataset

::: {.notes}
Thennal model got the best results:

Got model with 1 WER

Other models
:::

## Result improvement from whisper base model

::: {.notes}
in WER Malayalam CommonVoice9 dataset:

tiny - 102.7
base - 122.9
small - 104.8
medium - 137.8
large - 107.1
largev2 - 103.2
:::

## Tools for benchmarkings

- https://github.com/kurianbenoy/malayalam_asr_benchmarking

## Conclusion


According to whisper in future work section:

**Studying fine-tuning **

>In this work, we have focused on
the robustness properties of speech processing systems and
as a result only studied the zero-shot transfer performance
of Whisper. While this is a crucial setting to study due to it
being representative of general reliability, for many domains
where high-quality supervised speech data does exist, it is
likely that results can be improved further by fine-tuning.
An additional benefit of studying fine-tuning is that it allows
for direct comparisons with prior work since it is a much
more common evaluation setting.

::: {.notes}
You maybe able to achieve SOTA in your own language with Whisper
:::


