<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kurian Benoy</title>
<link>https://kurianbenoy.com/blog.html</link>
<atom:link href="https://kurianbenoy.com/blog.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Wed, 15 Mar 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Everything is about to be changed and launch of GPT-4</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/gpt4/index.html</link>
  <description><![CDATA[ 




<section id="buzz-about-chatgpt" class="level2">
<h2 class="anchored" data-anchor-id="buzz-about-chatgpt">Buzz about ChatGPT</h2>
<p>There has been a lot of buzz about GPT and ChatGPT in specific. Tom Scott, a youtuber recently published a video on how he used ChatGPT to fix a problem in his email backup program. He said it’s beginning of something new like how internet had literally changed everything 20-30 years back.</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/jPhJbKBuNnA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<blockquote class="blockquote">
<p>AI is the new electricity - Andrew NG</p>
</blockquote>
<p>When I was writing this article, I forget the syntax of how to embed youtube videos in quarto markdown. I solved this issue by asking this <a href="https://quarto-bot.onrender.com/">question to Quarto Help Bot</a> which was made by <a href="https://hamel.dev/">Hamel Husain</a>.</p>
<p>I have seen chatbots, yet the way ChatGPT interacts and communicates is insane to be honest. You can ask it literally anything and these Large Language models are becoming incredibly useful. Hamel had used <a href="https://github.com/hwchase17/langchain/">LangChain</a> which is like a framework for building applications with LLMs specifically for quarto.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/gpt4/https:/www.gsb.stanford.edu/sites/default/files/styles/1630x_variable_tinypng/public/resources/ng-ai-1630_1.jpg.webp?itok=9_DYUOPs" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">An Image from gsb.stanford.edu article on Andrew NG remark</figcaption><p></p>
</figure>
</div>
</section>
<section id="how-has-the-ai-landscape-been-going-in-the-past-one-year" class="level2">
<h2 class="anchored" data-anchor-id="how-has-the-ai-landscape-been-going-in-the-past-one-year">How has the AI landscape been going in the past one year?</h2>
<p>Personally I have been following ML/AI for the past five years atleast. Last year really was hyped up. Initially there was this releases in DALL-E and it’s open source alternative Craiyon(then named DALLE mini) being viral. During this time so many trending things like Stable Diffusion, Whisper etc came.</p>
<p>One month back, I started seeing my cousins, parents etc. discussing about ChatGPT and how awesome it is. Some of the application apps like <a href="https://www.roamaround.io">Roamaround.ai</a> build on top of ChatGPT was being used. The final nail was last Sunday, when my grandfather called me to read about ChatGPT article in news.</p>
<p>I have seen people get hyped up about advances in ML. Yet I have never heard about the new technology being discussed by any of my family member like this. Hamel Hussein put this really well in his tweet about what is different in this wave of ML advances.</p>
<p></p><div id="tweet-91868"></div><script>tweet={"url":"https:\/\/twitter.com\/HamelHusain\/status\/1636513242041442305","author_name":"Hamel Husain","author_url":"https:\/\/twitter.com\/HamelHusain","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EThis wave of ML advances feels different than all others before it.  Usually, lots of people sleep on it or just pay lip service to ML.  \u003Cbr\u003E\u003Cbr\u003EThis time, people are rushing to ship ML products, and successfully doing so at breakneck speed.\u003C\/p\u003E&mdash; Hamel Husain (@HamelHusain) \u003Ca href=\"https:\/\/twitter.com\/HamelHusain\/status\/1636513242041442305?ref_src=twsrc%5Etfw\"\u003EMarch 16, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-91868").innerHTML = tweet["html"];</script><p></p>
</section>
<section id="release-of-gpt-4" class="level2">
<h2 class="anchored" data-anchor-id="release-of-gpt-4">Release of GPT-4</h2>
<p>The GPT-4 model was released by OpenAI today IST. It’s been a hectic week already TBH, with so many releases already.</p>
<p></p><div id="tweet-69489"></div><script>tweet={"url":"https:\/\/twitter.com\/iScienceLuvr\/status\/1635747429839671300","author_name":"Tanishq Mathew Abraham","author_url":"https:\/\/twitter.com\/iScienceLuvr","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"ro\" dir=\"ltr\"\u003EGPT-4 release\u003Cbr\u003EMed-PaLM2 announcement\u003Cbr\u003EPaLM API release\u003Cbr\u003EClaude API release \u003Ca href=\"https:\/\/t.co\/Oef6qw6uhf\"\u003Epic.twitter.com\/Oef6qw6uhf\u003C\/a\u003E\u003C\/p\u003E&mdash; Tanishq Mathew Abraham (@iScienceLuvr) \u003Ca href=\"https:\/\/twitter.com\/iScienceLuvr\/status\/1635747429839671300?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-69489").innerHTML = tweet["html"];</script><p></p>
<p>The initial reaction to this model has been awesome, and lot of people have been reacting about this.</p>
<p></p><div id="tweet-49307"></div><script>tweet={"url":"https:\/\/twitter.com\/Suhail\/status\/1635704809725767680","author_name":"Suhail","author_url":"https:\/\/twitter.com\/Suhail","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EWe tried GPT-4 internally over the past few months and it is *a lot* better than meets the eye. I encourage folks to try it. World changing technology.\u003C\/p\u003E&mdash; Suhail (@Suhail) \u003Ca href=\"https:\/\/twitter.com\/Suhail\/status\/1635704809725767680?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-49307").innerHTML = tweet["html"];</script><p></p>
<p>You can read more about this release in below resources:</p>
<p><a href="https://openai.com/research/gpt-4">Research document</a></p>
<p><a href="https://openai.com/product/gpt-4">Product details</a></p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/oc6RV5c1yd0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Check out the summary of what was highlights of GPT-4 and it’s developer livestream in this tweet thread by FSDL.</p>
<p></p><div id="tweet-38859"></div><script>tweet={"url":"https:\/\/twitter.com\/full_stack_dl\/status\/1635734384463745024","author_name":"Full Stack Deep Learning","author_url":"https:\/\/twitter.com\/full_stack_dl","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003ELive-tweeting the GPT-4 livestream from OpenAI ⤵️\u003C\/p\u003E&mdash; Full Stack Deep Learning (@full_stack_dl) \u003Ca href=\"https:\/\/twitter.com\/full_stack_dl\/status\/1635734384463745024?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-38859").innerHTML = tweet["html"];</script><p></p>
</section>
<section id="how-can-we-try-gpt-4-now" class="level2">
<h2 class="anchored" data-anchor-id="how-can-we-try-gpt-4-now">How can we try GPT-4 now?</h2>
<p>According to OpenAI, you can try the latest GPT-4 via Chat GPT Plus Membership.</p>
<p>Two more options seems to be available for normal users without mulimodal search:</p>
<ol type="1">
<li>BingGPT</li>
<li>Poe App from Quora</li>
</ol>
</section>
<section id="is-binggpt-really-using-gpt-4" class="level2">
<h2 class="anchored" data-anchor-id="is-binggpt-really-using-gpt-4">Is BingGPT really using GPT-4?</h2>
<p>To be honest, at the moment we can’t be really sure about that. Even though as Microsoft <a href="https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4">Bing team confirmed today that they are using GPT-4</a>.</p>
<p>In lot of user tests, it doesn’t really seem to be the same. I tested a trick question:</p>
<blockquote class="blockquote">
<p>Which is heavier, two pounds of brick or one pound of feathers?</p>
</blockquote>
<p>GPT-4 seems to give the correct answer at time of writing.</p>
<p></p><div id="tweet-29748"></div><script>tweet={"url":"https:\/\/twitter.com\/charles_irl\/status\/1635699547023482880","author_name":"Charles \uD83C\uDF89 Frye","author_url":"https:\/\/twitter.com\/charles_irl","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003Egpt-4 passes the &quot;two pounds of bricks&quot; adversarial question without prompt fiddling \u003Ca href=\"https:\/\/t.co\/jRcYzxSr38\"\u003Epic.twitter.com\/jRcYzxSr38\u003C\/a\u003E\u003C\/p\u003E&mdash; Charles \uD83C\uDF89 Frye (@charles_irl) \u003Ca href=\"https:\/\/twitter.com\/charles_irl\/status\/1635699547023482880?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-29748").innerHTML = tweet["html"];</script><p></p>
<p>Bing-GPT seems to give wrong answer.</p>
<p></p><div id="tweet-54399"></div><script>tweet={"url":"https:\/\/twitter.com\/kurianbenoy2\/status\/1636066002843627523","author_name":"Kurian Benoy","author_url":"https:\/\/twitter.com\/kurianbenoy2","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EIs it really GPT-4 though? \u003Ca href=\"https:\/\/t.co\/UZXvapfM6k\"\u003Epic.twitter.com\/UZXvapfM6k\u003C\/a\u003E\u003C\/p\u003E&mdash; Kurian Benoy (@kurianbenoy2) \u003Ca href=\"https:\/\/twitter.com\/kurianbenoy2\/status\/1636066002843627523?ref_src=twsrc%5Etfw\"\u003EMarch 15, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-54399").innerHTML = tweet["html"];</script><p></p>
<p>Chat-GPT seems to now give correct answer, it was previously giving wrong answer.</p>
<p></p><div id="tweet-93113"></div><script>tweet={"url":"https:\/\/twitter.com\/1littlecoder\/status\/1636069386699022336","author_name":"1LittleCoder\uD83D\uDCBB","author_url":"https:\/\/twitter.com\/1littlecoder","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EOlder ChatGPt corrected \u003Ca href=\"https:\/\/t.co\/RNXgq5bL8K\"\u003Epic.twitter.com\/RNXgq5bL8K\u003C\/a\u003E\u003C\/p\u003E&mdash; 1LittleCoder\uD83D\uDCBB (@1littlecoder) \u003Ca href=\"https:\/\/twitter.com\/1littlecoder\/status\/1636069386699022336?ref_src=twsrc%5Etfw\"\u003EMarch 15, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-93113").innerHTML = tweet["html"];</script><p></p>
<p>Charles seems to have come with an explaination to this problem, at the time I was writing this article.</p>
<p><em>“GPT-4” is really a series of models, and the one live in chat now is likely the 0314 checkpoint available via the API. BingChat can’t’ve launched with that checkpoint and likely has branched off in the intervening weeks.”</em></p>
<p></p><div id="tweet-80839"></div><script>tweet={"url":"https:\/\/twitter.com\/charles_irl\/status\/1636071852593549312","author_name":"Charles \uD83C\uDF89 Frye","author_url":"https:\/\/twitter.com\/charles_irl","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003ENice find! &quot;GPT-4&quot; is really a series of models, and the one live in chat now is likely the 0314 checkpoint available via the API. BingChat can&#39;t&#39;ve launched with that checkpoint and likely has branched off in the intervening weeks.\u003C\/p\u003E&mdash; Charles \uD83C\uDF89 Frye (@charles_irl) \u003Ca href=\"https:\/\/twitter.com\/charles_irl\/status\/1636071852593549312?ref_src=twsrc%5Etfw\"\u003EMarch 15, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-80839").innerHTML = tweet["html"];</script><p></p>


</section>

 ]]></description>
  <category>Deep learning</category>
  <category>NLP</category>
  <category>coding</category>
  <guid>https://kurianbenoy.com/posts/2023/gpt4/index.html</guid>
  <pubDate>Wed, 15 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://www.gsb.stanford.edu/sites/default/files/styles/1630x_variable_tinypng/public/resources/ng-ai-1630_1.jpg.webp?itok=9_DYUOPs" medium="image"/>
</item>
<item>
  <title>My daily fitness routine</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/fitness_journey/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/fitness_journey/https:/user-images.githubusercontent.com/24592806/223161083-1a5cfc9b-03f0-4425-a1d6-ebc398542727.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Stable diffusion image generated with prompt Very muscular man, photograph quality, ultra detailed</figcaption><p></p>
</figure>
</div>
<p>Hello everyone, I just thought of sharing my daily fitness routine which I have been following for the past 1 month. Previously I had written about <a href="https://kurianbenoy.com/posts/2020/2020-11-22-weightloss.html">How I lost almost 4Kgs in 3 weeks - my wegiht loss Journey</a>. I want to continue this journey, even though just after writing that post I gained a lot of kilos and I couldn’t follow everything I mentioned in that article.</p>
<p>So this time, I am with a new routine:</p>
<p>During morning I go to gym and do High Intensity Interval Training (HIIT) for 30-45 minutes. In the gym I go, this usually consists of 8 stations of 3 minutes exercises followed by 30 seconds rest. The first four stations are vary day after day, followed by a challenge which changes every week. After this I do boxing, followed by two more stations of 3 minutes exercises which usually are floor exercises.</p>
<p>In evening I go for a walk for 45-60 minutes after my work. I usually try to walk almost 4 kilometers and monitor my progress in Strava app. I usually walk in the roads near my home till a paddy field and then return back. My usual pace is 4.5-6 km/h and I cover one kilometer in approximately 11-12 minutes.</p>
<p>Some of you might be wondering why I am sharing this, well I am sharing this as I want to document my fitness progress. Looking back, I myself can look at things I did and see how I progressed. I also want to share this with others who are interested.</p>



 ]]></description>
  <category>myself</category>
  <guid>https://kurianbenoy.com/posts/2023/fitness_journey/index.html</guid>
  <pubDate>Mon, 06 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/24592806/223161083-1a5cfc9b-03f0-4425-a1d6-ebc398542727.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Attending MBIFL 2023, a literature festival</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/mbifl2023/index.html</link>
  <description><![CDATA[ 




<p>Since I am a frequent book purchaser from Mathrubhumi book, in January I got a notification to buy early bird tickets for <a href="https://www.mbifl.com/speakers-2023/">MBIFL 2023</a>. I immediately bought 4 day’s tickets to attend the literature festival. When it came to February, I realised due to some commitments at home and work, I couldn’t attend all the days of this literature festival despite having a ticket.</p>
<p>MBIFL had almost 300+ speakers, with famous speakers like Nobel prize winners, Brooker prize winners, politicians etc.</p>
<p>Yet I had just one wish. <a href="https://en.wikipedia.org/wiki/Benyamin_(writer)">Benyamin</a> is an author who has written lot of thriller novels like അൽ - അറേബ്യൻ നോവൽ ഫാക്‌ടറി and മുല്ലപ്പു നിറമുള്ള പകലുകൾ(which is a dual novel) along with the famous ആടു ജീവിതം(Goat Days). I just wanted to meet him in person and get an autograph on my copy of my favourite novel.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/mbifl2023/book.jpg" class="img-fluid figure-img" width="300"></p>
<p></p><figcaption class="figure-caption">My favourite novel</figcaption><p></p>
</figure>
</div>
<p>I travelled early morning from my house and reached the venue by almost 10:30 AM. During this time, there was a conversational session about പ്രവാസിയുടെ അക്ഷരകാലം with P Sreeramkrishan, Benyamin, Shabini Vasudev and KV Mohan Kumar. After the session, there was a huge fan base to meet author Benyamin. I first went to get a signature from another author KV Mohan Kumar in the panel, and then waited in the queue to get a signature from Benyamin.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/mbifl2023/benyamin_session.jpg" class="img-fluid figure-img" width="300"></p>
<p></p><figcaption class="figure-caption">Session on പ്രവാസിയുടെ അക്ഷരകാലം</figcaption><p></p>
</figure>
</div>
<p>After lot of books were signed by Benyamin which was bought by his fans with some of his famous works like ആടു ജീവിതം, മാന്തളിരിലെ ഇരുപത് കമ്മ്യൂണിസ്ററ് വർഷങ്ങൾ, അൽ - അറേബ്യൻ നോവൽ ഫാക്‌ടറി. I got my copy also signed with a salutation of snehattode(with love). I just asked my favourite author does a person named Sameera Parveen who was a character in Jasmine Days really exist or not. Benyam answered that it’s a mixture of multiple people who he had seen in his life, yet there is no one such person who doesn’t exist as Sameera Parveen like Najeeb in ആടു ജീവിതം.</p>
<p>My mission was just completed in one hour and I got a few more signatures like Shabini Vasudev who is an author from Bahrain and from Vinu V John, who is the star anchor of Asianet news(who kindly reminded me he is not famous to be giving autograph).</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/mbifl2023/book_signature.jpg" class="img-fluid figure-img" width="300"></p>
<p></p><figcaption class="figure-caption">All the signature I got</figcaption><p></p>
</figure>
</div>
<p>After that, I attended the talk with Aparna Balamurali and Captian GR Gopinath. Shashi Tharoor talked about his book Pride, Prejudice and Punditry. Seeing Tharoor answer a question to a student reminded me of India’s former people’s president APJ. I wish him all the success as a politician.</p>
<p>One of the last sessions I attended that day was by Polish author Justi Guziak on Know yourself to express yourself. This session talked about improvising and was a hands-on workshop to learn this art. During the session, the speakers gave me a chit with the question <code>what was the best gift you have ever received?</code>. This question was to be asked to someone who was at the other end of the audience. I gave my question and Janaki who was from Thiruvananthapuram told me the best gift she ever received was a dog she received when she was in her 7th standard. This dog has been living with her for the past 15 years as a constant when she went through her school, then college and even after her marriage. Another situation which was given during the workshop was to convince Mr Karun to give something valuable in his hand. After a lot of convincing, I was able to share the lunch with Karun.</p>
<p>That winded up MBIFL 2023, a literature festival for me a data scientist who doesn’t have anything related to it. It was cool to interact and meet with so many cool people. I am looking forward to MBIFL 2024 soon…</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/mbifl2023/tharoor.jpg" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption class="figure-caption">Session by Shashi Tharoor</figcaption><p></p>
</figure>
</div>
<p><em>Update 1(March 5, 2023)</em></p>
<p>I found a very cool video in 360 degree which showed how the MBIFL 2023 venue atmosphere is. It was a very cool video and I thought of including this also with this blogpost.</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/ZrbFzIFu-d0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>



 ]]></description>
  <category>Life</category>
  <category>Travel</category>
  <category>conference</category>
  <guid>https://kurianbenoy.com/posts/2023/mbifl2023/index.html</guid>
  <pubDate>Sun, 05 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/mbifl2023/book.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Welcome To My Quarto Website</title>
  <dc:creator>Tristan O&#39;Malley</dc:creator>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/welcome/index.html</link>
  <description><![CDATA[ 




<p><img src="https://kurianbenoy.com/posts/2023/welcome/thumbnail.jpg" class="img-fluid"></p>
<p>This is my first post in a Quarto blog. Welcome everyone to my new blog.</p>
<p>I have been wanting for a long time to unify <a href="https://github.com/kurianbenoy/ml-blog">my existing Machine learning blog</a> based on fast-pages together with <a href="https://github.com/kurianbenoy/kurianbenoy.github.io/tree/4b5246ada3190dbdd73dc96d266a5ade7ef078a3">my main blog website</a>.</p>
<p>The unification process is a bit challenging:</p>
<ol type="1">
<li>All my previous blog post in main website was written with <a href="https://github.com/daattali/beautiful-jekyll">beautiful jekyll</a> format using markdown.</li>
<li>Need support for jupyter-notebook, which beautiful jekyll doesn’t support</li>
</ol>
<p>This is where Quarto comes as a saviour. It has wide support for various formats like markdown, jupyter notebook, rmarkdown. The goal, JJ and team is looking to have a single source of publication is really interesting. I was already familiar with nbdev with few of the projects I previously made.</p>
<p>I converted all of my existing blog post in markdown to fastpages markdown format. Then I leveraged <a href="https://nbdev.fast.ai/migrating.html">nbdev 1 migration scripts</a> to move it to quarto.</p>



 ]]></description>
  <category>TIL</category>
  <guid>https://kurianbenoy.com/posts/2023/welcome/index.html</guid>
  <pubDate>Sun, 18 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/2023/welcome/thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Paddy Disease Classification competition</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-08-04-fastai56.html</link>
  <description><![CDATA[ 




<section id="lesson-notebooks" class="level2">
<h2 class="anchored" data-anchor-id="lesson-notebooks">Lesson Notebooks</h2>
<p>There are four notebook covering Paddy Disease Competition, and I feel each of these notebooks are excellent:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/paddy.JPG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<ol type="1">
<li><a href="https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1">Road to Top Part 1</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2">Road to Top Part 2</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3">Road to Top Part 3</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/multi-target-road-to-the-top-part-4">Road to Top Part 4</a></li>
</ol>
</section>
<section id="how-was-paddy-competiton-for-me" class="level2">
<h2 class="anchored" data-anchor-id="how-was-paddy-competiton-for-me">How was Paddy competiton for me?</h2>
<p>This competition is still ongoing at the time of writing. Yet during one month break during which <a href="https://www.youtube.com/playlist?list=PLfYUBJiXbdtSLBPJ1GMx-sQWf6iNhb8mM">Jeremy’s live-coding sessions</a> were held. I got some time to play with Paddy disease classification competition with this competition with other fastai friends also.</p>
<p>At the start of lesson 7, Jeremy said some kind words to Nick and me which can be found in below youtube video. I am extremely lucky to learn from such a great teacher. Without these four notebooks and <a href="https://www.youtube.com/playlist?list=PLfYUBJiXbdtSLBPJ1GMx-sQWf6iNhb8mM">Jeremy’s live-coding sessions</a>, it wouldn’t have been possible.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/jeremy_class_shoutout.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Jeremy showing leaderboard in class</figcaption><p></p>
</figure>
</div>
<p><a href="https://youtube.com/clip/Ugkx5ItB_l5CnUy-T5tpfEXuqB9GR6f-bvZi">A clip from original video</a></p>
<p>I am not going in detail on this lesson, as I feel the introduction notebooks have covered everything so well. So signing off early this time.</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022-08-04-fastai56.html</guid>
  <pubDate>Thu, 04 Aug 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/paddy.JPG" medium="image"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Tabular Models (Linear Regression &amp; Random Forests)</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-07-28-fastai55.html</link>
  <description><![CDATA[ 




<section id="what-is-important-for-an-ml-practitioner" class="level2">
<h2 class="anchored" data-anchor-id="what-is-important-for-an-ml-practitioner">What is important for an ML practitioner</h2>
<p>Most of the time as a practitioner, your job is to connect a set of inputs to the sets of outputs you want with machine learning algorithm together in a framework. According to Jeremy what is important is how you tweak on first layer and last layer of neural network. The middle layer is usually not that important.</p>
</section>
<section id="remind-yourself-these-concepts" class="level2">
<h2 class="anchored" data-anchor-id="remind-yourself-these-concepts">Remind yourself these concepts</h2>
<p>Before getting started with this lesson, let’s remind ourselves <strong>What is matrix &amp; vector?</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/182064940-f5723473-d393-4a16-ab86-a7baf1ed0f8b.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p>In this chaper, you may stumble into terms like matrix-vector multiplication, matrix matrix products etc. So it’s a good idea to remind yourself with the concept of <a href="http://matrixmultiplication.xyz/">matrix multiplication</a> and <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">broadcasting</a>.</p>
<p>In this chapter three notebooks where covered, so it’s bit more hectic compared to the previous chapters to be honest. The notebooks covered were:</p>
<ul>
<li><a href="https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch">Linear Models and Neural net from Scratch</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework">Why you should use a framework?</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/how-random-forests-really-work/">How random forests really work</a></li>
</ul>
<p>For the course there was close to one month gap between fifth and sixth lesson, because of exams in University of Queenzland.</p>
</section>
<section id="linear-model-neural-network-from-scratch-notebook" class="level2">
<h2 class="anchored" data-anchor-id="linear-model-neural-network-from-scratch-notebook">Linear model &amp; neural network from scratch notebook</h2>
<p>In this notebook first few sections covers on data cleaning and feature engineering with pandas. A few notes which I jotted down, when I started looking into the lesson at first.</p>
<ul>
<li>In pandas never delete columns</li>
<li>You can replace missing values using mode of column</li>
<li>We can have multiple modes, so choose the first element as 0</li>
<li>In first baseline model, don’t do complicated things at the start.</li>
<li>for categorical variables we can set dummy variables for Pclass with <code>pd.get_dummies</code></li>
</ul>
<p>Then the notebook progresses first into building:</p>
<ol type="1">
<li>Linear models</li>
<li>Neural networks</li>
<li>Deep Learning</li>
</ol>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This notebook is a pre-requisite for lesson 7 when we are covering collabrative filtering also.</p>
</div>
</div>
</section>
<section id="why-you-should-use-a-framework" class="level2">
<h2 class="anchored" data-anchor-id="why-you-should-use-a-framework">Why you should use a framework?</h2>
<p>This notebook, does some interesting feature engineering followed by building models with fastai framework. It also shows how to use ensembling with fastai library and to get in the top 25% of accuracy.</p>
<p>I have seen this cliche argument that for learning ML, you need to go into details and using frameworks is a step down. Jeremy emphasises always use good frameworks on top of it. Rather than re-inventing from scratch. Lot of the success of fast.ai comes from it not asking practitioners to go into details. One of the reasons I like frameworks like blurr, Icevision is also because of that and it’s helping users who are familiar with fastai to easily build complex computer vision and NLP models.</p>
<p>During a conversation with Icevision core-developer, <a href="https://dicksonneoh.com/">Dickson Neoh</a>:</p>
<blockquote class="blockquote">
<p>In icevision, within 10 minutes I can train an object detection model with any dataset. It may not be most accurate, yet I can iterate so quickly.</p>
</blockquote>
</section>
<section id="how-random-forests-really-work" class="level2">
<h2 class="anchored" data-anchor-id="how-random-forests-really-work">How random forests really work?</h2>
<p>Jeremy was know as the random forest guy before he became know as the Deep learning person. One of the cool things about random forest is it’s very hard to get something wrong unlike logistic regression.</p>
<p>Random forests are really intereptables, and helps in getting good accuracy. He also covered about gradient boosted trees during this lesson.</p>
</section>
<section id="homework-dataset" class="level2">
<h2 class="anchored" data-anchor-id="homework-dataset">Homework dataset</h2>
<p>To practise these techniques, I feel a good place to start is by participating in Kaggle <a href="https://www.kaggle.com/competitions/tabular-playground-series-aug-2022">Tabular Playground dataset competition</a> or <a href="https://www.kaggle.com/competitions?listOption=completed">previous tabular competitions in Kaggle</a>.</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022-07-28-fastai55.html</guid>
  <pubDate>Thu, 28 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/24592806/182064940-f5723473-d393-4a16-ab86-a7baf1ed0f8b.png" medium="image" type="image/png"/>
</item>
<item>
  <title>A strange bug when using fastai library with Weights &amp; Biases</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-07-26-wandbbug.html</link>
  <description><![CDATA[ 




<p>After attending an introduction to using weights &amp; biases along with fastai session conducted by <a href="https://twitter.com/capetorch">Thomas Capaballe</a>. I was excited to use weights and biases library along with a few of my hobby projects. I was working on training an Image classification models on the Kaggle competition dataset <a href="https://www.kaggle.com/competitions/tpu-getting-started">Petal to Metal</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/wblogo.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image info</figcaption><p></p>
</figure>
</div>
<p>In general, whenever I am passing a code to any fastai learner objects with callback. I usually directly pass it along with <code>vision_learner</code> as shown in below code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">arch <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"convnext_tiny_in22k"</span></span>
<span id="cb1-2">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(</span>
<span id="cb1-3">    data,</span>
<span id="cb1-4">    arch,</span>
<span id="cb1-5">    metrics<span class="op" style="color: #5E5E5E;">=</span>error_rate,</span>
<span id="cb1-6">    cbs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb1-7">        WandbCallback(log_preds<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, log_model<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>),</span>
<span id="cb1-8">        SaveModelCallback(monitor<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"accuracy"</span>),</span>
<span id="cb1-9">    ],</span>
<span id="cb1-10">)</span>
<span id="cb1-11">learn.fine_tune(<span class="dv" style="color: #AD0000;">5</span>)</span></code></pre></div>
</div>
<p>I exported this model, as I was trying to create a <a href="https://huggingface.co/spaces/kurianbenoy/Identify_which_flower">hugging face spaces to identify various flowers species</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">learn.export()</span></code></pre></div>
</div>
<p>Now I went ahead creating the inference code with requirements for this model. This is when I noticed that the model exported requires <code>wandb</code> library to run the inference code. I was totally surprised, why it was happening at first.</p>
<p><strong>Why this annoying behaviour?</strong></p>
<p>It’s because when passing the callbacks to <code>Learner</code> class or it’s variants like in case of computer vision fastai uses <code>vision_learner</code> class makes it stick around. In my case, I don’t want the callback to hang around the <code>Learner</code> class forever, as it’s just for training job monitoring only.</p>
<p>After a bit of googling, I found this solution from one of the forum posts written by <a href="twitter.com/waydegilliam">Wayde Gilliam</a>.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Instead of adding your callback to <code>Learner</code> … if it is simply used for training, just include it in your call(s) to <code>fit or fit_one_cycle</code>. As the callback is no longer associated to your Learner, they won’t interfere with your call to <code>get_preds()</code>.</p>
</div>
</div>
<p><a href="https://forums.fast.ai/t/is-there-anyway-to-call-learn-get-preds-without-triggering-any-of-the-callbacks/64753/10">Original answer</a>.</p>
<p>So inorder to fix it, I just passed the callbacks I am using directly with <code>fine_tune</code> method directly. Let’s check the code to pass callbacks this way.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">arch <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"convnext_tiny_in22k"</span></span>
<span id="cb3-2">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(data, arch, metrics<span class="op" style="color: #5E5E5E;">=</span>[accuracy, error_rate])</span>
<span id="cb3-3">learn.fine_tune(</span>
<span id="cb3-4">    <span class="dv" style="color: #AD0000;">5</span>,</span>
<span id="cb3-5">    cbs<span class="op" style="color: #5E5E5E;">=</span>[</span>
<span id="cb3-6">        WandbCallback(log_preds<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, log_model<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>),</span>
<span id="cb3-7">        SaveModelCallback(monitor<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"accuracy"</span>),</span>
<span id="cb3-8">    ],</span>
<span id="cb3-9">)</span></code></pre></div>
</div>
<p>Hence I learned this valuable lesson, which fixed my bug in inferencing code for <a href="https://twitter.com/kurianbenoy2/status/1543985447441145856">huggingface spaces which I was creating</a>.</p>
<p></p><div id="tweet-98820"></div><script>tweet={"url":"https:\/\/twitter.com\/kurianbenoy2\/status\/1543985447441145856","author_name":"Kurian Benoy","author_url":"https:\/\/twitter.com\/kurianbenoy2","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003E\u003Ca href=\"https:\/\/twitter.com\/hashtag\/TIL?src=hash&amp;ref_src=twsrc%5Etfw\"\u003E#TIL\u003C\/a\u003E: It’s better to pass callbacks to fine_tune() and fit_one_cycle() method instead of passing directly to the learner object, to avoid unwanted effects when using your models for inference.\u003C\/p\u003E&mdash; Kurian Benoy (@kurianbenoy2) \u003Ca href=\"https:\/\/twitter.com\/kurianbenoy2\/status\/1543985447441145856?ref_src=twsrc%5Etfw\"\u003EJuly 4, 2022\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-98820").innerHTML = tweet["html"];</script><p></p>
<p><a href="https://twitter.com/TheZachMueller">Zach Mueller</a> also confirmed this is the case.</p>
<p></p><div id="tweet-54759"></div><script>tweet={"url":"https:\/\/twitter.com\/TheZachMueller\/status\/1544297503771746309","author_name":"Zach Mueller","author_url":"https:\/\/twitter.com\/TheZachMueller","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EYup! Unless it&#39;s a callback designed to hang around, you should almost never tie it directly to the Learner\u003C\/p\u003E&mdash; Zach Mueller (@TheZachMueller) \u003Ca href=\"https:\/\/twitter.com\/TheZachMueller\/status\/1544297503771746309?ref_src=twsrc%5Etfw\"\u003EJuly 5, 2022\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-54759").innerHTML = tweet["html"];</script><p></p>



 ]]></description>
  <category>fastai</category>
  <guid>https://kurianbenoy.com/posts/2022-07-26-wandbbug.html</guid>
  <pubDate>Tue, 26 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/wblogo.png" medium="image" type="image/png" height="76" width="144"/>
</item>
<item>
  <title>Getting featured in Spaces of the week and my latest two gradio spaces</title>
  <link>https://kurianbenoy.com/posts/2022-07-06-gradio_spaces.html</link>
  <description><![CDATA[ 




<p>I recently created two gradio based webapps, and one of my spaces - Paddy Doctor got featured in list of hugging face Spaces of the week.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/177607850-eed39c76-51b5-4b00-aad1-804e699540d2.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p>Both gradio apps based on two kaggle competitions which I have been participating in. Both are on computer vision models with one to identify the type of disease in the paddy crop and another to identify the name of flowers(which I am terribly bad at remembering names).</p>
<p>Do checkout the links below for the spaces</p>
<p><a href="https://huggingface.co/spaces/hugginglearners/Paddy-Doctor">Paddy Doctor</a></p>
<p><a href="https://huggingface.co/spaces/hugginglearners/Identify_which_flower">Identify which flower</a></p>



 ]]></description>
  <category>huggingface</category>
  <category>Deep learning</category>
  <category>fastai</category>
  <guid>https://kurianbenoy.com/posts/2022-07-06-gradio_spaces.html</guid>
  <pubDate>Wed, 06 Jul 2022 00:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/24592806/177607850-eed39c76-51b5-4b00-aad1-804e699540d2.png" medium="image" type="image/png"/>
</item>
<item>
  <title>How to approach learning Vim - tips from two monks</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-06-27-tipstolearnvim.html</link>
  <description><![CDATA[ 




<p>Early morning, the disciple woke up to learn from a monk’s session at 6:30 AM to advance his skills. Today the monk was teaching about how to use vim, which is a great text editor.</p>
<p>Monk said Vim is powerful and specifically data scientists should learn Vim because interactive text munching is what we do with input data files and output data files all the time.</p>
<section id="showing-the-power-of-vim" class="level2">
<h2 class="anchored" data-anchor-id="showing-the-power-of-vim">💪Showing the power of Vim</h2>
<p>The monk then went ahead and showed how he made Youtube chapter markers from the posts as shown below. The monk wanted to convert this comment to a format which is suitable for youtube to add chapter markers, so folks can easily watch it in future.</p>
<pre><code>00:00 Create a total empty notebook
- How to be lazy and a great programmer? 03:02


04:13 Create an empty notebook and symlink from persistence storage
-  Why open a new window to use jupyter lab? to keep paperspace interface for shutting down when finished
-  Why should you read paperspace docs? What did Jeremy find out? 05:16
-  What are the interesting folders inside the root directory?
-  How is storage folder different from notebooks directory? Why both of them exist for good reason? 06:32
-  Should we worry about using pip install when paperspace uses conda a lot? 08:02
-  How to pip upgrade packages into the home directory with --user? pip install -U --user fastcore 13:14
-  What folder we want to be there next time when we open notebook? .local/
-  How to save this .local/ into persistence storage? mv .local /storage/

19:24 Create pre-run.sh from scratch to automate .local symlink from storage


-  How to create a python file to setup the symlink first before running jupyter lab 
-  Does Jeremy think paperspace is the way to have easy to use GPU for fastai in 
-  How to make a symlink from /storage/ back to this notebook’s /notebooks director
-  What does this step above do? to link the /storage/ folder back into /notebook
-  Why to access the /storage/ folder inside notebooks is useful?
-  How to create a text file, edit it and save it inside /storage/ with jupyter lab?
</code></pre>
<p>The monk opened his Vim editor and showed a bunch of ways he can easily do this task very quickly with ex commands as shown in the gif below.</p>
<p>Finally, the output will be like in this format:</p>
<pre><code>00:00 Create an notebook
04:13 Symlink from persistence storage
19:24 Create pre-run.sh from scratch to automate .local symlink from storage</code></pre>
<p>If you are curious to learn the trick, follow the below three steps:</p>
<p>Step 1: To delete and move to the start of the next digit type d /^tep 2: Then move down a row using j (or down arrow) and type dot ‘.’ to repeat the movement: j.</p>
<p>Step3: When it’s almost over with no more chapter markers, type dG to delete till the end of the file.</p>
</section>
<section id="disciple-asks-how-to-approach-learning-vim" class="level2">
<h2 class="anchored" data-anchor-id="disciple-asks-how-to-approach-learning-vim">Disciple asks how to approach learning Vim❓</h2>
<p>This disciple was really impressed, yet intimidated at the same time seeing this and asked to the monk <strong>how can someone learn Vim and lot’s of keyboard shortcuts he showed when someone is a beginner at this topic.</strong></p>
</section>
<section id="first-monk-speaks" class="level2">
<h2 class="anchored" data-anchor-id="first-monk-speaks">First Monk speaks</h2>
<p>The trained monk replied as following:</p>
<p>The trick with learning something new is try and like learn in small chunks. So don’t expect to learn all of Vim. At this point:</p>
<p>Start by learning i to start inserting text, arrow keys to move around, escape to go back to command mode, and :wq to close and save. At that point you can use vim to edit your shell scripts and stuff. Then try and learn maybe one or two new commands each day like motion commands w and b are useful to move forward and backward a word.</p>
<p>There are lot of tutorials out there in internet like openvim.com is very helpful to learn Vim. You can work through tutorial like this.</p>
<p>Yeah honestly we all get intimidated, when we see an expert working with something that we don’t know yet and at first it’s like WOW that’s powerful I wish i could do that. You will be like my god you know how would i ever get to that point … the goal is not to be an expert at Vim the goal is to like be able to use Vim to like slowly do something that you want to be able to do.</p>
<p>This is one of the things the I really had to practice for myself in my late teens and early 20s was to repeatedly put myself in a position where I was intentionally doing things slowly by using a tool that I wanted to know and I was pretty sure at some point would be useful but I didn’t know it well enough to do it faster than with other than some other tools.</p>
<p>So I’ve always you know since like 16 been pretty good at using Lotus 1-2-3 and Excel spreadsheets. I tended to turn to them for everything and then I wanted to learn SQL databases. So I kind of forced myself to do things involving lists with databases for a while even though I got slower and then I was like … I’m going to start doing more stuff with VBA macros and stop doing stuff manually and again it was kind of slower for a while and then became faster.</p>
<p>Particularly like you know things like cleaning up that Youtube timestamp thing to create chapter markers. I could have done that manually you know and and the first ten times it would be faster to do it manually but don’t do it manually right because each time you do it manually you know you’re missing out on the opportunity to get better at the thing that’s going to make you faster.</p>
<p>The thing about practicing what you think might eventually be the fast way is that those fast ways accumulate together in kind of these multiplicative ways. So you know I’ve been kind of using this approach of always trying to do things the way I suspect would be the fastest if i was an expert at it. I have been doing that for like 30 years now.</p>
<p>Now most people who watch me work go WOW you’re very fast at doing stuff. You must be really smart you know. I am like Oh no I’m not really smart like you should have seen me when I started, I was terrible… Yet now these things have all accumulated right.</p>
<p>If anybody finds you know good tutorials let me know honestly it’s been a long time since I’ve run a vim tutorial. So I don’t know any good tutorials and don’t know the first one that came up in google is good or bad. I am sure though openvim.com is pretty good though.</p>
<section id="thoughts-of-vim-plugins" class="level3">
<h3 class="anchored" data-anchor-id="thoughts-of-vim-plugins">Thoughts of Vim plugins</h3>
<p>I recommend don’t install lots of plugins there’s lots of plugins you can install. After using vim for well over 20 years, I don’t use any plugins at all. It’s not to say that there are none that are of any use … but like they’re not that useful honestly and you can get lost in that whole like customizing things thing. I just wanted to make it clear to say that actually out of the box Vim works fine and you customize with vimrc configurations.</p>
</section>
</section>
<section id="second-monk-speaks" class="level2">
<h2 class="anchored" data-anchor-id="second-monk-speaks">Second monk speaks</h2>
<p>This when another monk who is working in NVIDIA chimed in with tips to learn vim.</p>
<p>According to me the best tutorial for learning Vim is in terminal. The vimtutor is a excellent tutorial. The first time I looked vimtutor is intimidating, it took me only on like third or fourth try does it start to make sense and was able to complete the entire thing.</p>
<p>When i was learning the basics of them I realized Vim has a steep learning curve. I like to make things appealing, attractive and simple for me. So there is this game called vim-adventures.com.</p>
<p>When I had my corporate job and instead of whatever people do on calls which is just you know browse Reddit. I would do play with website vim-adventures to learn more.</p>
<p>Another resource, which is really great is the Vim book: Practical Vim, Edit Text at the Speed of Thought. It is really well written and there’s a similar book for tmux so that’s that’s two book which made the really big difference for me personally.</p>


</section>

 ]]></description>
  <category>opensource</category>
  <category>fastaicourse</category>
  <category>terminal</category>
  <guid>https://kurianbenoy.com/posts/2022-06-27-tipstolearnvim.html</guid>
  <pubDate>Mon, 27 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/monk.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Building a baseline model for Malayalam Text Classification</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-06-04-baselinemodel.html</link>
  <description><![CDATA[ 




<section id="why-trying-out-simple-baseline-models" class="level2">
<h2 class="anchored" data-anchor-id="why-trying-out-simple-baseline-models">Why trying out simple baseline models?</h2>
<p>I have been working on open source project to work on Malayalam text classification approaches. If you want to follow along the previous blogs check the <a href="https://kurianbenoy.com/ml-blog/categories/#malayalamtextmodels">tag #malayalamtextmodels</a></p>
<p>One of the most under-rated advices which I actually learned from the Approaching almost any Machine learning Problem(AAAMLP) by <a href="https://twitter.com/abhi1thakur">Abhishek Thakur</a> was to start always with simple models and to create a baseline first. This is something <a href="https://twitter.com/jeremyphoward">Jeremy</a> also repeatedly emphasises:</p>
<blockquote class="blockquote">
<p>So we should always be careful to benchmark simple models, as see if they’re good enough for our needs. In practice, you will often find that simple models will have trouble providing adequate accuracy for more complex tasks, such as recommendation systems, NLP, computer vision, or multivariate time series. But there’s no need to guess – it’s so easy to try a few different models, there’s no reason not to give the simpler ones a go too!</p>
</blockquote>
<p><a href="https://github.com/fastai/course22/blob/master/07-how-random-forests-really-work.ipynb">source: 7-how-random-forests-really-work</a></p>
</section>
<section id="doing-modeling-with-simple-approaches" class="level2">
<h2 class="anchored" data-anchor-id="doing-modeling-with-simple-approaches">Doing modeling with simple approaches</h2>
<p>Instead of directly trying out transformers models, I first thought of working with some simple models and see how well they perform. Since I had previously read AAAMLP and seen Abhisheks chapter on how trying out simple techniques in IMDB dataset have him impressive results. I also thought of trying the same approaches.</p>
<p>What follows is my attempt to follow steps initially outlined in AAAMLP book.My code doesn’t depart from the original code in book much.</p>
<p>Let’s start off by importing libraries:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> nltk</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;">import</span> train_test_split</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> nltk.tokenize <span class="im" style="color: #00769E;">import</span> word_tokenize</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> sklearn <span class="im" style="color: #00769E;">import</span> linear_model</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> sklearn <span class="im" style="color: #00769E;">import</span> naive_bayes</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> sklearn <span class="im" style="color: #00769E;">import</span> metrics</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> sklearn <span class="im" style="color: #00769E;">import</span> model_selection</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> sklearn <span class="im" style="color: #00769E;">import</span> preprocessing</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> sklearn.feature_extraction.text <span class="im" style="color: #00769E;">import</span> CountVectorizer</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">from</span> sklearn.feature_extraction.text <span class="im" style="color: #00769E;">import</span> TfidfVectorizer</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">nltk.download(<span class="st" style="color: #20794D;">"punkt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to
[nltk_data]     /home/kurianbenoy/nltk_data...
[nltk_data]   Package punkt is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>True</code></pre>
</div>
</div>
<p>For training, I used a privately shared dataset with me which contained news articles with their associated labels. It contained almost 9000+ sentences labelled in 6 categories of news like Sports, Kerala, Business, Gulf, India, Entertainment.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df[<span class="st" style="color: #20794D;">"labels"</span>].value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Kerala           3847
Entertainment    1968
Sports           1061
Gulf             1034
India             881
Business          572
Name: labels, dtype: int64</code></pre>
</div>
</div>
<section id="logistic-regression-countvectorizer" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-countvectorizer">Logistic regression + CountVectorizer</h3>
<p>One of the first models shared was about using Logistic regression and Count Vectorizer model in AAAMLP book. Let’s see how well it performs in our dataset.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">count_vec <span class="op" style="color: #5E5E5E;">=</span> CountVectorizer(tokenizer<span class="op" style="color: #5E5E5E;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb8-2">count_vec.fit(df.text)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 15.3 s, sys: 196 ms, total: 15.5 s
Wall time: 15.5 s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CountVectorizer(token_pattern=None,
                tokenizer=&lt;function word_tokenize at 0x7f940dc34d30&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">CountVectorizer</label><div class="sk-toggleable__content"><pre>CountVectorizer(token_pattern=None,
                tokenizer=&lt;function word_tokenize at 0x7f940dc34d30&gt;)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb10-2">xtrain <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(df.text)</span>
<span id="cb10-3">model <span class="op" style="color: #5E5E5E;">=</span> linear_model.LogisticRegression()</span>
<span id="cb10-4">model.fit(xtrain, df.labels)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 4min 27s, sys: 7.5 s, total: 4min 35s
Wall time: 1min 2s</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">data <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb13-2">    <span class="st" style="color: #20794D;">"text"</span>: [</span>
<span id="cb13-3">        <span class="st" style="color: #20794D;">"സ്കൂബാഡൈവിങ്ങ്, സ്നോർക്കേലിങ്ങ്, സ്പീഡ്ബോട്ടിങ്ങ്, സർഫിങ്ങ് തുടങ്ങിയ കടൽവിനോദങ്ങൾക്കു പേരുകേട്ട ബാലിയിൽ പോയിട്ടും ഇതൊന്നും പരീക്ഷിച്ചില്ല.ധൈര്യം വരാത്തതുകൊണ്ടാണ്. ഇപ്പോൾ ആലോചിക്കുമ്പോൾ ഒരുകൈ നോക്കാമായിരുന്നെന്നുോന്നുന്നു. സാരമില്ല, ബാക്കിവെച്ച ആഗ്രഹങ്ങളാണല്ലോ മുന്നോട്ടുനീങ്ങാനുള്ള പ്രേരണ. അവസരങ്ങൾ ഇനിയുമുണ്ടാകുമെന്ന് കരുതുന്നു."</span></span>
<span id="cb13-4">    ],</span>
<span id="cb13-5">    <span class="st" style="color: #20794D;">"labels"</span>: [<span class="st" style="color: #20794D;">"sport"</span>],</span>
<span id="cb13-6">}</span>
<span id="cb13-7">data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>{'text': ['സ്കൂബാഡൈവിങ്ങ്, സ്നോർക്കേലിങ്ങ്, സ്പീഡ്ബോട്ടിങ്ങ്, സർഫിങ്ങ് തുടങ്ങിയ കടൽവിനോദങ്ങൾക്കു പേരുകേട്ട ബാലിയിൽ പോയിട്ടും ഇതൊന്നും പരീക്ഷിച്ചില്ല.ധൈര്യം വരാത്തതുകൊണ്ടാണ്. ഇപ്പോൾ ആലോചിക്കുമ്പോൾ ഒരുകൈ നോക്കാമായിരുന്നെന്നുോന്നുന്നു. സാരമില്ല, ബാക്കിവെച്ച ആഗ്രഹങ്ങളാണല്ലോ മുന്നോട്ടുനീങ്ങാനുള്ള പ്രേരണ. അവസരങ്ങൾ ഇനിയുമുണ്ടാകുമെന്ന് കരുതുന്നു.'],
 'labels': ['sport']}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">test_df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(data)</span>
<span id="cb15-2">test_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>സ്കൂബാഡൈവിങ്ങ്, സ്നോർക്കേലിങ്ങ്, സ്പീഡ്ബോട്ടിങ...</td>
      <td>sport</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">test_df <span class="op" style="color: #5E5E5E;">=</span> df.sample(frac<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.1</span>, random_state<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb16-2">test_df.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(936, 2)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">xtest <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(test_df.text)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">preds <span class="op" style="color: #5E5E5E;">=</span> model.predict(xtest)</span>
<span id="cb19-2">accuracy <span class="op" style="color: #5E5E5E;">=</span> metrics.accuracy_score(test_df.labels, preds)</span>
<span id="cb19-3">accuracy</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>0.9989316239316239</code></pre>
</div>
</div>
<p>You may be wondering, why I haven’t deleted all these code piece even after experimenting. This is something, which recently picked up following fastai v5 course. Instead of always deleting after experimenting, keep your experiments also public. But after experimentation is done, wrap it up as function like the one below so you can reuse it in future experiments as well.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">def</span> vectorize_evaluate_loop(train_df, test_df):</span>
<span id="cb21-2">    count_vec <span class="op" style="color: #5E5E5E;">=</span> CountVectorizer(tokenizer<span class="op" style="color: #5E5E5E;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb21-3">    count_vec.fit(train_df.text)</span>
<span id="cb21-4">    dependent_train <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(train_df.text)</span>
<span id="cb21-5">    model <span class="op" style="color: #5E5E5E;">=</span> linear_model.LogisticRegression()</span>
<span id="cb21-6">    model.fit(dependent_train, train_df.labels)</span>
<span id="cb21-7">    dependent_test <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(test_df.text)</span>
<span id="cb21-8">    predictions <span class="op" style="color: #5E5E5E;">=</span> model.predict(dependent_test)</span>
<span id="cb21-9">    <span class="cf" style="color: #003B4F;">return</span> metrics.accuracy_score(test_df.labels, predictions)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="op" style="color: #5E5E5E;">%%</span>time</span>
<span id="cb22-2">vectorize_evaluate_loop(df, test_df)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 4min 37s, sys: 6.69 s, total: 4min 43s
Wall time: 1min 17s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.9989316239316239</code></pre>
</div>
</div>
<p>The function to create k-folds for calculating validation accuracy across K folds of data. It’s very important to create <a href="https://www.fast.ai/2017/11/13/validation-sets/">good validation sets</a>.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">df[<span class="st" style="color: #20794D;">"kfold"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb26-2">df <span class="op" style="color: #5E5E5E;">=</span> df.sample(frac<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>).reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">df.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(9363, 3)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">Y_value <span class="op" style="color: #5E5E5E;">=</span> df.labels.values</span>
<span id="cb29-2">kf <span class="op" style="color: #5E5E5E;">=</span> model_selection.StratifiedKFold(n_splits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb29-3"></span>
<span id="cb29-4"><span class="cf" style="color: #003B4F;">for</span> fold, (text_, value_) <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(kf.split(X<span class="op" style="color: #5E5E5E;">=</span>df, y<span class="op" style="color: #5E5E5E;">=</span>Y_value)):</span>
<span id="cb29-5">    df.loc[value_, <span class="st" style="color: #20794D;">"kfold"</span>] <span class="op" style="color: #5E5E5E;">=</span> fold</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="cf" style="color: #003B4F;">for</span> fold_ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb30-2">    train_df <span class="op" style="color: #5E5E5E;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;">!=</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb30-3">    test_df <span class="op" style="color: #5E5E5E;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;">==</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb30-4">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Fold value: </span><span class="sc" style="color: #5E5E5E;">{</span>fold_<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb30-5">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Accuracy: </span><span class="sc" style="color: #5E5E5E;">{</span>vectorize_evaluate_loop(train_df, test_df)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold value: 0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8873465029364656
Fold value: 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8777362520021356
Fold value: 2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8916177255739456
Fold value: 3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.875
Fold value: 4</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8669871794871795</code></pre>
</div>
</div>
</section>
<section id="naive-bayes-classifier" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes-classifier">Naive Bayes Classifier</h3>
<p>A bit faster to complete training, yet only difference is it’s having less accuracy compared to previous approach.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="kw" style="color: #003B4F;">def</span> naive_bayes_evaluate_loop(train_df, test_df):</span>
<span id="cb42-2">    count_vec <span class="op" style="color: #5E5E5E;">=</span> CountVectorizer(tokenizer<span class="op" style="color: #5E5E5E;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb42-3">    count_vec.fit(train_df.text)</span>
<span id="cb42-4">    dependent_train <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(train_df.text)</span>
<span id="cb42-5">    <span class="co" style="color: #5E5E5E;"># changing different model name for function</span></span>
<span id="cb42-6">    model <span class="op" style="color: #5E5E5E;">=</span> naive_bayes.MultinomialNB()</span>
<span id="cb42-7">    model.fit(dependent_train, train_df.labels)</span>
<span id="cb42-8">    dependent_test <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(test_df.text)</span>
<span id="cb42-9">    predictions <span class="op" style="color: #5E5E5E;">=</span> model.predict(dependent_test)</span>
<span id="cb42-10">    <span class="cf" style="color: #003B4F;">return</span> metrics.accuracy_score(test_df.labels, predictions)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="cf" style="color: #003B4F;">for</span> fold_ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb43-2">    train_df <span class="op" style="color: #5E5E5E;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;">!=</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb43-3">    test_df <span class="op" style="color: #5E5E5E;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;">==</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb43-4">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Fold value: </span><span class="sc" style="color: #5E5E5E;">{</span>fold_<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb43-5">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Accuracy: </span><span class="sc" style="color: #5E5E5E;">{</span>naive_bayes_evaluate_loop(train_df, test_df)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold value: 0
Accuracy: 0.8441003737319808
Fold value: 1
Accuracy: 0.8227442605445809
Fold value: 2
Accuracy: 0.8296849973304858
Fold value: 3
Accuracy: 0.8269230769230769
Fold value: 4
Accuracy: 0.8183760683760684</code></pre>
</div>
</div>
</section>
<section id="logistic-regression-tfidf-vectorizer" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-tfidf-vectorizer">Logistic Regression + Tfidf Vectorizer</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="kw" style="color: #003B4F;">def</span> tf_idf_evaluate_loop(train_df, test_df):</span>
<span id="cb45-2">    <span class="co" style="color: #5E5E5E;"># note we are using TfidfVectorizer instead of CountVectorizer</span></span>
<span id="cb45-3">    count_vec <span class="op" style="color: #5E5E5E;">=</span> TfidfVectorizer(tokenizer<span class="op" style="color: #5E5E5E;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb45-4">    count_vec.fit(train_df.text)</span>
<span id="cb45-5">    dependent_train <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(train_df.text)</span>
<span id="cb45-6">    model <span class="op" style="color: #5E5E5E;">=</span> linear_model.LogisticRegression()</span>
<span id="cb45-7">    model.fit(dependent_train, train_df.labels)</span>
<span id="cb45-8">    dependent_test <span class="op" style="color: #5E5E5E;">=</span> count_vec.transform(test_df.text)</span>
<span id="cb45-9">    predictions <span class="op" style="color: #5E5E5E;">=</span> model.predict(dependent_test)</span>
<span id="cb45-10">    <span class="cf" style="color: #003B4F;">return</span> metrics.accuracy_score(test_df.labels, predictions)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="cf" style="color: #003B4F;">for</span> fold_ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb46-2">    train_df <span class="op" style="color: #5E5E5E;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;">!=</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb46-3">    test_df <span class="op" style="color: #5E5E5E;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;">==</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb46-4">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Fold value: </span><span class="sc" style="color: #5E5E5E;">{</span>fold_<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb46-5">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Accuracy: </span><span class="sc" style="color: #5E5E5E;">{</span>tf_idf_evaluate_loop(train_df, test_df)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold value: 0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8478376935397758
Fold value: 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8344901227976508
Fold value: 2
Accuracy: 0.8489054991991457
Fold value: 3
Accuracy: 0.8290598290598291
Fold value: 4</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8253205128205128</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluating-and-looking-results" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-and-looking-results">Evaluating and looking results</h2>
<p>I am genuinely surprised by the following:</p>
<ol type="1">
<li>A simple linear regression on this text classification tasks get’s close to 87-89% accuracy when evaluated using K-fold validation approach. We haven’t done any complex fine tuning or even label_encoding at the moment. Based on improving with some more tweaks, I am trying a <a href="https://github.com/smc/malayalam-text-classifier/tree/main/notebooks">few things here</a>.</li>
<li>The state of art model for Text classification in Malayalam claims to have got 92% accuracy based on training only on validation dataset, like we have done in sklearn it seems.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/171474436-2e9a25d5-5e62-41a0-b249-e65a2df57585.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p><a href="https://github.com/adamshamsudeen/Vaaku2Vec/blob/master/train_classifier.ipynb">Source</a></p>
<p><strong>What is the difference between Vaaku2Vec and this simple model if it’s just less than 3% more accurate?</strong></p>
<blockquote class="blockquote">
<p>Yet there is a huge difference between ULMFiT approach which Vaaku2Vec and our baseline model. The Vaaku2Vec model has been trained on base model of Malayalam Wikipedia text, so more text corpus will be present and the model has learned from it. In case of our simple baseline model, it has learned just from 9000+ data points only. Now in case of a new word which is not in this dataset, there is a probability it maybe found in Vaaku2Vec model. Yet it’s not always true, because words like Covid will defenitely be not recognized by Vaaku2Vec model also.</p>
</blockquote>
</section>
<section id="using-simple-models-for-labelling" class="level2">
<h2 class="anchored" data-anchor-id="using-simple-models-for-labelling">Using simple models for labelling</h2>
<p>One of the best things about using simple models to train is also that you can use it for data labelling efforts. To be honest, I am still learning more about data-annotation and labelling. My friend Alex is an expert though here and checkout his awesome blog <a href="https://blog.zenml.io/data-labelling-annotation">How to get the most out of data annotation</a>. I really loved this image showing 5 steps of datalabelling.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/171987028-11d5e564-f292-4478-8273-749c5d280045.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p><a href="https://blog.zenml.io/data-labelling-annotation/">Source and credits: Alex</a></p>
<p>I see more work on data annotation coming soon as part of this project also. With that have a nice day.</p>


</section>

 ]]></description>
  <category>malayalamtextmodels</category>
  <category>malayalam</category>
  <category>NLP</category>
  <category>opensource</category>
  <category>ML</category>
  <category>Deep learning</category>
  <category>SMC</category>
  <guid>https://kurianbenoy.com/posts/2022-06-04-baselinemodel.html</guid>
  <pubDate>Sat, 04 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/24592806/171474436-2e9a25d5-5e62-41a0-b249-e65a2df57585.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Starting an open-source project - Malayalam Text Classifier</title>
  <link>https://kurianbenoy.com/posts/2022-05-30-malayalamtext-0.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/malayalam.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">malayalam letters</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>TLDR: Kurian has committed to start an <a href="https://github.com/smc/malayalam-text-classifier">open-source project for Text classification</a> tasks in Malayalam which is going to build as an open-source project under <a href="https://smc.org.in/">SMC community</a>.</p>
</blockquote>
<section id="why-i-am-starting-this-project" class="level2">
<h2 class="anchored" data-anchor-id="why-i-am-starting-this-project">Why I am starting this project?</h2>
<p>I have been doing the fastai course since 2018. Yet I have been taking it seriously probably, only after I bought the book <a href="https://kurianbenoy.com/2021-06-10-Fast-group/">Deep Learning for Coders with FastAI &amp; Pytorch</a> almost one year back. This year I took the <a href="https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai">fastai v5 course</a>, and I feel it’s time to follow a piece of advice which I have heard multiple times.</p>
<blockquote class="blockquote">
<p>Important: Jeremy Howard, who is teaching this course and wrote the book prompts you to take what you learned and apply it to something that has meaning for you. (This is something that most of those who’ve found any success with the course <a href="https://sanyambhutani.com/how-not-to-do-fast-ai--or-any-ml-mooc-/">emphasise repeatedly</a>.)</p>
</blockquote>
</section>
<section id="problem-domain" class="level2">
<h2 class="anchored" data-anchor-id="problem-domain">Problem Domain</h2>
<p>According to <a href="https://huggingface.co/tasks/text-classification">huggingface tasks page</a>:</p>
<blockquote class="blockquote">
<p>Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness.</p>
</blockquote>
<p>Malayalam is a highly inflectional and agglutinative language compared to other languages. The quantitative complexity of Malayalam classification was <a href="https://kavyamanohar.com/documents/tsd_morph_complexity_ml.pdf">explained in this paper</a>. The computer still doesn’t seem to have understood the basic behaviour of the language to do text classification. Malayalam is a language which morphologically complex making it even more difficult.</p>
<p>Very few people seem to have applied techniques in deep learning in Malayalam, and it seems to be a good place to see if really deep learning techniques can be applied in my mother tongue, Malayalam. A lot of progress in other languages has happened and in general NLP, yet it’s a good time to see if it works in Indic languages like Malayalam.</p>
</section>
<section id="why-text-classification-is-interesting" class="level2">
<h2 class="anchored" data-anchor-id="why-text-classification-is-interesting">Why Text classification is interesting?</h2>
<p>I believe working on tasks like <code>Text classification</code> is way more difficult when we are working in low-resource languages like Malayalam. Yet when working on problems like this, you realize what are things you take for granted in the English language.</p>
<p>In the English language, there are plenty of labelled datasets on any problem set you to want. A lot of articles and blogs have been written on how to apply various NLP techniques in English. When it comes to Malayalam, there is just a handful of people who have tried and applied this in Malayalam.</p>
<blockquote class="blockquote">
<p>Note to myself: Will is more important than Skill and it’s important to be tenacious here.</p>
</blockquote>
<p>I believe this is here, it’s very important to believe in one’s tenacity and try out new things in a field where very less research happening, and there are no proper open datasets for researchers to work on. This is why I feel this project can be challenging, and my approach is to see if the latest transformer approaches can do something or not.</p>
</section>
<section id="previous-work-vaaku2vec" class="level2">
<h2 class="anchored" data-anchor-id="previous-work-vaaku2vec">Previous work: Vaaku2Vec</h2>
<p>The most important work in Malayalam text classification as far as I know is <a href="https://github.com/adamshamsudeen/Vaaku2Vec">Vaaku2Vec project - State-of-the-Art Language Modeling and Text Classification in the Malayalam Language</a>.</p>
<p>According to their Github README:</p>
<blockquote class="blockquote">
<p>We trained a Malayalam language model on the Wikipedia article dump from Oct, 2018. The Wikipedia dump had 55k+ articles. The difficulty in training a Malayalam language model is text tokenization since Malayalam is a highly inflectional and agglutinative language. In the current model, we are using an nltk tokenizer (will try better alternative in the future) and the vocab size is 30k. The language model was used to train a classifier which classifies a news into 5 categories (India, Kerala, Sports, Business, Entertainment). Our classifier came out with a whooping 92% accuracy in the classification task.</p>
</blockquote>
<p>It was revolutionary at that time, to see deep learning techniques applied to get SOTA in Malayalam. IndicNLP as an organisation did a lot of work, from working on projects like Word2vec, Vaakk2vec etc. They worked on creating a Named entity recognition dataset for Malayalam etc. They conducted Devsprints in colleges like Model Engineering college… and presented their work in Pycon India and Kochi Python. Most of the work was done by <a href="https://www.linkedin.com/in/adamshamsudeen/">Adam Shamsudeen</a> and <a href="https://www.linkedin.com/in/kamalkraj/">Kamal K Raj</a>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rgCXWaKzMKU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="whats-the-plan-for-the-project" class="level2">
<h2 class="anchored" data-anchor-id="whats-the-plan-for-the-project">What’s the plan for the project?</h2>
<blockquote class="blockquote">
<p>Important: Cervantes once wrote that “the journey is better than the inn”, which means that the process is more valuable than the destination.</p>
</blockquote>
<p>At moment, the project doesn’t have any concrete goals and it’s just me who is working in my free time.</p>
<p>I have created a <a href="https://github.com/smc/malayalam-text-classifier/issues">few issues</a> and my next blog post will be on creating a baseline model on a private dataset that a few kind folks shared with me. I expect the dataset creation to be an iterative task. I am looking forward to blogging about what I work on and stumble upon in each stage of the project.</p>
<p>When I was looking for where I wanted to create this as an open-source project obviously, I choose <a href="https://smc.org.in/">Swathanthra Malayalam Community</a> because:</p>
<ul>
<li>I feel SMC as an organization played a pivotal part in revolutionizing Malayalam computing and has a strong community presence. They have made a lot of work by creating fonts, helping in internationalization efforts, …</li>
<li>People like <a href="https://thottingal.in/">Santhosh Thottingal</a> and <a href="https://kavyamanohar.com/">Kavya Manohar</a> have helped me a lot in my previous failed attempt to <a href="https://github.com/kurianbenoy/MTTS">build TTS with deep learning in Malayalam</a>.</li>
<li>Some of the open-source projects made by SMC still survive like the website of <a href="https://msc.smc.org.in/">Malayalam Speech Corpus</a> which is impressive to me.</li>
</ul>
<p>I would like to thank the following people for all the support and motivation they have given me in starting this open-source project on this occasion:</p>
<ol type="1">
<li><a href="https://twitter.com/strickvl/">Alex Strick van Linschoten</a></li>
<li><a href="https://twitter.com/santhoshtr">Santhosh Thottingal</a> and <a href="https://twitter.com/kavya_manohar">Kavya Manohar</a></li>
<li><a href="https://twitter.com/fanbyprinciple">Ashwin Jayaprakash</a></li>
</ol>


</section>

 ]]></description>
  <category>malayalamtextmodels</category>
  <category>malayalam</category>
  <category>NLP</category>
  <category>opensource</category>
  <category>ML</category>
  <category>Deep learning</category>
  <category>SMC</category>
  <guid>https://kurianbenoy.com/posts/2022-05-30-malayalamtext-0.html</guid>
  <pubDate>Mon, 30 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/malayalam.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Installing Python Packages &amp; setting up libraries for Data Science - the right way</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-05-28-fastai-walthrus1.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p><a href="https://forums.fast.ai/u/jeremy">Jeremy</a> has been conducting these official course walk-thrus which started on May 27, 2022 for students of <a href="https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai">fastaiv5 course</a>. The idea of these course walk-thrus were “going to explain exactly how to do every step, and why we do things the way we do”.</p>
<p>We in the sense <code>fastai</code> approach of development. It was very useful to me and it covered answers to some of things which I was searching for a long time. I will use it again and again, so thought of writing it down to refer later. The first walk thrus was on the topic: <code>Introduction to the terminal. How to install Python and libraries</code> and I felt I got more value out of these walk-thrus than some of lessons in course</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The right way here means the way Jeremy does stuff. Obiviously there as thousand of way to do thing, yet going through each ways has it’s own pros/cons.</p>
</div>
</div>
</section>
<section id="whats-terminal-how-to-work-with-it" class="level2">
<h2 class="anchored" data-anchor-id="whats-terminal-how-to-work-with-it">🚖 What’s terminal, how to work with it?</h2>
<section id="terminal-vs-shell" class="level3">
<h3 class="anchored" data-anchor-id="terminal-vs-shell">Terminal vs Shell</h3>
<p>A terminal is a program which can display console window to run program. Yet thing inside is not strictly a terminal, but called a shell. The black coloured stuff, which you see in movies used by hackers is Terminal as shown in image below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/170852543-17bdb268-7ace-43c6-b1a0-a2b5b0a9ac43.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p>Usually in a <strong>terminal there can be multiple shells</strong>, which can have different colours, shells etc. So terminal and shell are totally different in meaning. You can think shell as the a ship which does main things it’s supposed to do like running program, while terminal is like the a group of ships which is usually controlled by a parent like a corporal.</p>
<p>In a windows terminal it can start no of shells like <code>PowerShell, Command Prompt, Ubuntu</code> etc… Most of the time we use both terminal and shell interchangebly which is ok.</p>
</section>
<section id="installing-terminal-shell" class="level3">
<h3 class="anchored" data-anchor-id="installing-terminal-shell">Installing Terminal &amp; Shell</h3>
<p>You can install terminal in Windows by downloading <a href="https://apps.microsoft.com/store/detail/windows-terminal/9N0DX20HK701?hl=en-us&amp;gl=US">Windows terminal</a>. In case of linux/MacOS, you can just search for terminal as it will come with a terminal pre-installed.</p>
<p>In Windows, Jeremy recommends to use <a href="https://docs.microsoft.com/en-us/windows/wsl/install">WSL</a>, which install a linux distribution within windows and then install <a href="https://apps.microsoft.com/store/detail/ubuntu/9PDXGNCFSCZV">Ubuntu from Microsoft Store</a>.</p>
</section>
<section id="handy-tips" class="level3">
<h3 class="anchored" data-anchor-id="handy-tips">Handy Tips</h3>
<p>It’s a good idea to change the default shell from <code>Power shell to Ubuntu</code> for easy usage. Also learn some keyboard shortcuts.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Learning Keyboard shortcuts can be immensely valuable.</p>
</div>
</div>
</section>
<section id="keyboard-shortcuts" class="level3">
<h3 class="anchored" data-anchor-id="keyboard-shortcuts">Keyboard shortcuts</h3>
<p>Some of the useful keyboard shortcuts shared during lesson and in forums are as follows:</p>
<p><strong>Shared by <a href="https://forums.fast.ai/u/jeremy/summary">Jeremy</a></strong></p>
<p><kbd>Ctrl+Shift+1</kbd> - Open shell set for default profile.</p>
<p><kbd>Ctrl+Shift+3</kbd> - Open shell listed as number 3 in WSL.</p>
<p><kbd>Alt+Enter</kbd> - Enter terminal in full screen.</p>
<p><kbd> Ctrl + r </kbd> - Recursvie back search to search the previous typed commands.</p>
<p><kbd>Ctrl-a</kbd> - Move to the start of the current line.</p>
<p><kbd>Ctrl-e</kbd> - Move to the end of the line.</p>
<p><kbd>Tab</kbd> Autocomplete.</p>
<p><strong>Shared by <a href="https://forums.fast.ai/u/miwojc/summary">miwojc</a></strong></p>
<p><kbd>Ctrl-f</kbd> - Move forward a character.</p>
<p><kbd>Ctrl-b</kbd> - Move back a character.</p>
<p><kbd>Alt-f</kbd> - Move forward to the end of the next word. Words are alphanumeric.</p>
<p><kbd>Alt-b</kbd> - Move back to the start of the current or previous word. Words are alphanumeric.</p>
<p><kbd>Ctrl-l</kbd> - Clear the screen.</p>
<p><kbd>Ctrl-p</kbd> - Fetch the previous command from the history list (same as up but easier to reach).</p>
<p><kbd>Ctrl-n</kbd> - Fetch the next command from the history list (same as down).</p>
<p><kbd>Ctrl-r</kbd> - Search backward through history.</p>
<p><kbd>Ctrl-d</kbd> - Delete the character under the cursor.</p>
<p><kbd>Ctrl-k </kbd> - Kill (cut) forwards to the end of the line.</p>
<p><kbd>Ctrl-u</kbd> - Kill (cut) backwards to the start of the line.</p>
<p><kbd>Alt-d</kbd> - Kill (cut) forwards to the end of the current word.</p>
<p><kbd>Ctrl-w</kbd> - Kill(cut) backwards to the start of the current word.</p>
<p><strong>Shared by <a href="https://forums.fast.ai/u/kurianbenoy/summary">Kurian</a></strong></p>
<p><kbd>Alt Shift + </kbd> - Open a new vertical pane</p>
<p><kbd>Alt Shift -</kbd> - Open a new horizontal pane</p>
<p><kbd>Ctrl Shift w</kbd> - Closing a Pane</p>
</section>
</section>
<section id="how-to-install-python-packages-for-datascience" class="level2">
<h2 class="anchored" data-anchor-id="how-to-install-python-packages-for-datascience">🔰 How to install Python Packages for datascience</h2>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Never use the python which comes by default with operating system, always use a differnt python to work on stuff you want, else it will become really messy… ⚠️.</p>
</div>
</div>
<section id="installation-with-mamba" class="level3">
<h3 class="anchored" data-anchor-id="installation-with-mamba">Installation with mamba</h3>
<p>To follow this advice, this let’s go ahead and install python seperately with packaging manager called <a href="https://github.com/mamba-org/mamba">mamba</a> which is a Fast Cross-Platform Package Manager. It’s aka. faster version of conda.</p>
<p>So go to the <a href="https://github.com/conda-forge/miniforge#mambaforge">mambaforge installer</a>. Based on your operating system, download the shell script to install with:</p>
<pre><code>wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh
bash Mambaforge-Linux-x86_64.sh</code></pre>
<p>After downloading and installation is complete. To refresh terminal either close and reopen terminal or typing below command:</p>
<pre><code>. ~/.bashrc</code></pre>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Jeremy recommends to install popular libraries which are supported in conda from mamba. If it’s not there in conda, or something which requires editable install use pip.</p>
</div>
</div>
</section>
<section id="uninstalling-mambaconda" class="level3">
<h3 class="anchored" data-anchor-id="uninstalling-mambaconda">🐛 Uninstalling mamba/conda</h3>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you are a beginner, working with virtual environments is intimidating. So jeremy recommends whenever you face any issues as a beginner, it’s important to know how to delete your setup.</p>
</div>
</div>
<p>These are steps to see if conda/mamba is properly uninstalled in a linux environment:</p>
<ul>
<li>Check if ipython, jupyter is installed. If yes, first uninstall it.</li>
</ul>
<p><strong>Note: You can uninstall via:</strong></p>
<pre><code>pip uninstall jupyter
pip uninstall ipython3</code></pre>
<p><strong>You can check the path of program by typing the command, to see if was installed by system python or mamba</strong></p>
<pre><code>(base) kurianbenoy@Lap-34:~/blog/ml-blog$ which jupyter
/home/kurianbenoy/mambaforge/bin/jupyter</code></pre>
<ul>
<li>Then remove mamabaforge folder. In linux usually, mambaforge is installed in /home/username.</li>
</ul>
<p>So to delete the mambaforge package:</p>
<pre><code>(base) kurianbenoy@Lap-34:~$ ls
blog  downloads  mambaforge
(base) kurianbenoy@Lap-34:~$ rm -rf mambaforge/</code></pre>
<ul>
<li>Then delete conda package also.</li>
</ul>
</section>
<section id="using-fastsetup" class="level3">
<h3 class="anchored" data-anchor-id="using-fastsetup">Using fastsetup</h3>
<p><a href="github.com/fastai/fastsetup">Goto github repository</a> and download the <a href="https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh">setup-conda.sh file</a>.</p>
<pre><code>wget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh</code></pre>
<p>This is a normal shell script, so just run the shellscript to install mamba as follows:</p>
<pre><code>source setup-conda.sh
. ~/.bashrc
conda install -yq mamba</code></pre>
</section>
<section id="my-question-to-jeremy" class="level3">
<h3 class="anchored" data-anchor-id="my-question-to-jeremy">My question to Jeremy</h3>
<p>❓I asked to Jeremy about: which version of python is using and how to use for a different python version</p>
<p>Jeremy on checking Mambaforge repository, realised that python version which we are using now is python 3.9. It’s always a good idea to know, which kind of python versions are near their end of life and <a href="https://endoflife.date/python">can be here</a>. At the time of writing any version above python 3.7 to python3.10 is recommended to use. Yet according to Jeremy, he usually prefers to use latest python only 1 year after it’s released, but fastai do support the latest version.</p>
<p><a href="https://twitter.com/radekosmulski/">Radek</a> who is a engineer at Nvidia, told he usually prefer mamba because with just one line of code you can switch to any python version you want. Afer the session in forums, Radek shared how to do this as shown in below screenshot.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/170855465-1f74f66e-8238-43a2-b9f3-dcbff67a547b.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
</section>
<section id="installing-datascience-packages---pytorch-and-jupyter" class="level3">
<h3 class="anchored" data-anchor-id="installing-datascience-packages---pytorch-and-jupyter">Installing datascience packages - pytorch and jupyter</h3>
<p>Since for fastai course, we are using pytorch. Let’s install pytorch based on <a href="https://pytorch.org/">official page instructions</a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/170853841-9ed4763c-4969-40fd-9db9-01b6f06e612e.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>One of the advantages of installing libraries like pytorch in Anaconda is that if you are using conda, it install all the packages and drivers for GPU setup as well. In a normal pip based installation, there are lot more steps required for installing correctly in GPU.</p>
</div>
</div>
<p><strong>Go ahead and install python packages in this manner, by just replacing conda with mamba.</strong></p>
<pre><code>mamba install pytorch torchvision torchaudio cpuonly -c pytorch</code></pre>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s always a good idea to google and find the correct conda packages before installation, as conda requires some specifications like setting the correct channel to install.</p>
</div>
</div>
<p><strong>Now let’s install <code>jupyter lab</code> to do our experiments quickly:</strong></p>
<pre><code>mamba install jupyterlab</code></pre>
<p>Then run the jupyter lab, with the following command:</p>
<pre><code>jupyter lab --no-browser</code></pre>
<p>This opens up jupyterlab in localhost:8888</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/170855155-67d3167c-e635-40a6-a0cb-bd12d6d81d0d.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
</section>
<section id="installing-packages-with-fastchan" class="level3">
<h3 class="anchored" data-anchor-id="installing-packages-with-fastchan">Installing packages with fastchan</h3>
<p>Even though Jeremy didn’t cover this topic during walk-thrus. I came to know about <code>fastchan</code> when I wanted to install <code>pytorch and huggingface transformers</code> in a gpu based system. What is fastchan and the problem it solves is covered by <a href="https://wandb.ai/wandb_fc/pytorch-image-models/reports/A-faster-way-to-get-working-and-up-to-date-conda-environments-using-fastchan---Vmlldzo2ODIzNzA">detailed blogpost</a> by the <a href="https://wandb.ai/aarora">Aman Arora</a>.</p>
<p>To install both <code>pytorch and huggingface transformers</code> in a GPU, I used the following command:</p>
<pre><code>mamba install pytorch transformers cudatoolkit=11.4 -c fastchan</code></pre>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>One of fastai students, during the start of lesson talked about the need of a quick setup, which just works as expected. One of biggest takeaways for me, personally is a quick and fastsetup to do my experiments in DataScience. Sometimes installing packages in data science can take hours of effort, and that’s why I really loved this setup.</p>
<p>Thanks to <a href="twitter.com/jeremyphoward/">Jeremy Howard</a> for creating this quick setup and for starting the project <a href="https://www.fast.ai/2021/07/15/fastconda/">fastchan</a>.</p>


</section>

 ]]></description>
  <category>fastaicourse</category>
  <category>terminal</category>
  <category>Python</category>
  <category>setup</category>
  <guid>https://kurianbenoy.com/posts/2022-05-28-fastai-walthrus1.html</guid>
  <pubDate>Sat, 28 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/24592806/170852543-17bdb268-7ace-43c6-b1a0-a2b5b0a9ac43.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Quickly trying out a NLP model for Kaggle Competition</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-05-23-nlpkagglecomp.html</link>
  <description><![CDATA[ 




<p>This is my attempt to see how well we can build a NLP model for <a href="https://www.kaggle.com/competitions/nlp-getting-started/overview">Natural Language Processing with Disaster Tweets</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/nlp_random.jpeg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">NLP random competition</figcaption><p></p>
</figure>
</div>
<p>According to competition you are required to :</p>
<blockquote class="blockquote">
<p>In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we’ve created a quick tutorial to get you up and running.</p>
</blockquote>
<section id="downloading-data" class="level2">
<h2 class="anchored" data-anchor-id="downloading-data">Downloading Data</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">creds <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">""</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb2-2"></span>
<span id="cb2-3">cred_path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">"~/.kaggle/kaggle.json"</span>).expanduser()</span>
<span id="cb2-4"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> cred_path.exists():</span>
<span id="cb2-5">    cred_path.parent.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-6">    cred_path.write_text(creds)</span>
<span id="cb2-7">    cred_path.chmod(<span class="bn" style="color: #AD0000;">0o600</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="op" style="color: #5E5E5E;">!</span> kaggle competitions download <span class="op" style="color: #5E5E5E;">-</span>c nlp<span class="op" style="color: #5E5E5E;">-</span>getting<span class="op" style="color: #5E5E5E;">-</span>started</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>nlp-getting-started.zip: Skipping, found more recently modified local copy (use --force to force download)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="op" style="color: #5E5E5E;">!</span> unzip nlp<span class="op" style="color: #5E5E5E;">-</span>getting<span class="op" style="color: #5E5E5E;">-</span>started.<span class="bu" style="color: null;">zip</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">df <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(<span class="st" style="color: #20794D;">"train.csv"</span>)</span>
<span id="cb7-2">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">df.describe(include<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"object"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>7552</td>
      <td>5080</td>
      <td>7613</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>221</td>
      <td>3341</td>
      <td>7503</td>
    </tr>
    <tr>
      <th>top</th>
      <td>fatalities</td>
      <td>USA</td>
      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>45</td>
      <td>104</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">df[<span class="st" style="color: #20794D;">"input"</span>] <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">"text"</span>]</span></code></pre></div>
</div>
</section>
<section id="tokenization" class="level2">
<h2 class="anchored" data-anchor-id="tokenization">Tokenization</h2>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> Dataset, DatasetDict</span>
<span id="cb10-2"></span>
<span id="cb10-3">ds <span class="op" style="color: #5E5E5E;">=</span> Dataset.from_pandas(df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">ds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>Dataset({
    features: ['id', 'keyword', 'location', 'text', 'target', 'input'],
    num_rows: 7613
})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">model_nm <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"microsoft/deberta-v3-small"</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForSequenceClassification, AutoTokenizer</span>
<span id="cb14-2"></span>
<span id="cb14-3">tokz <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(model_nm)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;">def</span> tok_func(x):</span>
<span id="cb15-2">    <span class="cf" style="color: #003B4F;">return</span> tokz(x[<span class="st" style="color: #20794D;">"input"</span>])</span>
<span id="cb15-3"></span>
<span id="cb15-4"></span>
<span id="cb15-5">tok_ds <span class="op" style="color: #5E5E5E;">=</span> ds.<span class="bu" style="color: null;">map</span>(tok_func, batched<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Parameter 'function'=&lt;function tok_func at 0x7f28da60b8b0&gt; of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fba50529948f4c4ab381839eebbba5d4","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;"># collapse_output</span></span>
<span id="cb17-2">row <span class="op" style="color: #5E5E5E;">=</span> tok_ds[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb17-3">row[<span class="st" style="color: #20794D;">"input"</span>], row[<span class="st" style="color: #20794D;">"input_ids"</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>('Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',
 [1,
  581,
  65453,
  281,
  262,
  18037,
  265,
  291,
  953,
  117831,
  903,
  4924,
  17018,
  43632,
  381,
  305,
  2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">tok_ds <span class="op" style="color: #5E5E5E;">=</span> tok_ds.rename_columns({<span class="st" style="color: #20794D;">"target"</span>: <span class="st" style="color: #20794D;">"labels"</span>})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">tok_ds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>Dataset({
    features: ['id', 'keyword', 'location', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],
    num_rows: 7613
})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;"># collapse_output</span></span>
<span id="cb22-2">tok_ds[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>{'id': 1,
 'keyword': None,
 'location': None,
 'text': 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',
 'labels': 1,
 'input': 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',
 'input_ids': [1,
  581,
  65453,
  281,
  262,
  18037,
  265,
  291,
  953,
  117831,
  903,
  4924,
  17018,
  43632,
  381,
  305,
  2],
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
</section>
<section id="validation-traning-testing" class="level2">
<h2 class="anchored" data-anchor-id="validation-traning-testing">Validation, Traning, Testing</h2>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">eval_df <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(<span class="st" style="color: #20794D;">"test.csv"</span>)</span>
<span id="cb24-2">eval_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just happened a terrible car crash</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Heard about #earthquake is different cities, s...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>there is a forest fire at spot pond, geese are...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Apocalypse lighting. #Spokane #wildfires</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">eval_df.describe(include<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"object"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3237</td>
      <td>2158</td>
      <td>3263</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>221</td>
      <td>1602</td>
      <td>3243</td>
    </tr>
    <tr>
      <th>top</th>
      <td>deluged</td>
      <td>New York</td>
      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>23</td>
      <td>38</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">model_dataset <span class="op" style="color: #5E5E5E;">=</span> tok_ds.train_test_split(<span class="fl" style="color: #AD0000;">0.25</span>, seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">34</span>)</span>
<span id="cb26-2">model_dataset</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['id', 'keyword', 'location', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 5709
    })
    test: Dataset({
        features: ['id', 'keyword', 'location', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1904
    })
})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">eval_df[<span class="st" style="color: #20794D;">"input"</span>] <span class="op" style="color: #5E5E5E;">=</span> eval_df[<span class="st" style="color: #20794D;">"text"</span>]</span>
<span id="cb28-2">eval_ds <span class="op" style="color: #5E5E5E;">=</span> Dataset.from_pandas(eval_df).<span class="bu" style="color: null;">map</span>(tok_func, batched<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4dfb22c0225740138052bbef2b6de946","version_major":2,"version_minor":0}
</script>
</div>
</div>
</section>
<section id="training-models" class="level2">
<h2 class="anchored" data-anchor-id="training-models">Training Models</h2>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> TrainingArguments, Trainer, DataCollatorWithPadding</span></code></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">bs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">128</span></span>
<span id="cb30-2">epochs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">data_collator <span class="op" style="color: #5E5E5E;">=</span> DataCollatorWithPadding(tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokz)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">training_args <span class="op" style="color: #5E5E5E;">=</span> TrainingArguments(<span class="st" style="color: #20794D;">"test-trainer"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias']
- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">trainer <span class="op" style="color: #5E5E5E;">=</span> Trainer(</span>
<span id="cb35-2">    model,</span>
<span id="cb35-3">    training_args,</span>
<span id="cb35-4">    train_dataset<span class="op" style="color: #5E5E5E;">=</span>model_dataset[<span class="st" style="color: #20794D;">"train"</span>],</span>
<span id="cb35-5">    eval_dataset<span class="op" style="color: #5E5E5E;">=</span>model_dataset[<span class="st" style="color: #20794D;">"test"</span>],</span>
<span id="cb35-6">    data_collator<span class="op" style="color: #5E5E5E;">=</span>data_collator,</span>
<span id="cb35-7">    tokenizer<span class="op" style="color: #5E5E5E;">=</span>tokz,</span>
<span id="cb35-8">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: location, text, id, input, keyword. If location, text, id, input, keyword are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 5709
  Num Epochs = 3
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed &amp; accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 2142</code></pre>
</div>
<div class="cell-output cell-output-display">


    <div>
      
      <progress value="2142" max="2142" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [2142/2142 03:04, Epoch 3/3]
    </div>
    <table class="dataframe table table-sm table-striped">
  <thead>
 <tr>
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>500</td>
      <td>0.491000</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>0.406300</td>
    </tr>
    <tr>
      <td>1500</td>
      <td>0.323600</td>
    </tr>
    <tr>
      <td>2000</td>
      <td>0.265800</td>
    </tr>
  </tbody>
</table><p>
</p></div>
<div class="cell-output cell-output-stderr">
<pre><code>Saving model checkpoint to test-trainer/checkpoint-500
Configuration saved in test-trainer/checkpoint-500/config.json
Model weights saved in test-trainer/checkpoint-500/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-500/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-500/special_tokens_map.json
Saving model checkpoint to test-trainer/checkpoint-1000
Configuration saved in test-trainer/checkpoint-1000/config.json
Model weights saved in test-trainer/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-1000/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-1000/special_tokens_map.json
Saving model checkpoint to test-trainer/checkpoint-1500
Configuration saved in test-trainer/checkpoint-1500/config.json
Model weights saved in test-trainer/checkpoint-1500/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-1500/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-1500/special_tokens_map.json
Saving model checkpoint to test-trainer/checkpoint-2000
Configuration saved in test-trainer/checkpoint-2000/config.json
Model weights saved in test-trainer/checkpoint-2000/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-2000/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-2000/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)

</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>TrainOutput(global_step=2142, training_loss=0.3674473464210717, metrics={'train_runtime': 184.9649, 'train_samples_per_second': 92.596, 'train_steps_per_second': 11.581, 'total_flos': 222000241127892.0, 'train_loss': 0.3674473464210717, 'epoch': 3.0})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">preds <span class="op" style="color: #5E5E5E;">=</span> trainer.predict(eval_ds).predictions.astype(<span class="bu" style="color: null;">float</span>)</span>
<span id="cb40-2">preds</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: location, text, id, input, keyword. If location, text, id, input, keyword are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Prediction *****
  Num examples = 3263
  Batch size = 8</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="408" max="408" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [408/408 00:05]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>array([[-2.78964901,  3.02934074],
       [-2.77013326,  3.00309706],
       [-2.74731326,  2.972296  ],
       ...,
       [-2.8556931 ,  3.08512282],
       [-2.7085278 ,  2.88177919],
       [-2.7887187 ,  3.00746083]])</code></pre>
</div>
</div>
<pre><code>1. Just happened a terrible car crash
2. Heard about #earthquake is different cities, stay safe everyone.
3. There is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all.</code></pre>
<p>The above are samples from our Test set, looks all disaster tweets which seems to have been predicted correctly. This is my first iteration in which I tried mostly editing from <a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">Jeremy’s notebook on getting started with NLP</a> in about 1 hour.</p>


</section>

 ]]></description>
  <category>kaggle</category>
  <category>fastaicourse</category>
  <category>NLP</category>
  <category>huggingface</category>
  <guid>https://kurianbenoy.com/posts/2022-05-23-nlpkagglecomp.html</guid>
  <pubDate>Mon, 23 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/nlp_random.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Lesson 4</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-05-19-fastai-54.html</link>
  <description><![CDATA[ 




<section id="introduction-to-lesson" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-lesson">Introduction to lesson</h2>
<p>Almost 100+ people watched live virtually and lesson were held live in front of a bunch of audience in University of Queensland. <code>Prof. John Williams</code> opened session by telling about filling a separate form, for people interested in attending the hackathon organized end of the course.</p>
<p>During the start <code>Jeremy</code> mentioned he would love folks to organize a online hackathon by community for folks attending remotely as well. Yet right now Jeremy and John doesn’t have the capacity to organize one.</p>
<blockquote class="blockquote">
<p>Todays lesson is something a lot of regulars of fast.ai course are excited about as it covers really new material on transformers.</p>
</blockquote>
</section>
<section id="why-using-a-different-framework---transformers" class="level2">
<h2 class="anchored" data-anchor-id="why-using-a-different-framework---transformers">Why using a different framework - Transformers</h2>
<p>Since this course is fastai, it may feel a bit weird when we are today going to use a different library called <code>transformers</code>.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>As practitioners, it’s important for us to learn more than one framework.</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Differences with fastai and transformers:</p>
</div>
</div>
<ol type="1">
<li><p><code>Transformers</code> provide lot of state of art models, and the <code>Tokenizers</code> library build with Rust is really good at the moment.</p></li>
<li><p>It’s good to get exposure to a library which is not so layered like <code>fast.ai</code>, which is reason that makes it super useful for beginners.</p></li>
</ol>
</section>
<section id="ulmfit-architecture" class="level2">
<h2 class="anchored" data-anchor-id="ulmfit-architecture">ULMFiT architecture</h2>
<p>The idea of fine-tuning a pre-trained NLP model in this way was pioneered by an algorithm called <a href="https://arxiv.org/abs/1801.06146">Universal Language Model Fine-tuning for Text Classification aka ULMFiT</a> which was first presented actually in a fastai course.</p>
<section id="whats-a-pretrained-model-and-what-is-finetuning" class="level3">
<h3 class="anchored" data-anchor-id="whats-a-pretrained-model-and-what-is-finetuning"><strong>What’s a pretrained model and what is finetuning?</strong></h3>
<p>Consider finetuning, as tweaking functions in such a way when if you are already some values of a, b lever are good and optimal for a particular function. Then tweaking value of c is easier right?</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A pre-trained model is a bunch of parameters that have already been fitted, where some of them we’re already pretty confident of what they should be, and some of them we really have no idea at all. And so fine-tuning is the process of taking those ones we have no idea what they should be at all, and trying to get them right, and then moving the other ones a little bit.</p>
</div>
</div>
</section>
<section id="steps-in-ulmfit" class="level3">
<h3 class="anchored" data-anchor-id="steps-in-ulmfit">Steps in ULMFiT</h3>
<p><strong>ULMFiT archtecture consits of three steps:</strong></p>
<ul>
<li>Training a language models with general dataset like wikipedia. So it gets so good in predicting next words. Now in <code>transformers</code> one big difference compared to <code>ULMFiT</code> is we use masking instead of predicting next word</li>
<li>IMDB lnagage build a language model, build on top of LM for wikipedia</li>
<li>In three step, is where model classifier comes and based on this label sentences as postive, negative etc.</li>
</ul>
</section>
</section>
<section id="fundamental-libraries-in-ml" class="level2">
<h2 class="anchored" data-anchor-id="fundamental-libraries-in-ml">Fundamental libraries in ML</h2>
<p>Four fundamental libraries you always need in datascience are:</p>
<ol type="1">
<li>NumPy</li>
<li>Pandas</li>
<li>matplotlib</li>
<li>Pytorch</li>
</ol>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>It looks pretty cool, if you build the state of art stuff. Yet if you don’t know fundamentals, you will encounter trouble. So i will recommend you to get started by first complete reading the <a href="https://github.com/fastai/fastbook">Deep Learning for Coders book</a>, then the Macinskey book on Python for Data Analysis, 3E which is free <a href="https://wesmckinney.com/book/">completely online</a>.</p>
</div>
</div>
</section>
<section id="nlp-notebook-tokenization" class="level2">
<h2 class="anchored" data-anchor-id="nlp-notebook-tokenization">NLP notebook tokenization</h2>
<p><a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">Getting started with NLP for absolute beginners</a></p>
<p>It’s been only a year or two since NLP has been getting good results, for computer vision things are being optimistic for a long time now.</p>
<ul>
<li>Tokenization, is converting the text blurbs into a set of small tokens.</li>
<li>Numericalization is the process of converting these tokens to numbers for models to train</li>
</ul>
<p>We used <code>deberta-v3</code> as base model as some models are always found to give good results. Yet there are lot of pretrained models available in public which can just found by searching like Patent for patent models in <a href="https://huggingface.co/models">Huggingface models hub</a>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>(Jeremy) For under 2000 words use transformers approach, for more than 2000 words per sequence it would a good idea to try ULMFiT also along with transformers.</p>
</div>
</div>
</section>
<section id="test-validation-training-dataset" class="level2">
<h2 class="anchored" data-anchor-id="test-validation-training-dataset">Test, Validation, Training Dataset</h2>
<p>The most important concept in ML is creating:</p>
<ol type="1">
<li>Test set</li>
<li>Validation set</li>
<li>Training set</li>
</ol>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>(Jeremy) Kaggle competitions are really a good way to create a good validation set… Beginners generally tend to overfit … In real world outside of kaggle you often won’t know it’s overfit. You just destroy value for organizations silently… You really don’t get it untill you screw it up a few times.</p>
</div>
</div>
<p><a href="https://www.fast.ai/2017/11/13/validation-sets/">How (and why) to create a good validation set</a></p>
<p><code>Test Set</code> is a separate data which is not used by ML model for learning. It’s kept as separate hold out dataset for further testing.</p>
</section>
<section id="understanding-metrics" class="level2">
<h2 class="anchored" data-anchor-id="understanding-metrics">Understanding metrics</h2>
<p>With the validation set, we are measuring some metrics like accuracy which tell how good our ML model is. In Kaggle for every competition there is a metric available to optimize based on.</p>
<section id="why-metrics-is-different-from-loss" class="level3">
<h3 class="anchored" data-anchor-id="why-metrics-is-different-from-loss">Why metrics is different from loss?</h3>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>(Jeremy) If you were taking something like accuracy as loss function for classifying cats vs dogs. Then it may go on finding gradient and optimizing, yet at some point if inacurate cats are still labelled as dogs by models. Evaluating with accuracy as loss functions will be same. We can’t proceed further with such a loss function, that’s why we use functions like MSE for loss usually.</p>
</div>
</div>
<p>Metrics in real world is ofcourse a big issue, so with one ML model which claims to have got good results in a particular metrics when implemented has caused issues in real world which affect lot of people.</p>
<p>So check the article written by Rachael Thomas on <a href="https://www.fast.ai/2019/09/24/metrics/">The problem with metrics is a big problem for AI</a>.</p>
</section>
</section>
<section id="pearson-coefficient" class="level2">
<h2 class="anchored" data-anchor-id="pearson-coefficient">Pearson Coefficient</h2>
<p>Understanding metrics is very key, especially in Kaggle competitons. According to this Kaggle competition page: “Submissions are evaluated on the Pearson correlation coefficient between the predicted and actual similarity scores.”</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>“This coefficient is usually abbreviated using the single letter r. It is the most widely used measure of the degree of relationship between two variables. r can vary between -1, which means perfect inverse correlation, and +1, which means perfect positive correlation.”</p>
</div>
</div>
<p>[source: Kaggle Notebook]((https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners)</p>
<p>Jeremy’s way of teaching this concept was explaining with code for us to get intuition</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> sklearn.datasets <span class="im" style="color: #00769E;">import</span> fetch_california_housing</span>
<span id="cb1-4"></span>
<span id="cb1-5">df <span class="op" style="color: #5E5E5E;">=</span> fetch_california_housing(as_frame<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb1-6">df <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">"data"</span>].join(df[<span class="st" style="color: #20794D;">"target"</span>]).sample(<span class="dv" style="color: #AD0000;">1000</span>, random_state<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">52</span>)</span>
<span id="cb1-7">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>MedInc</th>
      <th>HouseAge</th>
      <th>AveRooms</th>
      <th>AveBedrms</th>
      <th>Population</th>
      <th>AveOccup</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>MedHouseVal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7506</th>
      <td>3.0550</td>
      <td>37.0</td>
      <td>5.152778</td>
      <td>1.048611</td>
      <td>729.0</td>
      <td>5.062500</td>
      <td>33.92</td>
      <td>-118.28</td>
      <td>1.054</td>
    </tr>
    <tr>
      <th>4720</th>
      <td>3.0862</td>
      <td>35.0</td>
      <td>4.697897</td>
      <td>1.055449</td>
      <td>1159.0</td>
      <td>2.216061</td>
      <td>34.05</td>
      <td>-118.37</td>
      <td>3.453</td>
    </tr>
    <tr>
      <th>12888</th>
      <td>2.5556</td>
      <td>24.0</td>
      <td>4.864905</td>
      <td>1.129222</td>
      <td>1631.0</td>
      <td>2.395007</td>
      <td>38.66</td>
      <td>-121.35</td>
      <td>1.057</td>
    </tr>
    <tr>
      <th>13344</th>
      <td>3.0057</td>
      <td>32.0</td>
      <td>4.212687</td>
      <td>0.936567</td>
      <td>1378.0</td>
      <td>5.141791</td>
      <td>34.05</td>
      <td>-117.64</td>
      <td>0.969</td>
    </tr>
    <tr>
      <th>7173</th>
      <td>1.9083</td>
      <td>42.0</td>
      <td>3.888554</td>
      <td>1.039157</td>
      <td>1535.0</td>
      <td>4.623494</td>
      <td>34.05</td>
      <td>-118.19</td>
      <td>1.192</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, suppress<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;"># to get correlation coefficent between every row of matrix with every other matrix</span></span>
<span id="cb2-4">np.corrcoef(df, rowvar<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>array([[ 1.  , -0.12,  0.43, -0.08,  0.01, -0.07, -0.12,  0.04,  0.68],
       [-0.12,  1.  , -0.17, -0.06, -0.31,  0.  ,  0.03, -0.13,  0.12],
       [ 0.43, -0.17,  1.  ,  0.76, -0.09, -0.07,  0.12, -0.03,  0.21],
       [-0.08, -0.06,  0.76,  1.  , -0.08, -0.07,  0.09,  0.  , -0.04],
       [ 0.01, -0.31, -0.09, -0.08,  1.  ,  0.16, -0.15,  0.13,  0.  ],
       [-0.07,  0.  , -0.07, -0.07,  0.16,  1.  , -0.16,  0.17, -0.27],
       [-0.12,  0.03,  0.12,  0.09, -0.15, -0.16,  1.  , -0.93, -0.16],
       [ 0.04, -0.13, -0.03,  0.  ,  0.13,  0.17, -0.93,  1.  , -0.03],
       [ 0.68,  0.12,  0.21, -0.04,  0.  , -0.27, -0.16, -0.03,  1.  ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">def</span> relation_matrix(x, y):</span>
<span id="cb4-2">    <span class="cf" style="color: #003B4F;">return</span> np.corrcoef(x, y)[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">np.corrcoef(df.HouseAge, df.MedHouseVal)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([[1.  , 0.12],
       [0.12, 1.  ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">relation_matrix(df.HouseAge, df.MedHouseVal)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>0.1165853555067797</code></pre>
</div>
</div>
<p>When I ran through this code I was thinking about how [0,1] element in this corelation matrix is 0.12, when value of relation_matrix returns something as 0.11658535. I asked this simple doubt in the forum and after a while, I got answer from one of the <a href="https://forums.fast.ai/u/n-e-w/summary">course TAs Nick(n-e-w)</a>.</p>
<!-- ![image](https://user-images.githubusercontent.com/24592806/169845219-4915b78d-8be4-4972-bd37-40476d1b6f4c.png) -->
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is one of the best things IMO about taking the course live, rather than attending online. There is lot more activity, and you even get some of your questions answered by lot of experts and even Jeremy too.</p>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">def</span> show_corr(df, a, b):</span>
<span id="cb9-2">    x, y <span class="op" style="color: #5E5E5E;">=</span> df[a], df[b]</span>
<span id="cb9-3">    plt.scatter(x, y, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>, s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>)</span>
<span id="cb9-4">    plt.title(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>a<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> vs </span><span class="sc" style="color: #5E5E5E;">{</span>b<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">; r: </span><span class="sc" style="color: #5E5E5E;">{</span>relation_matrix(x, y)<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">show_corr(df, <span class="st" style="color: #20794D;">"MedInc"</span>, <span class="st" style="color: #20794D;">"AveRooms"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-19-fastai-54_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">show_corr(df[df.AveRooms <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">15</span>], <span class="st" style="color: #20794D;">"MedInc"</span>, <span class="st" style="color: #20794D;">"AveRooms"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-19-fastai-54_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>If you look at two graphs, once we removed the Average room &lt;15. We notice a huge difference in r value which denotes the <code>pearson coefficent</code> are sensitive to outliers. Thus we got an intutive feeling of what the metrics is doing, and how it’s being affected by outliers. Even if you make small error in some of predictions you will notice a hugh bump in leaderboard which affects your position, as pearson correlation penalizes heavily for wrong predictions.</p>
<p>Next week, will be the fifth lesson and the last one for month of May. The course will resume again after a three weeks breaks during month of June when monsoon season delights us here in Kerala with rain and everyone else with more fastai.</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022-05-19-fastai-54.html</guid>
  <pubDate>Thu, 19 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/monsoon.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Lesson 3</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-05-10-fastai-53.html</link>
  <description><![CDATA[ 




<section id="lesson-setup" class="level2">
<h2 class="anchored" data-anchor-id="lesson-setup">Lesson Setup</h2>
<p>There was a minor delay in streaming the lessons today, as today the sessions where being conducted in-person by Jeremy at University of Queensland. There were 130 people watching live in youtube.</p>
<p>Jeremy started the lesson by saying that usually lesson 1 and 2 are easy for everyone, while it’s usually from lesson 3 things start getting hard. There is also a lesson 0 on how to do fast.ai?</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/gGxe2mN3kAg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>I had the previously written about <a href="https://kurianbenoy.com/2021-06-16-fastgroup-1/">fastai lesson 0</a>, where Jeremy mentioned about <strong>How to do fast.ai lesson</strong> through the following five steps:</p>
<ol type="1">
<li>Watching lecture/book (watching the video first without trying anything)</li>
<li>Running notebook and experimentation (going through lesson notebooks and experimenting stuff)</li>
<li>Reproduce results (try with fastai clean notebook version, see if you are able to understand and do things on your own)</li>
<li>Working on a different dataset (play with a different dataset, paraticipate in kaggle …)</li>
</ol>
<p>Always studying done with other people is the best way to retain your knowledge. So it’s great to participate in study groups like <a href="https://www.meetup.com/delft-fast-ai-study-group/">Delft-fastai sessions</a>.</p>
<p>This week, Jeremy showcased the various students projects based on those who got highest number of votes in <a href="https://forums.fast.ai/t/share-your-work-here/96015">share your work here topic in fastai forums</a>. My work also got featured 🙂 in the lesson.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/https:/user-images.githubusercontent.com/24592806/168640845-07859116-bf6b-48c7-af61-5ff8a65dc2fb.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
</section>
<section id="dogs-vs-cat-notebooks--which-image-models-are-the-best" class="level2">
<h2 class="anchored" data-anchor-id="dogs-vs-cat-notebooks--which-image-models-are-the-best">Dogs vs Cat notebooks- which image models are the best?</h2>
<p>Today Jeremy featured, paperspace gradient platform. He has been using it for his development and it’s totally amazing. He got something done by them to update fastbook regularly.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In lesson2 the main things, is not about taking a particular platform and deploying them through javascript websites or online applications. But the key thing is to undestand the concept. There are two pieces:</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>The Training piece by end of which you get a model.pkl file. Once you got that (train.ipynb)</li>
</ol>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="2" type="1">
<li>Then part which takes inputs, spits out output … this separate step is deploying (app.ipynb)</li>
</ol>
</div>
</div>
<p>Finding good image models, by <a href="https://www.kaggle.com/code/jhoward/which-image-models-are-best/">baselines results along with inference time</a> will help us choose good architecture. He tried levit_models, which didn’t work really great.</p>
<p>From [13:52] in the video, he experiments with convnext tiny models from timm library. It got really good accuracy with almost 0.05 loss. At the moment for computer vision there are lot of good architectures, which beats resnets really well. In this case for predicting 37 breeds of dogs we can find categories in dataset using vocab of dataloaders in model.</p>
<pre><code>labels = model.dls.vocab</code></pre>
<p>It’s very important to understand what’s in a model? Using <code>get_submodule</code> in pytorch we can look at the various neural networks, what is their input and ouput and each layers. [21:24]</p>
<p>Let’s explore the architecture of a <a href="https://huggingface.co/Helsinki-NLP/opus-mt-mul-en/tree/main">translation model which translates from their target form to english</a>.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForSeq2SeqLM</span>
<span id="cb2-2"></span>
<span id="cb2-3"></span>
<span id="cb2-4">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForSeq2SeqLM.from_pretrained(<span class="st" style="color: #20794D;">"Helsinki-NLP/opus-mt-mul-en"</span>)</span></code></pre></div>
</div>
<p><strong>Looking at model architecture</strong></p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># collapse_output</span></span>
<span id="cb3-2">model</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>MarianMTModel(
  (model): MarianModel(
    (shared): Embedding(64172, 512, padding_idx=64171)
    (encoder): MarianEncoder(
      (embed_tokens): Embedding(64172, 512, padding_idx=64171)
      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)
      (layers): ModuleList(
        (0): MarianEncoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (activation_fn): SiLUActivation()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): MarianEncoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (activation_fn): SiLUActivation()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): MarianEncoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (activation_fn): SiLUActivation()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): MarianEncoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (activation_fn): SiLUActivation()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): MarianEncoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (activation_fn): SiLUActivation()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): MarianEncoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (activation_fn): SiLUActivation()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (decoder): MarianDecoder(
      (embed_tokens): Embedding(64172, 512, padding_idx=64171)
      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)
      (layers): ModuleList(
        (0): MarianDecoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (activation_fn): SiLUActivation()
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): MarianDecoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (activation_fn): SiLUActivation()
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): MarianDecoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (activation_fn): SiLUActivation()
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): MarianDecoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (activation_fn): SiLUActivation()
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): MarianDecoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (activation_fn): SiLUActivation()
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): MarianDecoderLayer(
          (self_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (activation_fn): SiLUActivation()
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): MarianAttention(
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (lm_head): Linear(in_features=512, out_features=64172, bias=False)
)</code></pre>
</div>
</div>
<p><strong>Looking at layer 1 <code>self_attn_layer_norm</code></strong></p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># collapse_output</span></span>
<span id="cb5-2">attention_layer <span class="op" style="color: #5E5E5E;">=</span> model.get_submodule(<span class="st" style="color: #20794D;">"model.encoder.layers.0.self_attn_layer_norm"</span>)</span>
<span id="cb5-3"><span class="bu" style="color: null;">list</span>(attention_layer.parameters())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>[Parameter containing:
 tensor([0.3865, 0.6348, 0.6938, 0.7140, 1.1017, 1.0888, 0.7801, 0.7572, 0.7402,
         0.5655, 0.5940, 0.7477, 0.6920, 0.6781, 0.5128, 0.5862, 0.7173, 0.5140,
         0.5940, 0.5998, 0.5002, 0.5931, 0.3720, 0.8686, 0.6557, 0.7436, 0.7564,
         0.5402, 0.6773, 0.6831, 0.7060, 0.8484, 0.8874, 0.9380, 0.7360, 0.6073,
         0.7911, 0.6247, 0.6225, 0.7281, 0.7470, 0.8066, 0.6336, 0.5607, 0.6914,
         0.7630, 1.0365, 0.5133, 0.8260, 0.9167, 0.6362, 0.6375, 0.7296, 1.0838,
         0.7916, 0.8332, 1.0474, 0.9655, 0.9446, 0.8361, 0.9928, 0.7550, 0.8335,
         0.9597, 0.3449, 0.6119, 0.9266, 0.8208, 0.7301, 0.9969, 0.4639, 0.6579,
         1.0493, 0.9808, 0.9181, 0.7736, 0.7346, 0.9642, 1.2211, 1.3974, 1.3712,
         1.4836, 1.2050, 1.1015, 1.3986, 1.4113, 1.3771, 1.5623, 1.5389, 1.0727,
         1.5310, 1.3641, 1.5365, 1.4774, 1.4893, 1.4168, 1.5904, 1.5720, 1.3812,
         1.5914, 1.5096, 1.2807, 0.1877, 1.3947, 1.6565, 1.2572, 1.7532, 1.7136,
         1.5001, 1.7059, 1.6033, 1.5448, 1.5357, 1.5565, 1.5366, 1.3784, 1.6677,
         1.6570, 1.6885, 1.6925, 1.5795, 1.6837, 1.7601, 1.6240, 1.8309, 1.6668,
         1.7021, 1.7827, 1.8194, 1.8531, 1.9633, 1.7518, 1.9518, 1.8846, 2.0106,
         1.9608, 1.8964, 1.9245, 0.0996, 1.8191, 1.8534, 1.7096, 1.7831, 0.1533,
         2.0808, 1.8960, 2.1153, 1.8570, 2.0739, 2.1022, 2.0319, 1.3613, 1.9232,
         2.1441, 2.0704, 2.1557, 2.1526, 2.2401, 2.0910, 1.8356, 2.1069, 1.7451,
         0.1487, 2.1800, 2.1589, 2.0273, 0.1957, 2.2119, 2.1048, 1.4881, 1.7567,
         2.2064, 2.1753, 2.2111, 2.1907, 2.1288, 1.8702, 2.1218, 2.1744, 2.2581,
         2.2565, 2.1913, 2.0952, 2.2975, 1.9853, 1.9851, 2.1758, 2.1094, 2.0666,
         2.0578, 1.7592, 2.1246, 2.1616, 2.1781, 2.1823, 2.4415, 2.0122, 1.9394,
         2.1719, 2.1455, 2.3547, 1.0006, 2.1169, 1.6765, 2.2037, 2.1994, 2.2939,
         2.1233, 2.1261, 2.1542, 2.1301, 2.0364, 2.2253, 2.1832, 2.2080, 2.0617,
         2.2758, 2.1373, 2.2573, 2.0367, 2.2055, 2.2531, 1.9362, 2.1346, 2.3110,
         1.8304, 2.2435, 2.0757, 2.1346, 2.0784, 2.2972, 1.9981, 2.2595, 2.3887,
         2.3544, 2.1077, 2.2306, 2.2086, 1.6925, 2.1120, 2.2147, 2.2832, 2.1880,
         2.0909, 2.1869, 2.3249, 2.2425, 2.2322, 2.2695, 2.3331, 0.1346, 0.2001,
         1.9555, 2.0758, 2.0961, 2.2567, 0.4750, 0.5842, 0.7058, 0.7570, 0.9744,
         1.0287, 0.9519, 0.8539, 0.6670, 0.0686, 0.5976, 0.6930, 0.7278, 0.5867,
         0.5813, 0.7097, 0.5000, 0.6474, 0.5425, 0.5578, 0.5803, 0.6271, 0.6408,
         0.0821, 0.6325, 0.8464, 0.9188, 0.7320, 0.1289, 0.1581, 0.7063, 0.8729,
         0.7022, 0.8077, 0.7002, 0.6772, 0.5950, 0.6649, 0.7646, 0.4813, 0.7579,
         0.5831, 0.4914, 0.7263, 0.5337, 0.5253, 0.7073, 0.3907, 0.7041, 0.6702,
         0.4874, 0.5163, 0.2580, 0.6476, 0.5674, 0.4555, 0.5476, 0.5859, 0.6279,
         0.4089, 0.5099, 0.5995, 0.5399, 0.7964, 0.4036, 0.6919, 0.6908, 0.5914,
         0.5730, 0.6122, 0.4277, 0.4590, 0.7666, 0.9008, 0.3882, 0.1257, 0.6154,
         0.6206, 0.1595, 0.6308, 0.4924, 0.5181, 0.5823, 0.2778, 0.8624, 0.2661,
         0.7717, 0.9022, 1.2887, 1.2015, 0.6473, 0.4860, 0.4110, 0.4339, 0.5128,
         1.1724, 1.1852, 1.2922, 1.0709, 1.2392, 1.2499, 1.4100, 1.3137, 0.8466,
         1.4344, 1.4693, 0.6968, 0.1751, 0.1710, 0.1834, 1.4736, 1.6201, 1.3277,
         1.6475, 1.4915, 1.5697, 1.4164, 1.7855, 0.0784, 1.7240, 1.5680, 1.7145,
         1.9040, 1.7964, 1.9526, 1.9328, 2.0737, 1.9253, 1.7730, 2.2707, 2.0602,
         0.4566, 0.5279, 2.1403, 2.0589, 2.0557, 2.1391, 2.1761, 1.8147, 2.0583,
         1.8788, 2.0470, 2.0793, 2.0560, 2.2968, 0.2280, 2.2384, 0.1449, 2.3148,
         2.2568, 2.1043, 2.2506, 0.1906, 2.1942, 2.3548, 2.2405, 2.1008, 2.2179,
         2.2754, 0.6110, 0.2974, 1.9307, 2.1931, 2.0484, 2.0105, 2.1261, 2.0659,
         2.1462, 2.1739, 1.9466, 2.4105, 2.2565, 2.0342, 2.1688, 0.2608, 2.0383,
         2.0664, 1.9995, 2.1393, 2.2680, 2.0550, 2.2346, 1.9870, 2.0796, 1.9112,
         1.2930, 2.2390, 2.1678, 0.1801, 2.0002, 1.6783, 2.0918, 2.3177, 1.8342,
         1.9244, 1.9471, 2.2717, 2.1227, 2.2932, 2.3473, 1.7774, 2.0945, 2.3712,
         2.1550, 2.0802, 0.1087, 2.2277, 1.9290, 2.2212, 2.0705, 1.8797, 2.1542,
         0.3608, 2.1922, 2.1362, 2.1825, 1.9593, 2.1429, 0.2623, 1.6499, 2.0807,
         2.0261, 2.1480, 1.9283, 0.1497, 2.1901, 2.0398, 2.0140, 2.5195, 2.0685,
         1.4206, 2.0745, 2.2225, 0.1621, 2.2012, 0.4932, 2.0481, 2.1097, 2.3599,
         0.4743, 1.9034, 2.2135, 2.0947, 2.1751, 1.7660, 2.4012, 2.1536, 1.9608,
         2.1268, 1.9698, 2.2014, 2.3058, 2.1618, 1.8719, 1.9626, 2.2343],
        requires_grad=True),
 Parameter containing:
 tensor([ 7.7839e-02,  1.4282e-01, -6.7494e-02,  6.3598e-02, -1.2071e-01,
          7.2978e-02, -1.3550e-01,  3.5607e-02, -4.4458e-02, -4.4257e-03,
         -3.3140e-01, -8.8216e-02,  2.0695e-01, -1.7521e-01, -7.0075e-02,
         -2.3476e-01, -3.5785e-01, -4.3914e-01,  1.4167e-01, -9.0072e-02,
         -1.6590e-01, -2.4325e-02, -9.6055e-02, -3.2896e-01,  1.2258e-02,
         -1.0973e-03,  2.2662e-01, -1.3086e-02, -2.1918e-01, -4.5178e-02,
         -1.9418e-01, -1.8878e-02, -1.3459e-02, -2.9698e-01, -3.9941e-02,
         -9.4998e-02, -1.9507e-01, -4.1943e-02,  1.6590e-01, -1.1282e-01,
          1.1039e-01,  2.5711e-02, -1.5641e-01,  5.5295e-02, -1.1544e-01,
         -1.7157e-01, -2.8929e-01,  2.3132e-01, -2.6698e-01, -2.9870e-02,
         -1.4797e-02, -1.4169e-01, -4.8199e-03,  1.4835e-02, -8.9909e-02,
         -4.6198e-02, -2.8071e-01, -4.3290e-01, -1.6699e-01, -2.0422e-01,
         -5.8818e-03, -2.2520e-01,  6.2375e-03,  3.9504e-02,  7.5439e-02,
         -1.4287e-01, -5.1881e-01, -5.5721e-02, -5.5866e-02, -5.3829e-01,
         -1.4044e-02, -9.2953e-02, -1.1587e-01, -3.8476e-02, -2.5480e-01,
         -5.7539e-02, -2.8871e-01,  3.5020e-02, -3.1672e-02, -5.8393e-02,
         -3.2713e-01, -1.8932e-01,  8.0913e-02, -4.6087e-01, -6.5291e-02,
         -4.0539e-01,  6.4874e-02, -1.7552e-01,  4.5883e-02,  9.9371e-03,
          1.4575e-02, -1.4779e-01,  3.0300e-01, -7.1591e-02, -3.0603e-02,
         -5.1550e-02,  3.3196e-01, -2.6409e-01, -1.0252e-01, -9.0839e-02,
         -6.5229e-02,  4.6278e-03,  6.9909e-01, -3.8764e-01, -1.8178e-01,
         -1.6395e-01, -4.2978e-01, -9.3517e-02, -2.7543e-02, -1.2259e-01,
         -2.8473e-01,  2.5956e-01, -2.6014e-01,  5.4886e-02, -2.7227e-02,
         -1.3363e-01, -1.5168e-01,  8.5377e-02,  2.9195e-01,  2.1162e-02,
         -3.9784e-02,  4.4097e-02,  9.6993e-02,  1.4139e-01,  2.4818e-01,
          1.8267e-02, -1.1592e-01,  1.0816e-01,  7.5200e-02, -1.3003e-01,
         -8.0244e-03,  5.8670e-02, -3.7428e-01,  2.2588e-01, -5.0269e-01,
         -2.3895e-01,  8.2600e-02, -6.8347e-02, -1.0482e+00, -1.3551e-01,
          1.1412e-02, -2.1185e-01, -2.4042e-01,  2.4737e-02, -2.5176e-01,
          1.5020e-01, -2.3560e-01,  1.1241e-01, -6.4413e-02, -3.5118e-01,
         -1.2333e-01,  1.9045e-01,  4.3384e-02, -2.4544e-01, -4.2071e-01,
         -7.8986e-02, -4.2295e-02,  4.0794e-01, -3.2176e-01, -5.9337e-01,
         -6.2764e-02,  1.0759e-01, -4.0607e-01, -1.3816e-01, -3.3327e-01,
         -2.0288e-01, -3.6235e-01, -4.0601e-01, -3.3251e-01,  1.0679e-01,
         -3.2651e-01, -4.5523e-01,  9.8463e-03, -1.7090e-01,  5.6157e-02,
         -2.0125e-01, -1.0815e-01, -1.1430e-01, -4.0327e-02, -3.9167e-01,
         -3.6428e-01, -4.4570e-01, -8.9959e-02, -4.9760e-01, -1.0579e-01,
          1.3707e-01, -7.0252e-02,  2.7966e-02, -2.4773e-01, -5.1971e-04,
          8.3816e-02,  2.1685e-02, -6.9780e-01,  2.2206e-02,  3.3752e-01,
         -3.2891e-01, -7.8279e-02,  3.3331e-03, -1.5812e-01, -7.3529e-02,
         -2.4885e-01,  7.1563e-03, -1.0669e-01, -9.1697e-02,  3.7219e-02,
          2.2590e-01, -3.7476e-01,  8.3716e-02,  5.5841e-02, -3.0678e-01,
         -3.4485e-01, -4.4003e-01,  1.9830e-01, -4.7639e-01, -6.4421e-02,
         -2.7313e-01, -1.4385e-01, -1.4548e-01, -3.6821e-01,  2.6972e-01,
         -3.0483e-01,  4.1683e-02, -2.3375e-02, -2.3032e-01, -4.5438e-01,
         -2.6145e-01, -2.2000e-01, -5.7517e-02,  4.7594e-02, -9.9610e-03,
         -4.2952e-01,  1.8124e-01, -1.1407e-01, -2.7262e-01, -1.1815e-01,
         -2.3155e-01, -4.2597e-01, -4.4960e-01, -1.8752e-01, -3.0844e-01,
          3.5617e-02, -3.7852e-01, -3.3136e-01, -1.9491e-01, -2.1862e-01,
         -3.3167e-01,  2.6676e-01, -1.9840e-01, -3.3605e-01, -1.6330e-01,
         -6.2717e-02, -8.3715e-01, -2.5243e-01, -1.3302e-01, -3.6257e-01,
          5.8300e-01, -1.1160e-01, -1.1229e-01, -4.1968e-01, -1.0799e-01,
         -1.9890e-01, -6.1067e-02, -2.9817e-01, -6.8028e-02, -1.3047e-01,
         -8.3282e-01, -2.1888e-01, -1.1378e-01, -1.4994e-02, -3.3752e-01,
          1.4736e-01, -2.0098e-01, -3.8907e-01,  1.4387e-01, -1.3784e-01,
          1.6391e-02, -1.7244e-01,  7.5800e-02, -2.3648e-01, -3.8036e-01,
          1.9662e-01,  7.4968e-02, -1.1686e-01, -3.6071e-01, -7.9299e-02,
          1.8760e-01,  1.6195e-01, -3.2272e-01, -2.1438e-01, -7.2898e-02,
          9.8829e-02,  7.1539e-02,  1.3703e-01, -1.5568e-01,  6.3408e-04,
         -3.5787e-02, -2.7407e-01, -5.7378e-02, -2.0438e-01, -2.4371e-02,
          1.7313e-01, -4.1306e-01, -9.4938e-02,  3.8556e-02, -2.3727e-01,
          5.0274e-02, -5.2022e-02,  6.9763e-03,  1.2209e-01, -1.4279e-01,
         -2.5014e-01, -1.8495e-02, -1.3463e-02, -2.4504e-01, -1.3166e-01,
         -7.7291e-02,  7.7370e-02,  1.1513e-02, -7.0425e-02,  1.5736e-01,
         -2.1174e-01, -4.2664e-02, -2.9207e-01,  3.2393e-02,  2.1656e-02,
          9.9900e-02, -1.3805e-01,  2.5438e-01,  2.0831e-01,  3.6837e-02,
         -3.3914e-03,  4.1395e-01,  5.6420e-02,  8.9263e-02,  2.1450e-02,
         -5.5800e-02,  7.0606e-02, -4.1126e-02,  3.8725e-03, -1.5734e-01,
          5.0738e-01,  1.5756e-02,  3.4117e-01, -3.4182e-01,  2.3014e-01,
          2.9587e-02, -8.8264e-02,  3.3711e-01, -1.4313e-01,  1.5262e-01,
         -8.7762e-02,  2.4450e-01, -2.0987e-01,  1.9820e-01,  1.7844e-01,
          1.4303e-01, -5.0851e-02, -9.4576e-02,  1.8408e-02,  1.1286e-01,
          3.3272e-01,  3.5103e-01, -4.2428e-02, -1.9907e-01,  9.6479e-02,
          3.2967e-02, -1.9729e-01,  2.2756e-01,  8.3037e-02,  2.5401e-01,
          2.9031e-01, -1.5839e-01, -1.3418e-02,  1.0571e-01, -3.5190e-01,
         -8.5125e-02,  1.5848e-01,  2.5322e-01,  2.0388e-02,  1.4573e-01,
          1.7365e-02,  3.1611e-01, -2.0127e-01,  8.0616e-02, -1.4502e-02,
          6.7866e-01,  5.2572e-01,  6.3858e-02,  3.9846e-02,  5.1869e-01,
         -7.9728e-03,  3.9597e-01,  4.7967e-01,  2.7590e-01,  9.2782e-02,
          3.3310e-01,  2.2875e-01,  3.4428e-01,  4.6610e-01, -1.0366e-01,
          3.4020e-01,  2.3838e-01,  3.1878e-01,  1.2648e-01,  5.1629e-01,
          3.4091e-01,  4.3710e-01,  6.2221e-01,  1.7226e-01,  4.4662e-01,
          4.0081e-01,  7.7952e-01,  4.0586e-01,  1.0278e+00,  3.0402e-01,
          1.5113e-01,  8.0986e-02,  2.9811e-01,  6.0928e-01,  3.3816e-01,
          5.8209e-01,  5.3371e-01,  3.8662e-01,  2.0641e-01,  3.6023e-01,
          3.1196e-02,  4.9345e-01,  3.2226e-01,  2.7840e-01,  2.7691e-01,
          9.6109e-01,  1.2737e-01,  4.1566e-01,  3.9062e-01,  3.0825e-01,
          4.9397e-01,  4.5440e-01,  5.2856e-01,  2.1089e-01,  4.5024e-01,
          3.9093e-01,  4.3543e-01,  1.2896e-01,  3.8236e-01,  5.7791e-02,
          5.9610e-02,  3.2190e-01,  4.1077e-01,  6.7217e-01,  3.1503e-01,
          4.5539e-01,  3.8127e-01,  3.7299e-01,  4.9606e-01,  5.1592e-01,
          8.7739e-01,  1.2913e-01,  3.2640e-01,  5.1213e-01,  2.5983e-01,
          3.1244e-01,  8.0140e-02,  3.2804e-01,  1.5592e-01,  4.3599e-01,
          5.4296e-01,  3.3799e-01,  5.6262e-01,  9.3698e-01,  4.7990e-01,
          4.9927e-02,  4.0214e-01,  5.5437e-01,  4.3915e-01,  1.3080e-01,
          3.5957e-01,  6.5735e-02,  9.8948e-02,  4.7541e-01,  9.1836e-02,
          3.4417e-01,  3.5615e-01,  4.0770e-02,  4.5717e-01,  6.4114e-01,
          2.4542e-01,  5.0354e-01,  1.7951e-01,  6.0904e-01,  1.5958e+00,
          2.1165e-01,  3.6238e-01,  2.0053e-01,  4.2348e-01,  6.8393e-01,
          8.5349e-01,  1.3414e-01, -1.2184e-03,  4.1054e-01,  7.6441e-01,
          6.1769e-02,  3.8833e-01,  3.6897e-01,  3.5290e-01,  2.8261e-01,
          3.1730e-01,  4.8138e-01, -1.5993e-01,  3.7400e-01,  2.7083e-01,
          2.0941e-01,  5.4596e-01], requires_grad=True)]</code></pre>
</div>
</div>
<p><strong>Looking at shape of last layer</strong></p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># collapse_output</span></span>
<span id="cb7-2">final <span class="op" style="color: #5E5E5E;">=</span> model.get_submodule(<span class="st" style="color: #20794D;">"model.decoder.layers.5.final_layer_norm"</span>)</span>
<span id="cb7-3">final_paramaeters <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">list</span>(final.parameters())</span>
<span id="cb7-4"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>final_paramaeters <span class="op" style="color: #5E5E5E;">=</span> <span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>final_paramaeters = [Parameter containing:
tensor([ 9.2454,  9.3895,  9.3544,  9.0685,  9.2224,  9.8569,  9.3900,  9.4416,
         9.4985,  9.2981,  9.5326,  9.2260,  8.8878,  9.4862,  9.5422,  9.3088,
         9.6653,  8.9836,  9.5670,  9.0307,  9.4179,  9.8929,  9.3411,  8.9442,
         8.3855,  9.0165,  9.5142,  9.5201,  9.2902,  9.5196,  8.8687,  9.3270,
         8.7709,  9.5791,  9.4227,  8.9457,  9.4278,  9.2320,  9.5537,  9.3045,
         9.2281,  9.1897,  8.9683,  9.3930,  9.1265,  9.2261,  9.1755,  9.2192,
         9.1531,  9.2323,  9.1581,  9.3413,  8.4585,  9.3836,  9.7359,  8.8970,
         9.4054,  8.9220,  9.2355,  9.6045,  9.6126,  9.4839,  9.2955,  9.2803,
         9.5649,  8.8892,  9.4749,  8.8119,  9.3922,  9.0771,  9.7973,  8.9035,
         9.7339,  9.1203,  9.5283,  8.9696,  8.4717,  9.3626,  9.3828,  7.9538,
         8.8453,  9.0190,  9.3108,  8.3297,  8.7236,  8.8562,  9.1680,  8.8641,
         7.8828,  8.7943,  8.4220,  8.8387,  9.3143,  8.1786,  9.1979,  9.0642,
         8.2838,  8.6224,  8.8548,  8.2028,  8.3914,  9.4564, 10.2469,  9.0537,
         8.7376,  9.3791,  8.5842,  8.4631,  8.6599,  8.8171,  7.8897,  8.6041,
         8.4556,  8.9208, 10.1143,  7.9758,  8.2237,  8.5698,  9.2252,  8.1479,
         8.0188,  8.9071,  8.1475,  9.6910,  8.2373,  8.2525,  8.6017,  8.4775,
         7.6445,  8.5943,  8.4234,  9.5359,  7.9101,  9.0395,  8.2788,  9.1683,
         8.9006,  9.3443, 10.6461,  8.7802,  8.7067,  8.1328,  8.4786,  9.5398,
         8.9038,  8.7195,  8.6432,  8.6484,  8.0920,  7.6238,  8.0674,  9.1098,
         8.9414,  8.5768,  8.5224,  8.2418,  8.2112,  8.5999,  8.4768,  8.9988,
         9.0594,  8.4397,  7.2651,  8.8350,  8.4989,  8.2867,  9.2490,  8.9484,
         9.0761,  9.4235,  8.6788,  8.3734,  8.5445,  8.6480,  8.5919,  8.7318,
         8.9115,  8.3845,  7.7635,  8.0614,  8.0440,  8.3904,  9.2142,  8.9592,
         8.3101,  8.5018,  8.3161,  8.6132,  8.5134,  8.6191,  9.2030,  8.4010,
         8.6543,  8.9678,  8.5206,  8.7887,  8.4305,  8.9793,  8.4836,  8.3803,
         8.5192,  9.0187,  8.2780,  8.4214,  8.5277,  8.3268,  8.6899,  8.8909,
         8.5217,  8.8556,  8.1597,  9.0187,  8.8114,  9.0544,  8.1888,  8.0256,
         8.2712,  7.8735,  8.3806,  8.3239,  8.1951,  8.1542,  8.8955,  8.1172,
         8.7627,  8.6084,  8.8146,  8.5941,  8.4780,  7.9555,  8.5277,  8.8061,
         8.1250,  8.5714,  8.6387,  7.6968,  8.5164,  8.5684,  8.8306,  8.1602,
         8.7625,  8.7649,  8.5770,  8.8186,  8.6728,  8.8203,  8.8378,  8.8105,
         8.2568,  8.4017,  9.9819,  9.0695,  8.9472,  8.4494,  7.6861,  8.1042,
         9.4347,  9.3720,  9.0644,  9.1978,  9.8322,  9.0001,  9.1845,  9.4331,
         9.3469, 11.0728,  9.3463,  8.5851,  9.6459,  9.1978,  9.2272,  9.5648,
         9.5100,  9.6435,  9.5191,  9.8178,  9.3789,  9.5861,  9.2071,  9.2581,
         8.5441,  9.6824,  9.0314,  9.2823, 10.2148, 10.1498,  9.3458,  8.9451,
         9.7831,  9.0849,  8.7979,  9.0224,  8.8580,  9.6999,  9.0158,  9.4426,
         9.2253,  9.1951,  9.4550,  9.1783,  9.5661,  9.3228,  9.4391,  9.2358,
         9.1685,  8.8517,  9.4883,  9.0652,  9.4498,  8.6077,  9.7002, 10.4473,
         9.9884,  8.8662,  9.4317,  9.2922,  9.0668,  9.7620,  9.2281,  9.4860,
         9.6106,  8.0309,  8.9221,  9.0221,  9.0459, 10.2337,  9.7973,  9.5885,
         9.0249,  8.8571,  8.7396,  8.9452,  9.2020,  9.1573,  8.4453,  9.3205,
         8.6279,  8.8441,  8.9208,  9.7410,  8.9751,  9.3891,  9.5010,  8.9050,
         8.8219,  8.4705,  9.4688,  9.2351,  9.1935,  9.7405,  9.1623,  8.1793,
         8.0767,  8.1733,  8.9422,  8.4693,  8.9346,  9.1120,  8.0441,  9.5878,
         9.5636,  8.8612,  9.0740,  9.1084,  9.7573,  9.8492,  9.6772,  9.1868,
         8.7703,  8.4915,  8.4426,  8.7710,  9.0574,  8.4157, 10.3115,  9.0996,
         8.5651,  9.0585,  8.4534,  8.7063,  8.4291,  8.3241,  7.9195,  9.0210,
         8.3222,  8.5985,  8.7874,  9.1164, 10.2389,  7.7741,  8.5940,  9.1308,
         9.3498,  8.7384,  8.3300,  8.2650,  8.7969,  8.6335,  8.6550,  8.7559,
         8.2821,  8.7692,  8.7830,  8.4424,  8.6879,  8.6025,  8.6327,  8.8367,
         9.4620,  8.5763,  8.3675,  8.4179,  9.2793,  8.8078,  9.3775,  9.6580,
        10.1902,  8.9006,  8.5452,  8.6059,  8.5685,  8.4081,  9.1445,  8.5781,
         8.9791,  8.7608,  8.6678,  8.4435,  7.6760,  8.6099,  8.8083,  8.1700,
         8.5081,  8.1777,  9.2411,  8.9585,  8.1853,  8.3657,  7.9898,  8.8000,
         8.1188,  9.3628,  8.9330,  7.7698,  9.6513,  9.2959,  9.1233,  9.0433,
         8.2871,  8.7241,  8.2236,  8.3967,  8.2571,  9.3786,  8.6354,  8.7345,
         8.3856,  8.4556,  8.7689,  8.7359,  8.6211,  9.7834,  8.9445,  8.8958,
         8.1290,  8.5490,  9.0263,  8.3258,  8.2379,  8.8249,  8.7301,  8.6340,
         9.3168,  8.7775,  9.9242,  8.9798,  9.1412,  8.5955,  8.1734,  8.9969,
         9.5123,  9.0581,  8.2497,  8.3555,  9.3501,  8.7719,  8.4376,  8.8456,
         8.2080,  8.9806,  8.5660,  9.1352,  8.5920,  8.2595,  8.1272,  9.0418,
         8.6972,  8.3413,  8.2742,  8.3118,  8.2167,  8.5550,  8.7187,  8.8749,
         9.7556,  8.4383,  9.0293,  8.1725,  8.5115,  8.9174,  8.9519,  9.0915],
       requires_grad=True), Parameter containing:
tensor([-1.6685e+00, -6.0155e-01, -5.9975e-01,  8.4297e-01,  8.5853e-01,
         5.6530e-02, -1.2840e+00, -5.1519e-01,  1.6774e+00,  3.2501e-01,
         1.4737e-01, -9.6427e-01,  2.1513e-01,  9.5219e-01, -3.7011e-03,
         6.6861e-01,  7.9758e-01,  2.4703e-01, -9.5743e-02,  1.9413e-01,
        -4.1348e-01, -8.3267e-01,  9.7684e-01, -5.1446e-01,  5.3158e-01,
         1.0447e+00,  1.7422e-01,  1.8719e+00,  7.0798e-01, -5.2600e-01,
         3.0636e-01,  3.1010e-01, -6.3830e-02, -2.3082e-01,  1.1787e+00,
        -2.5507e-01, -1.2747e+00,  7.3436e-01, -6.5267e-01,  1.0654e+00,
         7.2399e-01, -1.2560e+00, -6.7986e-01, -2.0358e-01, -2.1730e-01,
         5.1018e-02,  3.6179e-01,  2.0001e+00, -6.3287e-01,  1.5726e+00,
         2.8116e-01, -5.0017e-01, -1.6484e+00, -9.0159e-01, -2.5041e-01,
        -1.7400e-01,  6.4630e-01,  5.9313e-02, -7.2617e-03,  5.0565e-01,
         1.8716e+00, -8.8190e-01, -1.5941e-02,  7.8757e-02, -7.3102e-01,
        -4.5485e-01,  1.1036e+00, -3.2698e-01, -8.0969e-01, -6.6129e-01,
        -6.8337e-01, -1.6216e-01, -9.3829e-02,  6.4593e-01, -1.3784e+00,
         5.6243e-01,  8.1852e-01,  1.3817e-01,  5.7122e-01, -7.8534e-01,
        -9.2640e-01,  1.3659e-01, -6.8277e-01,  8.1809e-01, -1.4720e-01,
        -2.1538e+00, -7.1303e-02,  3.9166e-01, -7.9192e-01,  1.0671e+00,
         1.1110e+00,  9.8533e-01, -4.9213e-01, -8.4603e-01, -1.1119e+00,
         1.6191e+00,  7.9375e-02, -1.0472e-01, -5.4553e-01, -2.3597e-01,
        -2.6790e-01, -1.5157e+00, -2.6880e+00,  1.6904e-01,  2.3876e-01,
        -5.1432e-01,  5.7074e-01,  1.5021e+00, -1.7612e+00, -5.1162e-01,
         1.8071e+00, -2.2087e-01,  2.1651e-01,  3.1280e-01, -7.8104e-01,
        -2.3347e-01,  2.3287e+00,  4.3430e-01,  6.7748e-02, -7.1022e-01,
         1.3716e+00, -6.8236e-01, -1.9249e-02,  6.1708e-01,  3.5377e-01,
        -3.0060e-01,  8.7717e-01,  7.6281e-02,  1.6436e+00,  6.5745e-02,
         1.3911e+00, -1.1550e+00, -1.0942e+00, -5.4705e-02, -3.8439e-01,
        -2.0564e-01, -4.0284e-01,  1.8441e+00,  1.9942e+00, -3.3832e-01,
        -8.4892e-02,  2.6425e-01, -1.2417e-01, -8.9078e-01,  9.9491e-01,
        -1.2496e-01,  1.8860e-01, -1.9992e-01,  1.2828e+00, -1.6894e+00,
         1.7569e+00, -1.2428e-01, -6.2974e-01,  9.5339e-01,  5.5913e-01,
         8.3872e-01,  3.8710e-01,  4.7107e-01,  8.8813e-01,  1.5112e+00,
         6.4772e-02,  2.2407e+00, -2.4373e+00,  5.4596e-02, -2.3119e+00,
         7.8280e-01, -1.9582e+00, -4.4601e-01, -7.2071e-01,  1.0691e+00,
        -6.3960e-01, -9.6271e-01,  2.2167e+00,  1.6286e+00,  1.8287e-01,
        -1.0599e+00,  8.2727e-01,  4.2197e-01, -1.7488e-01,  2.2607e+00,
         1.6864e+00,  1.5625e+00, -2.4543e-01,  1.7482e-01, -1.4680e+00,
        -6.5810e-01, -1.7268e-01,  4.3401e-02,  1.2926e+00,  4.0332e-01,
         1.2770e-01, -5.4604e-02,  6.3163e-01,  5.8788e-01,  3.2761e-01,
         5.9546e-01, -1.4995e-02, -2.2789e-01, -3.0784e-01, -1.0060e-01,
        -1.6770e-01, -1.0096e+00,  9.2021e-01, -8.9897e-01, -5.9694e-01,
         8.2038e-01, -9.0749e-01, -3.0484e-01,  3.2038e-01,  1.2042e+00,
         6.0027e-01,  1.8709e-02, -4.0982e-01,  9.0638e-01, -9.6504e-01,
        -6.3824e-01, -2.3503e-02, -2.9762e-01,  1.1074e+00,  1.2170e-01,
         1.1205e+00, -1.9938e-01, -2.7814e-01, -3.8689e-01,  1.1914e+00,
        -6.5604e-01,  7.1130e-02, -7.0655e-01,  1.4939e+00, -2.6654e-01,
         4.9578e-01, -1.8316e+00, -6.2531e-01,  2.2550e+00, -9.1826e-01,
         2.1526e+00,  1.7631e-01,  1.2235e+00, -9.9429e-01, -8.9968e-01,
        -9.7487e-01, -3.5716e-01, -3.8364e-01, -2.2766e+00, -1.4803e+00,
         2.7549e-01, -5.8828e-01, -4.4274e-01,  2.0661e-02,  9.6894e-01,
        -5.4657e+00,  3.6806e+00, -5.8913e-01,  6.1390e-02,  9.8940e-01,
         1.8229e+00,  3.6467e-01,  2.9497e-01,  2.1930e+00,  1.8576e+00,
        -7.6800e-01,  1.3635e+00,  2.8457e-01,  2.9478e-02, -1.5696e+00,
         6.0662e-01, -1.1586e+00,  7.8294e-01,  3.4371e-01,  1.4571e-01,
        -4.5860e-01, -1.1644e+00, -1.2903e-01, -1.0055e+00, -5.4373e-02,
         1.3311e+00, -1.2074e+00,  8.7602e-02,  8.2454e-01, -2.2496e+00,
         2.4152e+00, -7.4065e-02,  3.5327e-01,  1.2092e+00,  6.9553e-02,
         2.4961e+00, -1.5597e+00,  4.1607e-01, -7.9795e-02, -4.4723e-01,
         2.6720e-01, -1.9072e+00, -6.5835e-01, -2.5336e-01, -9.1617e-01,
         8.8624e-01, -6.2251e-01,  9.6169e-01,  1.1279e+00, -5.6577e-01,
         1.8407e-01,  6.5294e-01, -6.1990e-01,  7.9014e-01, -6.0878e-01,
         1.0077e+00,  1.2790e+00, -1.3704e-02,  7.4945e-02,  5.6748e-01,
         1.0100e+00, -2.2963e-01, -9.2723e-01, -3.3553e-01, -7.0238e-01,
        -2.3026e+00, -5.3322e-02, -9.2703e-01,  1.4448e+00, -8.7800e-01,
        -6.4034e-01, -1.2203e+00, -1.1720e+00,  4.9662e-01,  3.4336e-01,
        -1.3538e+00,  4.1525e-01, -6.6715e-01,  4.1263e-01, -4.0352e-01,
        -3.7377e-01,  2.3441e+00,  3.5528e-01, -3.1402e-01,  3.5890e+00,
         2.8886e-02,  3.1700e-01, -7.7702e-01,  4.6834e-01,  5.4264e-01,
        -1.0964e+00,  1.4711e+00,  9.3168e-01,  5.4778e-01, -7.4466e-01,
         7.7792e-01,  1.5176e+00,  1.6450e+00,  2.6295e-02, -1.8510e+00,
         2.2687e-01,  1.3993e-01,  1.1727e+00,  6.4835e-02,  1.9505e-01,
         2.2950e-01, -1.3806e+00,  7.7071e-02, -1.8424e+00, -9.5833e-01,
        -8.7708e-01,  9.1619e-01,  1.0074e+00,  8.0151e-03,  1.0098e+00,
        -3.9247e-02, -2.7759e-01, -2.1021e+00, -4.1539e-01, -1.5258e-01,
         3.3655e-01, -2.6506e-01,  2.1964e+00,  6.0517e-01,  5.7097e-01,
         7.5984e-02,  1.0848e+00,  4.8223e-01,  8.0175e-01, -9.1310e-01,
         6.3781e-01,  1.1286e-01,  1.3899e+00, -4.5585e-01, -8.9240e-01,
        -5.6478e-01, -1.0510e+00, -6.3237e-01,  7.5205e-01, -5.0555e-01,
        -4.2338e-01,  1.1653e+00, -4.3769e-01, -4.9660e-01,  8.4734e-01,
         3.1255e-01,  1.4222e+00,  5.1850e-01,  5.9261e-03,  6.8774e-01,
        -2.2485e+00, -2.1259e-01,  1.7378e-01, -3.9461e+00,  8.5505e-01,
        -1.4455e+00,  2.2031e-02, -8.7173e-01,  9.4395e-01,  1.3690e+00,
         9.2501e-01,  5.9211e-01,  5.9655e-01, -9.7749e-01,  5.1079e-01,
         1.7735e-02,  3.1332e-01,  2.8223e-01,  2.2100e-01,  9.7640e-01,
         7.5128e-01, -1.2068e+00,  8.0254e-01,  4.7232e-01, -5.7225e-01,
         3.0082e-01, -4.5279e-01, -3.4367e-01, -2.8903e-01,  1.1790e+00,
        -2.3224e+00,  7.0363e-01,  4.5137e-01,  1.5505e+00,  8.4144e-01,
         3.9210e-02, -9.5217e-01, -9.1495e-01, -3.6971e-01,  1.3037e-01,
         1.0739e+00, -5.2155e-02, -1.7844e+00, -6.9291e-01,  6.2565e-01,
        -1.6121e+00, -4.0668e-01,  6.9844e-01,  2.1026e-01, -3.4400e-01,
        -2.3706e-02, -4.4798e-01,  6.0481e-01,  7.8424e-01,  6.2746e-01,
        -7.7199e-01,  2.0300e-01,  9.1969e-01, -1.1502e+00, -3.1036e-01,
         3.8410e-01,  3.3024e+00,  9.6322e-02,  3.5212e-01,  1.4104e+00,
        -2.7992e-01,  4.1524e-01, -1.1456e+00, -2.6424e-01, -6.5836e-02,
        -5.0440e-01,  5.7824e-01, -7.8925e-01, -2.0960e+00, -1.2973e-01,
         1.0862e+00,  1.3762e+00, -3.2528e-02, -2.2924e+00, -8.9146e-01,
        -3.0597e+00,  6.0693e-01, -2.5389e-01, -2.9927e-01,  3.3115e-01,
        -4.1729e-01,  1.3418e+00,  8.3576e-01, -1.0882e+00,  1.0617e+00,
        -2.8175e-01,  1.1439e+00, -4.9022e-01, -1.1799e-01, -4.8219e-01,
         9.3034e-02,  1.2776e+00, -1.2725e-01,  5.8007e-01,  1.3756e+00,
         1.2398e-01, -3.1594e-01, -7.3134e-02,  4.6101e-01,  1.4797e-01,
        -8.3583e-01, -1.8117e+00,  1.3540e-01,  1.4121e-01,  5.1246e-01,
         1.6791e-01, -1.5676e+00], requires_grad=True)]</code></pre>
</div>
</div>
</section>
<section id="looking-at-how-neural-network-really-work" class="level2">
<h2 class="anchored" data-anchor-id="looking-at-how-neural-network-really-work">Looking at how neural network really work?</h2>
<p><code>partial</code> in python is something which is usually used in lot of languages. It’s just subsituting value of x, in a function which is partial filled with already existing function.</p>
<p><a href="https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work">Jeremy explained with this notebook today</a></p>
<p>I followed along the notebook, making slight changes in variable names, function names, along with changing defined value to expirement with <a href="https://github.com/kurianbenoy/FastAI-notebooks/blob/d69e1cf9bf04f946ff6e1a9c30977d7ac8eeb9f7/coursev5/neuralnetworks_scratch.ipynb">how does a neural network really work notebook version on my own</a>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Thanks to <a href="https://twitter.com/strickvl">Alex Strick</a> for sharing this trick when working with notebooks during delft-fastai sessions.</p>
</div>
</div>
<!-- ![image](https://user-images.githubusercontent.com/24592806/168652892-925abcc5-4d4b-43f1-8309-d80b1376fd1e.png) -->
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Usually when I explain this is how neural networks work, one of my students said this is like how we draw an outline of an owl. In deep learning …, there is just step 1 where we draw outline, computer automatically does the step2 by drawing a beautiful owl.</p>
</div>
</div>
</section>
<section id="intuitive-understanding-with-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="intuitive-understanding-with-neural-networks">Intuitive understanding with neural networks</h2>
<p>Using RELUs we can tweak our function in such a way to fit the data. What neural networks, with a bunch of RELU functions does is it helps to optimize in such a way to fit any swiggly line or complex things which needn’t be always quadratic.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>For Linear algebra, almost all time you need is matrix multiplcation. In schools, you learn linear algrebra as if you need tons of experience to do machine learning. Yet it’s this operation of matrix multiplication that GPUs are so good at it, and there are even tensor cores for this.</p>
</div>
</div>
<p><a href="http://matrixmultiplication.xyz/">Refresher on matrix multiplication</a></p>
<p>Using Titanic dataset,see who survived and who didnt’ with excel to understand neural networks. In video from [1:05:00].</p>
<p>Next week, we are going to look into how validation sets and more into metrics. We will be looking into Kaggle notebook on <a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">how to get started with NLP</a>.</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022-05-10-fastai-53.html</guid>
  <pubDate>Tue, 10 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://user-images.githubusercontent.com/24592806/168640845-07859116-bf6b-48c7-af61-5ff8a65dc2fb.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Lesson 2</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-05-03-fastai-52.html</link>
  <description><![CDATA[ 




<section id="lesson-setup" class="level2">
<h2 class="anchored" data-anchor-id="lesson-setup">Lesson Setup</h2>
<p>Jeremy was taking this session from his home, as the venue in University of queensland was already booked by someone else. Jeremy was really really pumped for this lesson and it’s like going to the early days of fast.ai with lot of super exciting work happening.</p>
<blockquote class="blockquote">
<p>twitter: https://twitter.com/bhutanisanyam1/status/1521511103406043137</p>
</blockquote>
<p>Jeremy mentioned some technique on using Jupyter notebooks, and asked to take a look at jupyter extensions. The navigation section and how to collapse headings was explained during class. [24:00]</p>
</section>
<section id="fastbook-chapter-2" class="level2">
<h2 class="anchored" data-anchor-id="fastbook-chapter-2">Fastbook Chapter 2</h2>
<p>This week we started by taking a look at putting model in production using fastai. This was the same thing which is covered in chapter 2 of Deep Learning book To build grizzly bears and teddy bears classifier.</p>
<p>Few things have changed in book in this version:</p>
<ul>
<li>using <code>search_images_ddg</code> instead of bing search apis</li>
<li>using <code>huggingfaces spaces</code> as deployment instead of voila even though it’s still works</li>
</ul>
<blockquote class="blockquote">
<p>RandomResizedCrop could be a good idea to understand different varieties of same image.</p>
</blockquote>
<p>Does RandomResizedCrop crop duplicate the image – i.e.&nbsp;you get multiple copies and you ensure that all the parts of the image are used in training? or does it just make one crop?</p>
<p>Jeremy answered it in video at [32:30]. His answer was it doesn’t copying image. In each epoch every image get’s written and what happens is in-memory image is being wrapped by recropping and colouring in realtime during model training. It’s like infinitely multi-copies of images.</p>
<p>Check the book to learn more in detail about various augmentations.</p>
<p>Sanyam mentioned that RandomResized crop as a augmentation is very helpful:</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Actually this technique is SUPER helpful-in a recent interview, Chris Deotte (4x Grandmaster) shared how these resizing techniques helped them win a solo gold. This was in the petfinder Kaggle competition (2nd run of the comp)</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Jeremy is running on a laptop with 4GB GPU. Jeremy says in GPU, just run one thing at a time else you will get CUDA error.</p>
</div>
</div>
</section>
<section id="how-to-do-fast.ai-course" class="level2">
<h2 class="anchored" data-anchor-id="how-to-do-fast.ai-course">How to do fast.ai course</h2>
<p><strong>Tips for people in Yellow bucket:</strong></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you are in yellow, always stop try. First go ahead and watch video fully without touching your keyboard and write code. Then watch again and follow the course. This is an unusual way as it can’t be done in real college lectures, but it’s very effective way indeed.</p>
</div>
</div>
<p>I asked <a href="https://twitter.com/waydegilliam/">Wayde Gilliam</a> who is a long term fastai community member after the lesson about his process of watching lectures. He was gracious enough to share it with mith</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Watch the livestream and jot down timestamp to go back to for anything I found interesting in journal A (or just a piece of paper)</li>
</ol>
</div>
</div>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ol start="2" type="1">
<li>Go back through the video after 2-3 days, hit those spots I noted during the livestream. Will write detailed notes in another Journal (we’ll call that journal B)</li>
</ol>
</div>
</div>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>There’s too much info to digest in real-time so this approach works well and its what I’ve been doing for 4-5 yrs.</p>
</div>
</div>
</section>
<section id="huggingface-spaces" class="level2">
<h2 class="anchored" data-anchor-id="huggingface-spaces">Huggingface spaces</h2>
<p>Jeremy pointed to tanishq tutorial on <a href="https://tmabraham.github.io/blog/gradio_hf_spaces_tutorial">Gradio + HuggingFace Spaces</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/fastailesson2.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p>Also Jeremy mentioned some good tools which are useful:</p>
<ul>
<li>Github Desktop: Hamel who was a employee in github previously, is even using github desktop. Some complicated stuff in git can be solved using this tool. Even knowing terminal is cool.</li>
<li>WSL: As a datascientist, you spend a lot of time in terminals. Just use ubuntu with windows terminal. Any time Jeremy shows in terminal, he just uses windows terminal.</li>
<li>In terminal, he uses Tmux as a terminal emulator as pointed out in <a href="https://forums.fast.ai/t/lesson-2-official-topic/96033/231?u=kurianbenoy">fast.ai forums for my question</a>.</li>
</ul>
<p>Jeremy like Windows due to easiness in streaming, good apps and recording capabilities. Yet Jeremy also has a linux environment with a good Deep learning jig.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Jupyter notebooks debugging with magic methods %time, %debug</p>
</div>
</div>
<p>In fastai for inference, it returns back a tensor. One of issue in gradio tensors is not supported at moment. So we need to convert tensors to float and do prediction.</p>
<p>Jeremy created a <a href="https://huggingface.co/spaces/jph00/pets">cats vs dogs classifier using spaces</a>. His daughter when realised he is building such a classifier googled something which is a mix of cat and dog. For that his initial prediction was like 50-50% for both cats and dogs.</p>
<p>This kind of shows how important the support system around you and how much they acknowledge the work you do. This personally touched me. As my sister was encouraging me to go an all-nighter to complete the <a href="https://huggingface.co/spaces/kurianbenoy/audioclassification">Music genre classification spaces</a>.</p>
<p>TODO: Look through Jeremy setup and how he worked with gradio in local [58:00 onwards 1:14:00]</p>
</section>
<section id="fastsetup" class="level2">
<h2 class="anchored" data-anchor-id="fastsetup">fastsetup</h2>
<p>Installing python and jupyter-notebooks with proper git and conda setup.</p>
<p><a href="https://github.com/fastai/fastsetup">Fastai setup</a></p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A big issue in laptops with linux or mac there is a python default version, don’t use that python. As that python version is for your operating system to do it’s stuff. Don’t mess on top of it.</p>
</div>
</div>
<p>Use mamba based installation for fastai now:</p>
<pre><code>mamba install fastai
mamba install -c fastchan jupyter nbdev</code></pre>
</section>
<section id="trying-gradio-api-with-github-pages" class="level2">
<h2 class="anchored" data-anchor-id="trying-gradio-api-with-github-pages">Trying gradio API with github Pages</h2>
<p><a href="https://hf.space/embed/kurianbenoy/audioclassification/api">An example API in gradio</a> <a href="https://github.com/fastai/tinypets">Example Jeremy showcased</a></p>
<blockquote class="blockquote">
<p>With live demo, we could have easily used it with any websites. Without any software just with the browser, you can run this file. That’s the cool thing about javascript and can host in website called github pages</p>
</blockquote>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">fetch(<span class="st" style="color: #20794D;">'https://hf.space/embed/kurianbenoy/audioclassification/+/api/predict/'</span>, </span>
<span id="cb2-2">{ method: <span class="st" style="color: #20794D;">"POST"</span>,</span>
<span id="cb2-3"> body: JSON.stringify({<span class="st" style="color: #20794D;">"data"</span>:[ {<span class="st" style="color: #20794D;">"data"</span>: null, <span class="st" style="color: #20794D;">"is_example"</span>: true, <span class="st" style="color: #20794D;">"name"</span>: <span class="st" style="color: #20794D;">"000003.ogg"</span>}</span>
<span id="cb2-4">]}), headers: { <span class="st" style="color: #20794D;">"Content-Type"</span>: <span class="st" style="color: #20794D;">"application/json"</span> }})</span>
<span id="cb2-5">.then(function(response){ <span class="cf" style="color: #003B4F;">return</span> response.json()<span class="op" style="color: #5E5E5E;">;</span> })</span>
<span id="cb2-6">.then(function(json_response){ console.log(json_response) })</span></code></pre></div>
</details>
</div>
<p>He used alembic theme. With a particular configuration. At top of any github pages, you should add three dashes. The world of javascript apps, he build this cool apps.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The magic of using gradio APIs can be summarized as the following. It exposes a reliable way of sharing microservices. With this if you are just creating any hugging face spaces, with that APIs. You can use it any websites, apps etc. It looks to me there is no limitation with using Gradio API at the moment.</p>
</div>
</div>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022-05-03-fastai-52.html</guid>
  <pubDate>Tue, 03 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/fastailesson2.png" medium="image" type="image/png" height="67" width="144"/>
</item>
<item>
  <title>Music genre classifier using fast.ai</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-05-01-audiocnndemo.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>UPDATE - This project got featured in some of the cool project Jeremy Howard shared in lesson3 of fastaiv5 course.</p>
<p>During first lesson of Practical Deep Learning for Coders course, Jeremy had mentioned how using simple computer vision model we can build even a model to classify audio with image classification model itself.</p>
<p>Recently Kaggle grandmaster <a href="https://www.kaggle.com/robikscube">Rob Mulla</a> conducted a challenge to classify music according to what genre it was. At stakes there was a RTX 3080 Ti GPU. Let’s look how we can classify music genres using a simple computer vision model which was taught in the first lesson of fast.ai.</p>
</section>
<section id="downloading-packages-and-importing-libraries" class="level2">
<h2 class="anchored" data-anchor-id="downloading-packages-and-importing-libraries">Downloading packages and importing libraries</h2>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I had already installed fastai, pytorch for training this model before hand.</p>
</div>
</div>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span> pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq kaggle git<span class="op" style="color: #5E5E5E;">+</span>https:<span class="op" style="color: #5E5E5E;">//</span>github.com<span class="op" style="color: #5E5E5E;">/</span>huggingface<span class="op" style="color: #5E5E5E;">/</span>huggingface_hub<span class="co" style="color: #5E5E5E;">#egg=huggingface-hub["fastai"]</span></span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> fastai.data.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;">from</span> fastai.imports <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb2-3"><span class="im" style="color: #00769E;">from</span> fastai.vision.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> push_to_hub_fastai</span></code></pre></div>
</div>
</section>
<section id="collecting-data" class="level2">
<h2 class="anchored" data-anchor-id="collecting-data">Collecting Data</h2>
<p>In this piece of code, I will show you how you can download datasets from Kaggle in general and the datasets I had used for training model. Inorder to train models in audio, first convert the audio to a spectogram and throw an image model. Check this tweet from <a href="https://twitter.com/DienhoaT">Dien Hoa Truong</a> who won a NVIDIA RTX 3080 Ti GPU in this competition.</p>
<blockquote class="blockquote">
<p>twitter: https://twitter.com/DienhoaT/status/1519785308715462656</p>
</blockquote>
<p>For this competition you need two datasets:</p>
<ol type="1">
<li><a href="https://www.kaggle.com/competitions/kaggle-pog-series-s01e02/data">The competition data</a></li>
<li><a href="https://www.kaggle.com/datasets/dienhoa/music-genre-spectrogram-pogchamps">Image data generated from converting audio to melspectograms in form of images</a></li>
</ol>
<p>The data provided here are over 20,000 royalty free song samples (30 second clips) and their musical genres. Your task is to create a machine learning algorithm capable of predicting the genres of unlabeled music files. Create features, design architectures, do whatever it takes to predict them the best.</p>
<p><a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">The code for downloading data from kaggle has been adopted from Jeremy’s notebook</a></p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">creds <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">""</span></span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb3-4"></span>
<span id="cb3-5">cred_path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">"~/.kaggle/kaggle.json"</span>).expanduser()</span>
<span id="cb3-6"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> cred_path.exists():</span>
<span id="cb3-7">    cred_path.parent.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-8">    cred_path.write_text(creds)</span>
<span id="cb3-9">    cred_path.chmod(<span class="bn" style="color: #AD0000;">0o600</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">"../input/kaggle-pog-series-s01e02"</span>)</span>
<span id="cb4-2">path.ls()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(#6) [Path('input/kaggle-pog-series-s01e02/genres.csv'),Path('input/kaggle-pog-series-s01e02/sample_submission.csv'),Path('input/kaggle-pog-series-s01e02/test.csv'),Path('input/kaggle-pog-series-s01e02/test'),Path('input/kaggle-pog-series-s01e02/train.csv'),Path('input/kaggle-pog-series-s01e02/train')]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;">from</span> zipfile <span class="im" style="color: #00769E;">import</span> ZipFile</span>
<span id="cb6-2"><span class="im" style="color: #00769E;">from</span> kaggle <span class="im" style="color: #00769E;">import</span> api</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> path.exists():</span>
<span id="cb6-5">    api.competition_download_cli(<span class="bu" style="color: null;">str</span>(path))</span>
<span id="cb6-6">    ZipFile(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.zip"</span>).extractall(path)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading kaggle-pog-series-s01e02.zip to /home</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 9.05G/9.05G [07:54&lt;00:00, 20.5MB/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="op" style="color: #5E5E5E;">!</span> kaggle datasets download <span class="op" style="color: #5E5E5E;">-</span>d dienhoa<span class="op" style="color: #5E5E5E;">/</span>music<span class="op" style="color: #5E5E5E;">-</span>genre<span class="op" style="color: #5E5E5E;">-</span>spectrogram<span class="op" style="color: #5E5E5E;">-</span>pogchamps</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading music-genre-spectrogram-pogchamps.zip to /home
100%|█████████████████████████████████████▉| 6.80G/6.80G [07:00&lt;00:00, 14.7MB/s]
100%|██████████████████████████████████████| 6.80G/6.80G [07:00&lt;00:00, 17.4MB/s]</code></pre>
</div>
</div>
</section>
<section id="quick-eda-and-data-cleaning" class="level2">
<h2 class="anchored" data-anchor-id="quick-eda-and-data-cleaning">Quick EDA and Data Cleaning</h2>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">df_train <span class="op" style="color: #5E5E5E;">=</span> pd.read_csv(<span class="st" style="color: #20794D;">"../input/kaggle-pog-series-s01e02/train.csv"</span>)</span>
<span id="cb13-2">df_train.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>song_id</th>
      <th>filename</th>
      <th>filepath</th>
      <th>genre_id</th>
      <th>genre</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10150</td>
      <td>010150.ogg</td>
      <td>train/010150.ogg</td>
      <td>7</td>
      <td>Instrumental</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7358</td>
      <td>007358.ogg</td>
      <td>train/007358.ogg</td>
      <td>2</td>
      <td>Punk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20573</td>
      <td>020573.ogg</td>
      <td>train/020573.ogg</td>
      <td>5</td>
      <td>Folk</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11170</td>
      <td>011170.ogg</td>
      <td>train/011170.ogg</td>
      <td>12</td>
      <td>Old-Time / Historic</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16662</td>
      <td>016662.ogg</td>
      <td>train/016662.ogg</td>
      <td>1</td>
      <td>Rock</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">df_train[<span class="st" style="color: #20794D;">"filepath"</span>] <span class="op" style="color: #5E5E5E;">=</span> df_train[<span class="st" style="color: #20794D;">"filepath"</span>].<span class="bu" style="color: null;">str</span>.replace(<span class="st" style="color: #20794D;">"ogg"</span>, <span class="st" style="color: #20794D;">"png"</span>)</span></code></pre></div>
</div>
<p><strong>Shows a highly imbalanced dataset</strong></p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">df_train[<span class="st" style="color: #20794D;">"genre"</span>].value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>Rock                   3097
Electronic             3073
Punk                   2584
Experimental           1801
Hip-Hop                1761
Folk                   1215
Chiptune / Glitch      1181
Instrumental           1045
Pop                     945
International           814
Ambient Electronic      796
Classical               495
Old-Time / Historic     408
Jazz                    306
Country                 142
Soul-RnB                 94
Spoken                   94
Blues                    58
Easy Listening           13
Name: genre, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">df_train.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>song_id</th>
      <th>filename</th>
      <th>filepath</th>
      <th>genre_id</th>
      <th>genre</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10150</td>
      <td>010150.ogg</td>
      <td>train/010150.png</td>
      <td>7</td>
      <td>Instrumental</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7358</td>
      <td>007358.ogg</td>
      <td>train/007358.png</td>
      <td>2</td>
      <td>Punk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20573</td>
      <td>020573.ogg</td>
      <td>train/020573.png</td>
      <td>5</td>
      <td>Folk</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11170</td>
      <td>011170.ogg</td>
      <td>train/011170.png</td>
      <td>12</td>
      <td>Old-Time / Historic</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16662</td>
      <td>016662.ogg</td>
      <td>train/016662.png</td>
      <td>1</td>
      <td>Rock</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">df_train <span class="op" style="color: #5E5E5E;">=</span> df_train.set_index(<span class="st" style="color: #20794D;">"song_id"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;"># I noticed some of images are missing music-genre-spectrogram-pogchamps images which are in training data. So removed it</span></span>
<span id="cb19-2">df_train <span class="op" style="color: #5E5E5E;">=</span> df_train.drop(</span>
<span id="cb19-3">    [</span>
<span id="cb19-4">        <span class="dv" style="color: #AD0000;">23078</span>,</span>
<span id="cb19-5">        <span class="dv" style="color: #AD0000;">3137</span>,</span>
<span id="cb19-6">        <span class="dv" style="color: #AD0000;">4040</span>,</span>
<span id="cb19-7">        <span class="dv" style="color: #AD0000;">15980</span>,</span>
<span id="cb19-8">        <span class="dv" style="color: #AD0000;">11088</span>,</span>
<span id="cb19-9">        <span class="dv" style="color: #AD0000;">9963</span>,</span>
<span id="cb19-10">        <span class="dv" style="color: #AD0000;">24899</span>,</span>
<span id="cb19-11">        <span class="dv" style="color: #AD0000;">16312</span>,</span>
<span id="cb19-12">        <span class="dv" style="color: #AD0000;">22698</span>,</span>
<span id="cb19-13">        <span class="dv" style="color: #AD0000;">17940</span>,</span>
<span id="cb19-14">        <span class="dv" style="color: #AD0000;">22295</span>,</span>
<span id="cb19-15">        <span class="dv" style="color: #AD0000;">3071</span>,</span>
<span id="cb19-16">        <span class="dv" style="color: #AD0000;">13954</span>,</span>
<span id="cb19-17">    ]</span>
<span id="cb19-18">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">df_train.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>(19909, 4)</code></pre>
</div>
</div>
</section>
<section id="loading-data-using-fastai-dataloaders" class="level2">
<h2 class="anchored" data-anchor-id="loading-data-using-fastai-dataloaders">Loading Data using fastai DataLoaders</h2>
<p>For creating this notebook, I spend a major portion of my time in cleaning and sorting out appropriate datablocks/dataloaders for training image models using fast.ai. This is something which you as a practitioner experience, compared to learning all the theory and backpropogation algorithm.</p>
<p>So let’s see how we load this data using fast.ai. There are two approaches which we will discuss below. Both the approaches of loading data works, but the first approach as a disadvantage, which I will tell in a moment.</p>
<p><strong>Approach 1. Using DataBlock and loading images</strong></p>
<ul>
<li>Create a data frame <code>temp_train</code> and create new column <code>is_valid</code></li>
<li><code>is_valid</code> is default column named created for using <a href="https://docs.fast.ai/data.transforms.html#ColSplitter">ColSplitter</a></li>
<li>Now set <code>get_x</code> which specifies the path of files for inputting data which is set as base_path+filename path: <em>lambda o:f’{path}/’+o.path</em></li>
<li>Now set <code>get_y</code> which specifies the variable to predict, ie the genre of music</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">temp_train <span class="op" style="color: #5E5E5E;">=</span> df_train</span>
<span id="cb22-2">temp_train.loc[:<span class="dv" style="color: #AD0000;">15000</span>, <span class="st" style="color: #20794D;">"is_valid"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb22-3">temp_train.loc[<span class="dv" style="color: #AD0000;">15000</span>:, <span class="st" style="color: #20794D;">"is_valid"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">"../input/music-genre-spectrogram-pogchamps/spectograms/"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock(</span>
<span id="cb24-2">    blocks<span class="op" style="color: #5E5E5E;">=</span>(ImageBlock, CategoryBlock),</span>
<span id="cb24-3">    splitter<span class="op" style="color: #5E5E5E;">=</span>ColSplitter(),</span>
<span id="cb24-4">    get_x<span class="op" style="color: #5E5E5E;">=</span><span class="kw" style="color: #003B4F;">lambda</span> o: <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/"</span> <span class="op" style="color: #5E5E5E;">+</span> o.path,</span>
<span id="cb24-5">    get_y<span class="op" style="color: #5E5E5E;">=</span><span class="kw" style="color: #003B4F;">lambda</span> o: o.genre,</span>
<span id="cb24-6">    item_tfms<span class="op" style="color: #5E5E5E;">=</span>Resize(<span class="dv" style="color: #AD0000;">224</span>),</span>
<span id="cb24-7">    batch_tfms<span class="op" style="color: #5E5E5E;">=</span>aug_transforms(),</span>
<span id="cb24-8">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">dls <span class="op" style="color: #5E5E5E;">=</span> dblock.dataloaders(temp_train)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">dls.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-01-AudioCNNDemo_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;"># Can be used for debugging</span></span>
<span id="cb27-2"><span class="co" style="color: #5E5E5E;"># dblock.summary(df_train)</span></span></code></pre></div>
</div>
<p>This worked really well, and with this approach I was even able to train a ML model which got 50% accuracy.</p>
<blockquote class="blockquote">
<p>twitter: https://twitter.com/kurianbenoy2/status/1520470393760272384</p>
</blockquote>
<p>Yet when it came to export models, due to usage of <strong>lamda method in DataBlock</strong>. I got <a href="https://gist.github.com/kurianbenoy/e672bf20831d14af47436300a4951fd5">Pickling error</a> as the model was not able to be exported with <code>learn.export()</code> method.</p>
<p><strong>2. Using DataLoaders methods with loading from dataframe method</strong></p>
<p>This issue got me into using approach that using <code>ImageDataLoaders.from_df</code> in fastai. Let’s first take a look at our <code>df_train</code> dataframe:</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">df_train.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>filename</th>
      <th>filepath</th>
      <th>genre_id</th>
      <th>genre</th>
    </tr>
    <tr>
      <th>song_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10150</th>
      <td>010150.ogg</td>
      <td>train/010150.png</td>
      <td>7</td>
      <td>Instrumental</td>
    </tr>
    <tr>
      <th>7358</th>
      <td>007358.ogg</td>
      <td>train/007358.png</td>
      <td>2</td>
      <td>Punk</td>
    </tr>
    <tr>
      <th>20573</th>
      <td>020573.ogg</td>
      <td>train/020573.png</td>
      <td>5</td>
      <td>Folk</td>
    </tr>
    <tr>
      <th>11170</th>
      <td>011170.ogg</td>
      <td>train/011170.png</td>
      <td>12</td>
      <td>Old-Time / Historic</td>
    </tr>
    <tr>
      <th>16662</th>
      <td>016662.ogg</td>
      <td>train/016662.png</td>
      <td>1</td>
      <td>Rock</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>If you look at the dataframe, we know that on appending to the path, the filepath column. - This is the exact value for <code>get_x</code> method in fastai <code>fn_col = 1</code> which specifies the column name <code>filepath</code> at position 1. - label or <code>get_y</code> is specified by the column name <code>genre</code> at position 3. - valid_pct (ensure what percentage of data to be used for validation) - y_block=CategoryBlock to ensure it’s used for normal classification only and not multi-label</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">dls <span class="op" style="color: #5E5E5E;">=</span> ImageDataLoaders.from_df(</span>
<span id="cb29-2">    df_train,</span>
<span id="cb29-3">    path,</span>
<span id="cb29-4">    valid_pct<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>,</span>
<span id="cb29-5">    seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">34</span>,</span>
<span id="cb29-6">    y_block<span class="op" style="color: #5E5E5E;">=</span>CategoryBlock,</span>
<span id="cb29-7">    item_tfms<span class="op" style="color: #5E5E5E;">=</span>Resize(<span class="dv" style="color: #AD0000;">460</span>),</span>
<span id="cb29-8">    batch_tfms<span class="op" style="color: #5E5E5E;">=</span>aug_transforms(size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">224</span>),</span>
<span id="cb29-9">    fn_col<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb29-10">    label_col<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>,</span>
<span id="cb29-11">)</span>
<span id="cb29-12">dls.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-01-AudioCNNDemo_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="training-fastai-model" class="level2">
<h2 class="anchored" data-anchor-id="training-fastai-model">Training fastai model</h2>
<p>I trained using a <code>resnet18 model</code> at first, later we stepped up to use <code>resnet50</code> model.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, resnet50, metrics<span class="op" style="color: #5E5E5E;">=</span>error_rate)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>SuggestedLRs(valley=0.0008317637839354575)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-01-AudioCNNDemo_files/figure-html/cell-24-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">learn.fine_tune(<span class="dv" style="color: #AD0000;">10</span>, <span class="fl" style="color: #AD0000;">0.0008317637839354575</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.869285</td>
      <td>2.171426</td>
      <td>0.616428</td>
      <td>01:43</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.312176</td>
      <td>1.843815</td>
      <td>0.558654</td>
      <td>02:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.102361</td>
      <td>1.719162</td>
      <td>0.539061</td>
      <td>02:08</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.867139</td>
      <td>1.623988</td>
      <td>0.527003</td>
      <td>02:08</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.710557</td>
      <td>1.527913</td>
      <td>0.507661</td>
      <td>02:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.629478</td>
      <td>1.456836</td>
      <td>0.479779</td>
      <td>02:05</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.519305</td>
      <td>1.433036</td>
      <td>0.474253</td>
      <td>02:05</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.457465</td>
      <td>1.379757</td>
      <td>0.464456</td>
      <td>02:05</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.396283</td>
      <td>1.369344</td>
      <td>0.457925</td>
      <td>02:05</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.359388</td>
      <td>1.367973</td>
      <td>0.453655</td>
      <td>02:05</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.364363</td>
      <td>1.368887</td>
      <td>0.456167</td>
      <td>02:04</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">learn.export(<span class="st" style="color: #20794D;">"model.pkl"</span>)</span></code></pre></div>
</div>
</section>
<section id="pushing-models-to-hugging-face" class="level2">
<h2 class="anchored" data-anchor-id="pushing-models-to-hugging-face">Pushing models to hugging face</h2>
<p><code>huggingface_hub</code> has released two new functions to easily push fastai models to <a href="https://huggingface.co/models">Huggingface Hub</a>.</p>
<ul>
<li>Using <code>push_to_hub_fastai</code> you can easily push the fastai Learner to huggingface.</li>
<li>Additionally, you can load any fastai Learner from the Hub using <code>from_pretrained_fastai</code></li>
</ul>
<p><a href="https://twitter.com/espejelomar">Omar Espejel</a> had shared a fantastic notebook on <a href="https://colab.research.google.com/gist/omarespejel/9ba054ce74c7a4d4408085b611124bdf">these new functionalities in huggingface here</a>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You should install git-lfs and login to huggingface account with token before pushing</p>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> push_to_hub_fastai</span>
<span id="cb35-2"></span>
<span id="cb35-3">push_to_hub_fastai(</span>
<span id="cb35-4">    learn,</span>
<span id="cb35-5">    <span class="st" style="color: #20794D;">"kurianbenoy/music_genre_classification_baseline"</span>,</span>
<span id="cb35-6">    commit_message<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Resnet50 with 10 epochs of training"</span>,</span>
<span id="cb35-7">)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/music_genre_classification_baseline is already a clone of https://huggingface.co/kurianbenoy/music_genre_classification_baseline. Make sure you pull the latest changes with `repo.git_pull()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a0f99139c5ff4081b04d1cca65f16492","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>To https://huggingface.co/kurianbenoy/music_genre_classification_baseline
   390320d..3605083  main -&gt; main
</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>'https://huggingface.co/kurianbenoy/music_genre_classification_baseline/commit/360508311005aefeb3ca29933f2173202afe4f30'</code></pre>
</div>
</div>
<p>If you want to load this model in fastai and use it directly for inference just <code>from_pretrain_fastai</code> as shown in the below screenshot:</p>
<pre><code>from huggingface_hub import from_pretrained_fastai

learn = from_pretrained_fastai("kurianbenoy/music_genre_classification_baseline")</code></pre>
<!-- ![image](https://user-images.githubusercontent.com/24592806/166294010-f996f9e1-588c-4bdc-9466-e4e8b8fb7148.png) -->
</section>
<section id="taking-a-look-at-results" class="level2">
<h2 class="anchored" data-anchor-id="taking-a-look-at-results">Taking a look at results</h2>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">learn.show_results()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-01-AudioCNNDemo_files/figure-html/cell-28-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">interp <span class="op" style="color: #5E5E5E;">=</span> Interpretation.from_learner(learn)</span>
<span id="cb41-2">interp.plot_top_losses(<span class="dv" style="color: #AD0000;">9</span>, figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">15</span>, <span class="dv" style="color: #AD0000;">10</span>))</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-05-01-AudioCNNDemo_files/figure-html/cell-29-output-5.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="inference-function" class="level2">
<h2 class="anchored" data-anchor-id="inference-function">Inference function</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="im" style="color: #00769E;">from</span> fastai.vision.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb42-2"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> from_pretrained_fastai</span>
<span id="cb42-3"></span>
<span id="cb42-4">learn <span class="op" style="color: #5E5E5E;">=</span> from_pretrained_fastai(<span class="st" style="color: #20794D;">"kurianbenoy/music_genre_classification_baseline"</span>)</span>
<span id="cb42-5"></span>
<span id="cb42-6"></span>
<span id="cb42-7"><span class="kw" style="color: #003B4F;">def</span> predict(img):</span>
<span id="cb42-8">    img <span class="op" style="color: #5E5E5E;">=</span> PILImage.create(img)</span>
<span id="cb42-9">    _pred, _pred_w_idx, probs <span class="op" style="color: #5E5E5E;">=</span> learn.predict(img)</span>
<span id="cb42-10">    labels_probs <span class="op" style="color: #5E5E5E;">=</span> {labels[i]: <span class="bu" style="color: null;">float</span>(probs[i]) <span class="cf" style="color: #003B4F;">for</span> i, _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(labels)}</span>
<span id="cb42-11">    <span class="cf" style="color: #003B4F;">return</span> labels_probs</span></code></pre></div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>We trained a ML model which can identify with 54.4% accuracy to classify in a music file which genre it is. It’s not so bad for a baseline model. Dien Hoa Truong has shared some techniques which he learned during Kaggle competition with music genres.</p>
<p></p><div id="tweet-60624"></div><script>tweet={"url":"https:\/\/twitter.com\/DienhoaT\/status\/1520511289822433281","author_name":"Dien Hoa Truong","author_url":"https:\/\/twitter.com\/DienhoaT","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003E[Machine Learning] Speed up your experiment so that you can try out a lot of ideas and find what works best for your problem. Below ⬇️ is what I have learned during the Kaggle competition with music genre\uD83C\uDFB6:\u003C\/p\u003E&mdash; Dien Hoa Truong (@DienhoaT) \u003Ca href=\"https:\/\/twitter.com\/DienhoaT\/status\/1520511289822433281?ref_src=twsrc%5Etfw\"\u003EApril 30, 2022\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-60624").innerHTML = tweet["html"];</script><p></p>
<p>Thanks for reading :pray:</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022-05-01-audiocnndemo.html</guid>
  <pubDate>Sun, 01 May 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/music.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Lesson 0</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-04-26-fastai-50.html</link>
  <description><![CDATA[ 




<p><img src="https://kurianbenoy.com/posts/images/lesson0.jpg" class="img-fluid"></p>
<p>Last few weeks, I enrolled for the live cohort of Deep Learning For Coders with fastai Couse which is going to be taken by Jeremy Howard. It’s’ a previlege at the same time, a dream come true moment for me, as a fastai student who took some part of fast.ai from the year 2018.</p>
<p>Whatever I have done in ML can be partly attributed to the way and the Jeremy motivated students to be world class researchers. The fastai course has seen lot of success stories from folks like Aman Arora, Deoldify creator, Sanyam Bhutani, Even Oldrige, Jason Antic Radek, Zach Mueller, Wayde Gilliam and much more. Jeremy has inspired and enabled multiple people to be practitioners in Deep Learning. {bhuvani an example}</p>
<p>I still feel I am a late boomer, and due to pursuing a work along with academics. I am in a position to be extremely careful with what I spend time with and things I do.</p>
<p>I will do following:</p>
<ol type="1">
<li>Try out every notebook given by Jeremy during class and writes in Kaggle</li>
<li>breath and look through pytorch tutorials</li>
<li>Write blogpost every week with lesson summary and occasionally on new things I learning during course.</li>
<li>Participate in NLP competition provided by jeremy link</li>
</ol>
<p>I won’t do:</p>
<ol type="1">
<li>Won’t read Pytorch book(even though it’s very tempting to do)</li>
<li>Be active in twitter during course</li>
<li>Read EDA notebooks</li>
<li>Won’t write any notebooks in tensorflow :)</li>
</ol>



 ]]></description>
  <category>fastbook</category>
  <category>myself</category>
  <category>ML</category>
  <category>Deep learning</category>
  <category>fastai</category>
  <guid>https://kurianbenoy.com/posts/2022-04-26-fastai-50.html</guid>
  <pubDate>Tue, 26 Apr 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/lesson0.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Lesson 1</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-04-26-fastai-51.html</link>
  <description><![CDATA[ 




<p>First there was a set of introductions by university officials at UQ like VC. One curious thing was everyone of UQ staff were honouring something traditionaly of that land to live in reconciliation.</p>
<p>Then lecture of Jeremy starts, seeing his face the chatbox is in delight.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/jeremy.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p>Jeremy mentions there are two categories of students who attend the course:</p>
<ol type="1">
<li>Students who have enrolled via University of Queensland(with almost 350 people attending in-person and about 100 people remotely as well).</li>
<li>fastai fellows who have acknowledged for their contribution to community.</li>
</ol>
<p>Jeremy recommends having study buddies when we are learning the course is important. So he asks to create Study groups wherever possible. This course is now happening after a gap of 2 years, so there is a lot of new things which has to be covered as Deep learning moves so fast.</p>
<p>Using Dalle-2 technique we can generative creative images from generate twitter bios. For a creative person, this can be very helpful to create good artwork. Then one of another popular techniques was using Pathways language model which is able to answers question with explanations and even explains why some jokes are funny.</p>
<p>Jeremy talks about his interest in education.He is a homeschooler and learned from books by Paul Lockhart &amp; David Perkins which were inspiration for fast.ai. fastai teaches stuff in top-down manner. You will go into as much technical stuff as you, yet you will learn and implement cool stuff steadily.</p>
<p><strong>About fast.ai course</strong></p>
<p>He wrote an awesome book and this course. His book is one of the best sellers in Deep Learning and used to teach folks in companies like Tesla, OpenAI etc. Almost 6 million people watched his videos so far.Jeremy has won multiple competitions in Kaggle, was the CEO of kaggle. He build Enlitic, a medical company which was build for medical purpose with two other succesful startups.</p>
<blockquote class="blockquote">
<p>Jeremy mentioned for this course, we are not using any material directly from Deep Learning For Coders with Fastai &amp; Pytorch book. Yet he recommends to read portions of book after each chapter.</p>
</blockquote>
<p>Usually multiple people learn better if the same idea is exposed in different way from multiple sources. That’s the why behind this approach.</p>
<p>Jeremy started coding hands-own a bird or park classifier, which was considered as a very difficult problem in 2015. Even a comic depicted this. Yet things have changed so drastically in past few years, that it’s very easy to do that now.</p>
<blockquote class="blockquote">
<p>Yet let’s look, why we couldn’t build a bird classifer in 2015:</p>
</blockquote>
<ul>
<li>For classifying histopothical images. They used computer vision techniques.</li>
<li>They got big team of datascientist, mathematicans with lot of features who build relevant feature for machine learning hand by hand.</li>
<li>These project took years</li>
<li>Also deep learning was not in radar for researchers then.</li>
</ul>
<blockquote class="blockquote">
<p>What has now changed? - Using neural network they build these features on their own. - Mathew D Zeiler &amp; Rob Fergus(and actual weights) showed with visualization how neural networks work - Combine all features to learn and go slowly in past, neural networks learned on it’s own these techniques.</p>
</blockquote>
<p>If it’s a bird or not? notebook can be <a href="https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data">found here</a>. I am slightly tweaking this model to leverage pytorch image-models released by timm.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-04-26T18:16:10.999504Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-04-26T18:16:10.999257Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-04-26T18:16:11.752066Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-04-26T18:16:11.751145Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-04-26T18:16:10.999476Z&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">urls <span class="op" style="color: #5E5E5E;">=</span> search_images(<span class="st" style="color: #20794D;">"bird photos"</span>, max_images<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-2">urls[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-04-26T18:16:21.682492Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-04-26T18:16:21.682259Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-04-26T18:16:29.417344Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-04-26T18:16:29.416565Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-04-26T18:16:21.682466Z&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> fastdownload <span class="im" style="color: #00769E;">import</span> download_url</span>
<span id="cb2-2"></span>
<span id="cb2-3">dest <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"bird.jpg"</span></span>
<span id="cb2-4">download_url(urls[<span class="dv" style="color: #AD0000;">0</span>], dest, show_progress<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="im" style="color: #00769E;">from</span> fastai.vision.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb2-7"></span>
<span id="cb2-8">im <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(dest)</span>
<span id="cb2-9">im.to_thumb(<span class="dv" style="color: #AD0000;">256</span>, <span class="dv" style="color: #AD0000;">256</span>)</span></code></pre></div>
</div>
<p><strong>Note:</strong></p>
<ul>
<li><p>Image based algorithms, are not for images. Image for music classification by Deolho, Ethan sutin sounds from image recognizer. You can do music classification, with some creativity using cnns.</p></li>
<li><p>Also needing lots of data is a myth created by companies who sell data processng units. There are lot of free resources like Kaggle, Colab etc.</p></li>
</ul>
<blockquote class="blockquote">
<p>Observation by Jeremy: Tensorflow is slowly dying. Check this <a href="https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/">article which he cited</a>. Yet pytorch has lot of hairy code, which can be solved using good abstractions in fastai.</p>
</blockquote>
<ul>
<li>fastai library tries to provide good and the best fine-tuned models, which work well compared to other libraries. He showed code required for implementing AdamW in pytorch and in fastai.</li>
</ul>
<p><a href="https://tmabraham.github.io/">Tanishq Abraham</a> pointed me to implemtation of AdamW to <a href="https://github.com/fastai/fastbook/blob/master/16_accel_sgd.ipynb">chapter 16 in fastbook</a>.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-04-26T18:17:00.190847Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-04-26T18:17:00.190553Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-04-26T18:18:24.633396Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-04-26T18:18:24.632506Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-04-26T18:17:00.190811Z&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">download_url(</span>
<span id="cb3-2">    search_images(<span class="st" style="color: #20794D;">"forest photos"</span>, max_images<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)[<span class="dv" style="color: #AD0000;">0</span>], <span class="st" style="color: #20794D;">"forest.jpg"</span>, show_progress<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span></span>
<span id="cb3-3">)</span>
<span id="cb3-4">Image.<span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">"forest.jpg"</span>).to_thumb(<span class="dv" style="color: #AD0000;">256</span>, <span class="dv" style="color: #AD0000;">256</span>)</span>
<span id="cb3-5"></span>
<span id="cb3-6">searches <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"forest"</span>, <span class="st" style="color: #20794D;">"bird"</span></span>
<span id="cb3-7">path <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">"bird_or_not"</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> searches:</span>
<span id="cb3-10">    dest <span class="op" style="color: #5E5E5E;">=</span> path <span class="op" style="color: #5E5E5E;">/</span> o</span>
<span id="cb3-11">    dest.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, parents<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-12">    download_images(dest, urls<span class="op" style="color: #5E5E5E;">=</span>search_images(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>o<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> photo"</span>))</span>
<span id="cb3-13">    resize_images(path <span class="op" style="color: #5E5E5E;">/</span> o, max_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">400</span>, dest<span class="op" style="color: #5E5E5E;">=</span>path <span class="op" style="color: #5E5E5E;">/</span> o)</span></code></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-04-26T18:18:24.636177Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-04-26T18:18:24.635356Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-04-26T18:18:25.509264Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-04-26T18:18:25.508513Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-04-26T18:18:24.636135Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">failed <span class="op" style="color: #5E5E5E;">=</span> verify_images(get_image_files(path))</span>
<span id="cb4-2">failed.<span class="bu" style="color: null;">map</span>(Path.unlink)</span>
<span id="cb4-3"><span class="bu" style="color: null;">len</span>(failed)</span></code></pre></div>
</div>
<p>As the code showed, data cleaning is a big part of machine learninng. When we are learning this course as practitioners, we will spend lot of time of building and loading models. Like in compiler course lot of time is not spend on techniques, but on getting the environment up and ready.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-04-26T18:18:56.966471Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-04-26T18:18:56.966200Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-04-26T18:19:02.281502Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-04-26T18:19:02.280708Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-04-26T18:18:56.966440Z&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">dls <span class="op" style="color: #5E5E5E;">=</span> DataBlock(</span>
<span id="cb5-2">    blocks<span class="op" style="color: #5E5E5E;">=</span>(ImageBlock, CategoryBlock),</span>
<span id="cb5-3">    get_items<span class="op" style="color: #5E5E5E;">=</span>get_image_files,</span>
<span id="cb5-4">    splitter<span class="op" style="color: #5E5E5E;">=</span>RandomSplitter(valid_pct<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>, seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">42</span>),</span>
<span id="cb5-5">    get_y<span class="op" style="color: #5E5E5E;">=</span>parent_label,</span>
<span id="cb5-6">    item_tfms<span class="op" style="color: #5E5E5E;">=</span>[Resize(<span class="dv" style="color: #AD0000;">224</span>, method<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"squish"</span>)],</span>
<span id="cb5-7">).dataloaders(path)</span>
<span id="cb5-8"></span>
<span id="cb5-9">dls.show_batch()</span></code></pre></div>
</div>
<p>After examining, 100s of project and datascience requirments. fastai came up with this approach of DataBlock, which consists of five things:</p>
<ol type="1">
<li>blocks</li>
<li>get_items</li>
<li>splitter</li>
<li>Batch_tfms(optional)</li>
<li>get_y</li>
<li>item_tfms</li>
</ol>
<p>Without validation data, it won’t allow to train. parent_label, return parent folder. we saved as forests or birds. We need same size. Idea to do quickly, why not publish vision_learners with pets dataset.</p>
<p><strong>Now it’s time to train our model</strong></p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-04-26T18:20:47.879917Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-04-26T18:20:47.879147Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-04-26T18:21:20.299499Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-04-26T18:21:20.298718Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-04-26T18:20:47.879882Z&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, <span class="st" style="color: #20794D;">"vit_tiny_patch16_224"</span>, metrics<span class="op" style="color: #5E5E5E;">=</span>error_rate)</span>
<span id="cb6-2"></span>
<span id="cb6-3">learn.fine_tune(<span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
</div>
<p>One thing which is cool is that the whole presentation is also made with Jupyter Notebooks using <a href="https://rise.readthedocs.io/en/stable/">RiseJS</a>. Also jupyter notebooks can be used for writing books like <a href="https://www.amazon.in/Deep-Learning-Coders-fastai-PyTorch/dp/9385889206/ref=asc_df_9385889206/?tag=googleshopdes-21&amp;linkCode=df0&amp;hvadid=397083287744&amp;hvpos=&amp;hvnetw=g&amp;hvrand=16600915651709325915&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1007777&amp;hvtargid=pla-992154494864&amp;psc=1&amp;ext_vrnc=hi">Deep Learning for Coders</a>, for blogging using <a href="https://fastpages.fast.ai/">fastpages</a>, for CI/CD pipeline to run in parallel execution in <a href="https://github.com/fastai/fastai">fastai repo</a>.</p>
<p>Tanishq Mathew Abraham has summarized on what can be done in this twitter threads.</p>
<blockquote class="blockquote">
<p>twitter: https://twitter.com/iScienceLuvr/status/1519242326517829632</p>
</blockquote>
<p>After this Jeremy, showed all the examples in Chapter 1 in Deep Learning for coders. My notes then:</p>
<p>We are still scratching the surface. Lot of marketing out there, some of first open source models available. The deep learning when it broke X, y, z in domain. In NLP it breaks lot of stuff</p>
<p>What’s really go in on : in arthur samuel with graph. The graphs are build with gv2 in jupyter notebook. Deploying models in ML is a bit tricky. But it’s just predict and shows results.</p>
<p><strong>Conclusion by Jeremy</strong></p>
<p>So after first lesson:</p>
<ol type="a">
<li>If you know python, then it’s kind of easy for you.</li>
<li>If don’t know python, it’s very difficult</li>
</ol>
<p>Regardless of what level you are. Experiment yourself and do something more complex. Go ahead and push yourself a little bit, but not much. Then present your work. Do stuff on things where you are interested.</p>



 ]]></description>
  <category>fastaicourse</category>
  <category>fastbook</category>
  <guid>https://kurianbenoy.com/posts/2022-04-26-fastai-51.html</guid>
  <pubDate>Tue, 26 Apr 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/jeremy.png" medium="image" type="image/png" height="53" width="144"/>
</item>
<item>
  <title>Building a fine-tuned translation system for English-Malayalam</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022-03-13-hfenml-translate.html</link>
  <description><![CDATA[ 




<section id="building-a-fine-tuned-translation-system-for-english-malayalam" class="level1">
<h1>Building a fine-tuned translation system for English-Malayalam</h1>
<p>Hey, everyone. We all are familiar with translation systems like using google translate. So today, let’s build a fine tuned translation system for converting text from english to malayalam. It’s built using Blurr library - built on top of Hugging face and fast.ai made by <a href="https://twitter.com/waydegilliam">Wayde Gilliam</a>. Also our translation system is going to be fine tuned on <a href="https://huggingface.co/datasets/kde4">top of KDE specific dataset</a>. You can find the trained model <a href="https://huggingface.co/kurianbenoy/kde_en_ml_translation_model">here</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/translate.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image</figcaption><p></p>
</figure>
</div>
<p><strong>Installation</strong></p>
<div class="cell" data-outputid="f35998f1-0e57-4361-cf42-24092a950dc4" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span> python3 <span class="op" style="color: #5E5E5E;">-</span>m pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq datasets<span class="op" style="color: #5E5E5E;">==</span> fastai<span class="op" style="color: #5E5E5E;">==</span><span class="fl" style="color: #AD0000;">2.6.3</span></span>
<span id="cb1-2"><span class="op" style="color: #5E5E5E;">!</span> python3 <span class="op" style="color: #5E5E5E;">-</span>m pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq transformers[sentencepiece]</span>
<span id="cb1-3"><span class="op" style="color: #5E5E5E;">!</span> python3 <span class="op" style="color: #5E5E5E;">-</span>m pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq ohmeow<span class="op" style="color: #5E5E5E;">-</span>blurr<span class="op" style="color: #5E5E5E;">==</span><span class="fl" style="color: #AD0000;">1.0.5</span></span>
<span id="cb1-4"><span class="op" style="color: #5E5E5E;">!</span> python3 <span class="op" style="color: #5E5E5E;">-</span>m pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq nltk</span>
<span id="cb1-5"><span class="op" style="color: #5E5E5E;">!</span> python3 <span class="op" style="color: #5E5E5E;">-</span>m pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq sacrebleu</span>
<span id="cb1-6"><span class="op" style="color: #5E5E5E;">!</span> python3 <span class="op" style="color: #5E5E5E;">-</span>m pip install <span class="op" style="color: #5E5E5E;">-</span>Uqq  git<span class="op" style="color: #5E5E5E;">+</span>https:<span class="op" style="color: #5E5E5E;">//</span>github.com<span class="op" style="color: #5E5E5E;">/</span>huggingface<span class="op" style="color: #5E5E5E;">/</span>huggingface_hub<span class="co" style="color: #5E5E5E;">#egg=huggingface-hub["fastai"]</span></span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>ERROR: Could not find a version that satisfies the requirement datasets== (from versions: 0.0.9, 1.0.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0, 1.2.1, 1.3.0, 1.4.0, 1.4.1, 1.5.0, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.2, 1.13.3, 1.14.0, 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.17.0, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 2.0.0, 2.1.0, 2.2.0)
ERROR: No matching distribution found for datasets==</code></pre>
</div>
</div>
<section id="loading-data" class="level2">
<h2 class="anchored" data-anchor-id="loading-data">Loading Data</h2>
<p>A translation system is an example of <a href="https://huggingface.co/course/chapter1/7?fw=pt">sequence to sequence models</a>, which is usually used for tasks which involves generating new data. Translation usually needs datasets in both the source language and target language (the language to which it needs to be translated).</p>
<p>We are using <a href="https://huggingface.co/datasets/kde4">KDE4 datasets</a>, and choose both source language and translation language as english and malayalam respectively. Usually these datasets are curated by community volunteers to their native language, and this was probably done by KDE community volunteers in Kerala. When someone is localizing these texts into there in local languague, usually computer science specific terms are still written in english.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">import</span> pandas</span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span></code></pre></div>
</div>
<div class="cell" data-outputid="a2970d8a-4b94-4fd7-aad6-f6b62b674b38" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">raw_datasets <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"kde4"</span>, lang1<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"en"</span>, lang2<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ml"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"train[:1000]"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using custom data configuration en-ml-lang1=en,lang2=ml
Reusing dataset kde4 (/home/.cache/huggingface/datasets/kde4/en-ml-lang1=en,lang2=ml/0.0.0/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac)</code></pre>
</div>
</div>
<p>Most of translation dataset is in form of id and translation json output - with both <code>en</code> and <code>ml</code> as objects.</p>
<div class="cell" data-outputid="0b86dbb4-4cac-41ab-e1cc-acddf66cc928" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">raw_datasets[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>{'id': '0',
 'translation': {'en': 'Add Feed to Akregator',
  'ml': 'അക്രിഗേറ്ററില്\u200d ഫീഡ് കൂട്ടിച്ചേര്\u200dക്കുക'}}</code></pre>
</div>
</div>
</section>
<section id="transforming-data-into-dataloaders" class="level2">
<h2 class="anchored" data-anchor-id="transforming-data-into-dataloaders">Transforming data into DataLoaders</h2>
<section id="importing-libraries-and-get-hugging-face-objects" class="level3">
<h3 class="anchored" data-anchor-id="importing-libraries-and-get-hugging-face-objects">Importing libraries and get hugging-face objects</h3>
<div class="cell" data-outputid="8d89be36-0c1c-48bb-b9af-1f0e25837947" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;">from</span> blurr.text.data.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb8-2"><span class="im" style="color: #00769E;">from</span> blurr.text.modeling.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb8-3"><span class="im" style="color: #00769E;">from</span> blurr.text.utils <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="im" style="color: #00769E;">from</span> fastai.data.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb8-6"><span class="im" style="color: #00769E;">from</span> fastai.callback.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb8-7"><span class="im" style="color: #00769E;">from</span> fastai.learner <span class="im" style="color: #00769E;">import</span> load_learner, Learner</span>
<span id="cb8-8"><span class="im" style="color: #00769E;">from</span> fastai.optimizer <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb8-9"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="9703cb05-b8db-45d9-cd7a-f177191bc0ba" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">pretrained_model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Helsinki-NLP/opus-mt-en-ml"</span></span>
<span id="cb9-2">model_cls <span class="op" style="color: #5E5E5E;">=</span> AutoModelForSeq2SeqLM</span>
<span id="cb9-3">hf_arch, hf_config, hf_tokenizer, hf_model <span class="op" style="color: #5E5E5E;">=</span> get_hf_objects(</span>
<span id="cb9-4">    pretrained_model_name, model_cls<span class="op" style="color: #5E5E5E;">=</span>model_cls</span>
<span id="cb9-5">)</span>
<span id="cb9-6"></span>
<span id="cb9-7">hf_arch, <span class="bu" style="color: null;">type</span>(hf_config), <span class="bu" style="color: null;">type</span>(hf_tokenizer), <span class="bu" style="color: null;">type</span>(hf_model)</span></code></pre></div>
</div>
<div class="cell" data-outputid="2957c1fd-93f7-479c-b7cd-6610db09b0eb" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">translation_df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(raw_datasets[<span class="st" style="color: #20794D;">"translation"</span>], columns<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"en"</span>, <span class="st" style="color: #20794D;">"ml"</span>])</span>
<span id="cb10-2">translation_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>en</th>
      <th>ml</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Add Feed to Akregator</td>
      <td>അക്രിഗേറ്ററില്‍ ഫീഡ് കൂട്ടിച്ചേര്‍ക്കുക</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Add Feeds to Akregator</td>
      <td>അക്രിഗേറ്ററില്‍ ഫീഡുകള്‍ കൂട്ടിച്ചേര്‍ക്കുക</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Add All Found Feeds to Akregator</td>
      <td>എല്ലാ ഫീഡുകളും അക്രിഗേറ്ററില്‍ കൂട്ടിച്ചേര്‍ക്കുക</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Subscribe to site updates (using news feed)</td>
      <td>സൈറ്റുകളിലെ പുതുമകളറിയാന്‍ വരിക്കാരനാകുക (വാര്‍ത്താ ഫീഡുകള്‍ ഉപയോഗിച്ചു്)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Imported Feeds</td>
      <td>എടുത്ത ഫീഡുകള്‍</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">blocks <span class="op" style="color: #5E5E5E;">=</span> (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)</span>
<span id="cb11-2">dblock <span class="op" style="color: #5E5E5E;">=</span> DataBlock(</span>
<span id="cb11-3">    blocks<span class="op" style="color: #5E5E5E;">=</span>blocks,</span>
<span id="cb11-4">    get_x<span class="op" style="color: #5E5E5E;">=</span>ColReader(<span class="st" style="color: #20794D;">"en"</span>),</span>
<span id="cb11-5">    get_y<span class="op" style="color: #5E5E5E;">=</span>ColReader(<span class="st" style="color: #20794D;">"ml"</span>),</span>
<span id="cb11-6">    splitter<span class="op" style="color: #5E5E5E;">=</span>RandomSplitter(),</span>
<span id="cb11-7">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="5df2d528-999e-40c3-c4a7-8b8452118cbe" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">dls <span class="op" style="color: #5E5E5E;">=</span> dblock.dataloaders(translation_df, bs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb12-2">dls.show_batch(dataloaders<span class="op" style="color: #5E5E5E;">=</span>dls, max_n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, input_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100</span>, target_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">250</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A▁version▁control▁history▁entry▁consists of▁several▁lines.▁Specify the▁regular▁expression▁to▁detect</td>
      <td>ഒരു ഭാഷാന്തര നിയന്ത്രണത്തിന്റെ നാള്വഴി ചേര്ക്കുന്നതില് പല വരികളുണ്ടാകും. ആദ്യത്തെ വരി കണ്ടുപിടിക്കാനുള്ള നിത്യഭാവം നിര്ദ്ദേശിക്കുക (മുന്നിലെ വിശദീകരണം കൂടാതെ). ഇനം തിരിക്കാനുപയോഗിക്കുന്ന കീകളെ ഒന്നിച്ചാക്കാന് ബ്രാക്കറ്റുകള് ഉപയോഗിക്കുക. ഒഴിച്ചു വിട്ട</td>
    </tr>
    <tr>
      <th>1</th>
      <td>▁Mailody▁can▁store▁all▁attchements of▁all▁messages in▁a▁certain▁folder.▁Then▁you▁never▁have▁to▁save▁</td>
      <td>എല്ലാ സന്ദേശങ്ങളുടേയും എല്ലാ അനുബന്ധങ്ങളും ഒരു പ്രത്യേക അറയില് സൂക്ഷിക്കാന് മെയിലഡിക്ക് കഴിയും. നിങ്ങള്ക്കവയെ സന്ദേശങ്ങളില്നിന്ന് പ്രത്യേകം സൂക്ഷിക്കേണ്ടതില്ല. അവ അറയില് ഉണ്ടായിരിക്കും. പ്രത്യേകം ശ്രദ്ധിക്കുക, ഈ അറ ഇടക്കിടക്ക് കാലിയാക്കിക്കൊണ്ടിരിക്ക</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
</section>
<section id="training-fine-tuned-translation-system" class="level2">
<h2 class="anchored" data-anchor-id="training-fine-tuned-translation-system">Training fine-tuned translation system</h2>
<section id="using-blurr-high-level-api" class="level3">
<h3 class="anchored" data-anchor-id="using-blurr-high-level-api">Using blurr High-level API</h3>
<p>Bugs in ohmeow v1.0.4 has been fixed by the <a href="https://github.com/ohmeow/">open-source maintainer</a>.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;">from</span> blurr.text.utils <span class="im" style="color: #00769E;">import</span> BlurrText</span>
<span id="cb13-2"></span>
<span id="cb13-3">NLP <span class="op" style="color: #5E5E5E;">=</span> BlurrText()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">learn <span class="op" style="color: #5E5E5E;">=</span> BlearnerForTranslation.from_data(</span>
<span id="cb14-2">    translation_df,</span>
<span id="cb14-3">    pretrained_model_name,</span>
<span id="cb14-4">    src_lang_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"English"</span>,</span>
<span id="cb14-5">    src_lang_attr<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"en"</span>,</span>
<span id="cb14-6">    trg_lang_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Malayalam"</span>,</span>
<span id="cb14-7">    trg_lang_attr<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ml"</span>,</span>
<span id="cb14-8">    dl_kwargs<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"bs"</span>: <span class="dv" style="color: #AD0000;">16</span>},</span>
<span id="cb14-9">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="b19c8d45-ed6d-4d15-b6d3-05d5449fcf6c" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">metrics_cb <span class="op" style="color: #5E5E5E;">=</span> BlearnerForTranslation.get_metrics_cb()</span>
<span id="cb15-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">1</span>, lr_max<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">4e-5</span>, cbs<span class="op" style="color: #5E5E5E;">=</span>[metrics_cb])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package wordnet to /home/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /home/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>bleu</th>
      <th>meteor</th>
      <th>sacrebleu</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5.512897</td>
      <td>4.821253</td>
      <td>0.023251</td>
      <td>0.158193</td>
      <td>4.086147</td>
      <td>00:19</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-outputid="ef232a13-fe25-47bf-f688-16970c2fa37a" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">learn.show_results(learner<span class="op" style="color: #5E5E5E;">=</span>learn, input_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>, target_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">250</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>▁Mailody▁is▁able▁to▁convert▁your▁plain▁message▁to▁a▁html▁message▁and▁include▁that in the▁outgoing▁message.▁This▁means the▁receiver▁will▁also▁have▁clickable▁links▁and▁colored▁quote▁levels.</td>
      <td>നിങ്ങളുടെ സാദാ സന്ദേശം എച്ച്ടിഎംഎല് സന്ദേശമാക്കി മാറ്റി അത് പുറത്തേക്ക് അയക്കുന്ന സന്ദേശത്തില് ഉള്പ്പെടുത്താന് മെയിലഡിക്കു കഴിയും. അതായത് ഞൊട്ടാവുന്ന കണ്ണികളും വര്ണ്ണ ഉദ്ധരണി തലവും സ്വീകര്ത്താവിനുകൂടി ലഭ്യമാവും</td>
      <td>[നിങ്ങളുടെ സമ്പാദന സന്ദേശം ഒരു html സന്ദേശമാക്കി മാറ്റുവാനും പുറത്തുള്ള സന്ദേശത്തിൽ ഉൾ ക്കൊള്ളുന്ന സന്ദേശത്തിൽ ഉൾപ്പെടുത്തുവാനും Middiയ്ക്കു് കഴിയും. ഇതിനർത്ഥം റിക്കോർഡ് ചെയ്യാവുന്ന കണ്ണികള്ക്കും നിറങ്ങള്ക്കും വലക്കെട്ടുകളും നിറങ്ങള്ക്കു്., പതിപ്പ് നിയന്ത്രിത ചരിത്രത്തിന്റെ പ്രാരംഭമായതിന്റെ സാധാരണ പ്രയോഗം. സാധാരണയായി ഈ വരിയിൽ "$2Loux" കീവാതകം ഉണ്ട്. സ്വതവേയുള്ള മൂല്ല്യം: description from play played for play play for play for play play play for filme cout fillulume for for courtyourtime fume time ck., തുടങ്ങുന്നതിനായി, "പുതിയ" തെരഞ്ഞെടുത്ത് ആദ്യം ഒരു പുതിയ ഒപ്പ് ഉണ്ടാക്കുക. അപ്പോൾ നിങ്ങൾക്കു് തിരുത്താനും ഒപ്പുകളുടെ ശേഖരം സംരക്ഷിക്കാനും സാധിക്കും., തിരുത്ത് ചെയ്ത ഫയൽ സൂക്ഷിയ്ക്കുമ്പോൾ വരിയുടെ അവസാനങ്ങൾ സജ്ജീകരിയ്ക്കുന്നു. ഡോഎസ്/ ജാലകങ്ങൾ: CRS+LLF; യുഎഫ്: LRIFX; ഒപ്പം CRL++D=0, LRD=0A, LRFAA +0A, മുൻകാഴ്ചകൾ പരിശോധിക്കൽ പരാജയം. ഈ കമാൻഡ് പരിശോധിയ്ക്കുക:% 1 എന്ന ആജ്ഞ ഇപ്പോൾ പ്രവർത്തനരഹിതമായിരിക്കും., "Subject" അല്ലെങ്കിൽ 'suck' ഒരു ആഴത്തിലുള്ള അവസ്ഥയാണ്, സിസ്റ്റം പൂർണ്ണമായും അധികാരത്തിൽ കൊണ്ടുവരുന്നു, സസ്പെൻഡ് ഒരു നിദ്രാ സംസ്ഥാനമാണ്, സിസ്റ്റം ഊർജ്ജം കുറയ്ക്കുമ്പോള് മാത്രം ഊർജ്ജം സംഭരിക്കുക മാത്രമേ ഉള്ളൂ., ഈ മുൻകരുതൽ ലൈനിംഗ് ലൈനിംഗ് ലൈനിംഗ് വേളയിൽ മാത്രമേ ഉപയോഗമുള്ളു. ( വിശദാംശങ്ങൾക്ക് ഡോക്സ് കാണുക.), ഫയലിന്റെ പകർപ്പ് പ്രക്രിയയില് പിശക്: വായനയ്ക്കുള്ള ഫയൽ തുറക്കുന്നതിൽ പരാജയം:% 1, ▪ മാമോദീസ തുറന്നു നോക്കുകയും അടയ് ക്കുകയും ചെയ്യുന്നത് ക്രമമായ പ്രയോഗത്തിൽ ചേരുകയില്ല., എല്ലാ ഉപയോക്താക്കൾക്കും ആപ്പിൾട്ടുകൾ ഇൻസ്റ്റോൾ ചെയ്യുകയോ നീക്കം ചെയ്യുകയോ ചെയ്യുക., ഫയലിന്റെ പകർപ്പ് പ്രക്രിയയില് പിശക്: വായന പരാജയപ്പെട്ടു:% 1, വൈരുദ്ധ്യങ്ങളുടെ എണ്ണം സംബന്ധിച്ച് ഒരു സംവാദം കാണിക്കുക., നിങ്ങൾ ബാറ്ററി അധികാരത്തിൽ നിന്നും ഓടി രക്ഷപെടാൻ പോവുകയാണ്, ഇപ്പോൾ ഒന്നും ചെയ്യാനില്ല., വിലാസങ്ങള് ചേർത്തിട്ടില്ല. അയയ്ക്കുന്നതിന് മുമ്പ് കുറഞ്ഞത് ഒന്നെങ്കിലും ചേർക്കൂ., ക്ഷമിക്കണം, നിങ്ങളുടെ ഫോണൺ പതിപ്പ് പിന്തുണയ്ക്കുന്നില്ല.]</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
<section id="using-mid-level-of-blurr-apis" class="level3">
<h3 class="anchored" data-anchor-id="using-mid-level-of-blurr-apis">Using mid-level of blurr APIs</h3>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">b <span class="op" style="color: #5E5E5E;">=</span> dls.one_batch()</span></code></pre></div>
</div>
<div class="cell" data-outputid="b4319724-837b-42f2-83e6-b1e8a1ac619d" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="bu" style="color: null;">len</span>(b), b[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">"input_ids"</span>].shape, b[<span class="dv" style="color: #AD0000;">1</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(2, torch.Size([16, 72]), torch.Size([16, 114]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="6dbfeaa9-a0c9-4f66-db5c-ef0855d91172" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">dls.show_batch(dataloaders<span class="op" style="color: #5E5E5E;">=</span>dls, input_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">250</span>, target_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">250</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A▁version▁control▁history▁entry▁consists of▁several▁lines.▁Specify the▁regular▁expression▁to▁detect the▁first▁line (without the▁leading▁comment).▁Use▁parentheses▁to▁group the▁keys▁you▁want▁to▁use▁for▁sorting.▁If▁left▁empty,▁then▁KDiff3▁assumes▁that▁e</td>
      <td>ഒരു ഭാഷാന്തര നിയന്ത്രണത്തിന്റെ നാള്വഴി ചേര്ക്കുന്നതില് പല വരികളുണ്ടാകും. ആദ്യത്തെ വരി കണ്ടുപിടിക്കാനുള്ള നിത്യഭാവം നിര്ദ്ദേശിക്കുക (മുന്നിലെ വിശദീകരണം കൂടാതെ). ഇനം തിരിക്കാനുപയോഗിക്കുന്ന കീകളെ ഒന്നിച്ചാക്കാന് ബ്രാക്കറ്റുകള് ഉപയോഗിക്കുക. ഒഴിച്ചു വിട്ട</td>
    </tr>
    <tr>
      <th>1</th>
      <td>▁There▁is▁no▁Inbox▁found in▁any▁resource.▁Starting▁a▁new▁message▁will▁cause the▁message▁to▁be▁lost▁after▁you▁have▁sent▁it.▁You▁will▁not▁have▁a▁local▁copy▁anymore.▁If▁you▁want▁a▁copy,▁one▁way▁to▁do▁this▁is▁to▁add▁yourself▁as▁a CC▁to the▁message.&lt;pad&gt;&lt;</td>
      <td>വിഭവങ്ങളിലൊന്നും ഒരു ഇന്ബോക്സ് കാണുന്നില്ല. ഒരു പുതിയ സന്ദേശം തുടങ്ങുന്നത് അത് അയച്ച ശേഷം നഷ്ടപ്പെടാന് കാരണമാകും. പ്രാദേശിക പകര്പ്പുകളൊന്നും ഒരിക്കലും ലഭ്യമല്ലാതാവും. ഉദാഹരണമായി ഒരു പകര്പ്പ് ആവശ്യമുണ്ടെങ്കില് ഒരു കാര്ബണ് പതിപ്പുകൂടി കൂട്ടിച്ചേര്ത്തതാ</td>
    </tr>
    <tr>
      <th>2</th>
      <td>▁To▁prevent▁data▁loss▁or▁other▁damage,▁you▁can▁have the▁system suspend▁or▁hibernate,▁so▁you▁do▁not▁accidentally▁run▁out of▁battery▁power.▁Configure the▁number of▁minutes▁below▁which the▁machine▁will▁run the▁configured▁action.&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>
      <td>വിവരനഷ്ടമോ ഹാനിയോ തടയാന്, സിസ്റ്റം മയങ്ങുകയോ ശിശിരനിദ്രയിലാകുകയോചെയ്യാവുന്നതാണ്, അങ്ങനെ ആകസ്മികമായിട്ടുപോലും ബാറ്ററി ഊര്ജ്ജം തീരാതിരിയ്ക്കും. ക്രമീകരിച്ച നടപടിയുമായി മുന്നോട്ടു് പോകേണ്ടതു് എത്ര മിനിറ്റുകളില് താഴെയാകുമ്പോഴാണെന്നു് താഴെ ക്രമീകരിയ്ക്കുക</td>
    </tr>
    <tr>
      <th>3</th>
      <td>▁AutoSync▁is▁a▁feature▁from MP3tunes▁which▁allows▁you▁to▁automatically▁move▁your▁music▁between▁computers▁and▁devices.▁You▁can▁upload▁music▁from▁one▁location▁and▁have▁it▁download▁instantly▁to▁other▁locations.&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pa</td>
      <td>Enable harmony</td>
    </tr>
    <tr>
      <th>4</th>
      <td>▁Regular▁expression▁for▁lines▁where▁KDiff3▁should▁automatically▁choose▁one▁source.▁When▁a▁line▁with▁a▁conflict▁matches the▁regular▁expression▁then -▁if▁available - C,▁otherwise B▁will▁be▁chosen.&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;</td>
      <td>കെഡിഫ്3 സ്വതന്ത്രമായി ഒരു സ്രോതസ്സ് തെരഞ്ഞെടുക്കുന്നിടത്ത് വരികള്ക്കുള്ള നിത്യഭാവം. സംഘട്ടനമുള്ള വരി ചേര്ന്നുവരുമ്പോള് അതിന്റെ നിത്യഭാവം - സി ഉണ്ടെങ്കില് അത്, അല്ലെങ്കില് ബി തെരഞ്ഞെടുക്കപ്പെടും.</td>
    </tr>
    <tr>
      <th>5</th>
      <td>▁Loading▁external▁images▁gives▁spammers the▁acknowledgement▁that▁you▁received▁this▁message▁so▁they▁will▁use▁your▁email▁address▁to▁spam▁you.▁So▁you▁should▁only▁continue▁for▁very▁trusted▁messages.&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;</td>
      <td>പുറമെനിന്നൊരു ചിത്രം കയറ്റുന്നത് നിങ്ങള്ക്ക് ഈ സന്ദേശം ലഭിച്ചെന്ന മടക്കരശീതി ചവറയയ്ക്കുന്നവര്ക്ക് ലഭിച്ചേക്കാം. അവര് നിങ്ങളുട ഇതപാല് വിലാസം നിങ്ങള്ക്കു് നേരേയും ചവറയയ്ക്കാനുപയോഗിച്ചേക്കാം. അതുകൊണ്ട് വളരെ വിശ്വസ്ത സന്ദേശങ്ങള് മാത്രം തുടര്ന്നാല് മതി.</td>
    </tr>
    <tr>
      <th>6</th>
      <td>▁Mailody▁is▁able▁to▁convert▁your▁plain▁message▁to▁a▁html▁message▁and▁include▁that in the▁outgoing▁message.▁This▁means the▁receiver▁will▁also▁have▁clickable▁links▁and▁colored▁quote▁levels.&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pa</td>
      <td>നിങ്ങളുടെ സാദാ സന്ദേശം എച്ച്ടിഎംഎല് സന്ദേശമാക്കി മാറ്റി അത് പുറത്തേക്ക് അയക്കുന്ന സന്ദേശത്തില് ഉള്പ്പെടുത്താന് മെയിലഡിക്കു കഴിയും. അതായത് ഞൊട്ടാവുന്ന കണ്ണികളും വര്ണ്ണ ഉദ്ധരണി തലവും സ്വീകര്ത്താവിനുകൂടി ലഭ്യമാവും</td>
    </tr>
    <tr>
      <th>7</th>
      <td>▁You▁have▁clicked▁on▁a▁link▁which▁might▁not▁indicate▁correctly▁where▁you▁are▁really▁going▁to.▁Please▁check▁if▁you▁really▁want▁to▁view▁a▁page▁on▁this▁server:▁%1▁Do▁you▁want▁to▁go▁there?&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;</td>
      <td>നിങ്ങള് ഒരു കണ്ണിയില് ഞൊട്ടിയത് നിങ്ങളെവിടേക്കാണ് വാസ്തവത്തില് പോകുന്നത് എന്ന് കൃത്യമായി സൂചിപ്പിക്കുന്നില്ല. ഇ സേവകന്റെ താളിലേക്കു തന്നെ യാണോ പോകേണ്ടതെന്ന് പരിശോധിക്കുക:% 1 നിങ്ങള്ക്കിവിടെ പോകണോ?</td>
    </tr>
    <tr>
      <th>8</th>
      <td>▁Try▁to▁align B▁and C▁when▁comparing▁or▁merging▁three input▁files.▁Not▁recommended▁for▁merging▁because▁merge▁might▁get▁more▁complicated. (Default▁is▁off.)&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;</td>
      <td>അകത്തുവിടാനുള്ള 3ഫയലുകള് താരതമ്യമ് ചെയ്യുമ്പോഴോ ലയനം നടത്തുമ്പോഴോബിയും സിയും നിരഒപ്പിക്കാന് ശ്രമിക്കണം. കൂടുതല് കുഴപ്പം പിടിച്ചതായതുകൊണ്ട് ലയനത്തിന്റെ കാര്യത്തില് അത് ശുപാര്ശ ചെയ്തിട്ടില്ല. (ഓഫ് ആണ് സഹജം.)</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-outputid="c3827f61-c90c-4bfe-88bd-90c04b3e3acd" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">seq2seq_metrics <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb22-2">    <span class="st" style="color: #20794D;">"bleu"</span>: {<span class="st" style="color: #20794D;">"returns"</span>: <span class="st" style="color: #20794D;">"bleu"</span>},</span>
<span id="cb22-3">    <span class="st" style="color: #20794D;">"meteor"</span>: {<span class="st" style="color: #20794D;">"returns"</span>: <span class="st" style="color: #20794D;">"meteor"</span>},</span>
<span id="cb22-4">    <span class="st" style="color: #20794D;">"sacrebleu"</span>: {<span class="st" style="color: #20794D;">"returns"</span>: <span class="st" style="color: #20794D;">"score"</span>},</span>
<span id="cb22-5">}</span>
<span id="cb22-6"></span>
<span id="cb22-7">model <span class="op" style="color: #5E5E5E;">=</span> BaseModelWrapper(hf_model)</span>
<span id="cb22-8">learn_cbs <span class="op" style="color: #5E5E5E;">=</span> [BaseModelCallback]</span>
<span id="cb22-9">fit_cbs <span class="op" style="color: #5E5E5E;">=</span> [Seq2SeqMetricsCallback(custom_metrics<span class="op" style="color: #5E5E5E;">=</span>seq2seq_metrics)]</span>
<span id="cb22-10"></span>
<span id="cb22-11">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(</span>
<span id="cb22-12">    dls,</span>
<span id="cb22-13">    model,</span>
<span id="cb22-14">    opt_func<span class="op" style="color: #5E5E5E;">=</span>partial(Adam),</span>
<span id="cb22-15">    loss_func<span class="op" style="color: #5E5E5E;">=</span>PreCalculatedCrossEntropyLoss(),  <span class="co" style="color: #5E5E5E;"># CrossEntropyLossFlat()</span></span>
<span id="cb22-16">    cbs<span class="op" style="color: #5E5E5E;">=</span>learn_cbs,</span>
<span id="cb22-17">    splitter<span class="op" style="color: #5E5E5E;">=</span>partial(blurr_seq2seq_splitter, arch<span class="op" style="color: #5E5E5E;">=</span>hf_arch),</span>
<span id="cb22-18">)</span>
<span id="cb22-19"></span>
<span id="cb22-20">learn.freeze()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package wordnet to /home/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /home/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!</code></pre>
</div>
</div>
<div class="cell" data-outputid="62277fb8-a4bd-45f4-9eab-a193f828ff46" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">learn.lr_find(suggest_funcs<span class="op" style="color: #5E5E5E;">=</span>[minimum, steep, valley, slide])</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>SuggestedLRs(minimum=0.00010000000474974513, steep=2.75422871709452e-06, valley=0.00013182566908653826, slide=0.2089296132326126)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://kurianbenoy.com/posts/2022-03-13-hfenml-translate_files/figure-html/cell-19-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="655a9a61-3ebe-4442-8b04-dc814d181196" data-execution_count="20">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">15</span>, lr_max<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">5e-4</span>, cbs<span class="op" style="color: #5E5E5E;">=</span>fit_cbs)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>bleu</th>
      <th>meteor</th>
      <th>sacrebleu</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5.345715</td>
      <td>4.811335</td>
      <td>0.038182</td>
      <td>0.183787</td>
      <td>5.607312</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>4.658613</td>
      <td>4.272337</td>
      <td>0.058925</td>
      <td>0.206963</td>
      <td>3.932045</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>2</td>
      <td>4.196794</td>
      <td>4.031921</td>
      <td>0.069354</td>
      <td>0.167185</td>
      <td>4.876618</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.826715</td>
      <td>4.102871</td>
      <td>0.071109</td>
      <td>0.122637</td>
      <td>4.639123</td>
      <td>00:18</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.551352</td>
      <td>4.046614</td>
      <td>0.080512</td>
      <td>0.202187</td>
      <td>6.996449</td>
      <td>00:26</td>
    </tr>
    <tr>
      <td>5</td>
      <td>3.329875</td>
      <td>3.928597</td>
      <td>0.054780</td>
      <td>0.179460</td>
      <td>3.403195</td>
      <td>00:53</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.197556</td>
      <td>3.818610</td>
      <td>0.109263</td>
      <td>0.212960</td>
      <td>9.055532</td>
      <td>00:21</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.034615</td>
      <td>3.821332</td>
      <td>0.100355</td>
      <td>0.200819</td>
      <td>8.208149</td>
      <td>00:20</td>
    </tr>
    <tr>
      <td>8</td>
      <td>2.900438</td>
      <td>3.807550</td>
      <td>0.101014</td>
      <td>0.222323</td>
      <td>7.221607</td>
      <td>00:35</td>
    </tr>
    <tr>
      <td>9</td>
      <td>2.820454</td>
      <td>3.813579</td>
      <td>0.111548</td>
      <td>0.219794</td>
      <td>9.026264</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>10</td>
      <td>2.756891</td>
      <td>3.791952</td>
      <td>0.107236</td>
      <td>0.223636</td>
      <td>9.965611</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>11</td>
      <td>2.740331</td>
      <td>3.809624</td>
      <td>0.115999</td>
      <td>0.239258</td>
      <td>10.261043</td>
      <td>00:24</td>
    </tr>
    <tr>
      <td>12</td>
      <td>2.685602</td>
      <td>3.804891</td>
      <td>0.126693</td>
      <td>0.234446</td>
      <td>11.131677</td>
      <td>00:22</td>
    </tr>
    <tr>
      <td>13</td>
      <td>2.653799</td>
      <td>3.800799</td>
      <td>0.119988</td>
      <td>0.227742</td>
      <td>10.985718</td>
      <td>00:23</td>
    </tr>
    <tr>
      <td>14</td>
      <td>2.636473</td>
      <td>3.801427</td>
      <td>0.124357</td>
      <td>0.229134</td>
      <td>10.967688</td>
      <td>00:25</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-outputid="e5301994-a323-4eff-f28f-6f2c9b88169f" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">learn.show_results(learner<span class="op" style="color: #5E5E5E;">=</span>learn, input_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>, target_trunc_at<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>▁With▁a▁dynamic▁playlist, Amarok▁becomes▁your▁own▁personal▁dj,▁automatically▁selecting▁tracks▁for▁you,▁based▁on▁a▁number of▁parameters▁that▁you▁select.</td>
      <td>Turn dynamic mode on</td>
      <td>[Username for logins to disabled, format: Artist - Track (Album), from the currently playlist column name and token for playlist layouts, വരികളിലെ അക്ഷരങ്ങളുടെ അവസ്ഥ വിഗണിക്കുക. (മുന്നിലെ വിവരങ്ങളുമായി താരതമ്യം ചെയ്യാനും സിമുലേറ്ററിക്ക് കഴിയും.), ഒരു ടാബ് മാത്രമേ ഉപയോഗിക്കൂ. ഒരു ചെറിയ ടാബ് ബാറ്ററിയില്ലാതെ സ്വയം ടാബ് ബാറ്ററി യാന്ത്രികമായി മറയ്ക്കുന്നു. ഒരു ടാബ് മാത്രമേ ഉപയോഗിക്കൂ., ഇത്തരം പ്രകടനം തുടങ്ങുമ്പോള്꠱, മെയിലഡികളിൽ ചിരിച്ചതായി സ്വയമേവ ലയിപ്പിക്കുക. ഉദാഹരണമായി ഒരു അക്ഷരരൂപം പരിശോധിക്കുന്നുണ്ടോയെന്ന് പരിശോധിക്കാതെ സ്വയം ചിരിച്ചുകൊണ്ടാവും., മുന്꠱ജ്ജ് ഉപയോഗിച്ചുകൊണ്ട് പരാജയപ്പെട്ടു. ഈ ആജ്ഞ പരിശോധിക്കൂ:% 1 മുന്꠱നടപടി ആജ്ഞ ഇപ്പോൾ പ്രവര് പശ്ചാത്തപിക്കുകത്തനരഹിതമാക്കും., പുറമെനിന്ന്- മിച്ചമുള്ള മട്ടും പ്രാവർത്തികമാക്കുന്നു. വലിയ ഫയലുകളെക്കുറിച്ചുള്ള പരിശോധകന്റെ പരിശോധകനുഭവം വളരെ പതുക്കെയാവും., ഈ സ്ലൈഡനുപയോഗിച്ചു്, സിസ്റ്റം സോക്കറ്റ് പുറത്തേയ്ക്കു് പതിക്കുന്നു, പുറത്താക്കുവാനുള്ള മെയിലഡിഭാഗം ലഭ്യമല്ല, ദയവായി അത് അയക്കുന്നതിന് മുമ്പായി ക്രമീകരിയ്ക്കുക, ഈ മുന്꠱ പൂര്꠱വ്വ പ്രക്രിയയ്ക്കുള്ള സമയത്ത് വരിയില്꠱ മാത്രമേ ഉപയോഗിക്കൂ. (വിശദീകരണങ്ങള്ക്ക് പ്രമാണപത്രം നോക്കുക.), ഫയല്꠱ പകര്꠱പ്പെടുക്കുമ്പോള്꠱ പിശക്: ഫയലില്♬ വായനയ്ക്കുള്ള ഫയല്꠱ തുറക്കുന്നത് പരാജയപ്പെട്ടു. ഫയല് പശ്ചാത്തപിക്കുക നാമം:% 1, നിങ്ങളുപയോഗിക്കുന്ന ബീഗിള്꠱ ബാക്കെന് പശ്ചാത്തപിക്കുകഡുകള്꠱ തെരഞ്ഞെടുക്കുക., ഉപയോക്താവ്നാമം തിരിച്ചറിഞ്ഞിട്ടില്ല, അല്ലെങ്കിൽ പാറ്റേണുകളിലെ അടയാളമിടുക., അനുബന്ധങ്ങളുടെ അളവ്% 1 is new name for translate is the filter, representing the playlist column name and token for playlist layouts, ബാറ്ററികളിലെത്തിച്ചേരുമ്പോള്꠱ ശോഭ നിയന്ത്രിക്കുന്നു, ("ഒഴിഞ്ഞ ഇടങ്ങള്꠱ കാണിയ്ക്കുക" പ്രവര്꠱ത്തമരഹിതമാക്കിയാല് പശ്ചാത്തപിക്കുക ഒഴിഞ്ഞ ഇടങ്ങളുടെ വ്യ അല്ലാഹുക്കള്꠱ ഒഴിവാക്കും.), മാതാപിതാക്കൾ തുറക്കുന്നതും അടയ്ക്കുന്നതും ലയിപ്പിക്കുന്നതും ലയിപ്പിക്കുക.]</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<hr>
</section>
</section>
<section id="now-lets-translate-with-our-trained-models" class="level2">
<h2 class="anchored" data-anchor-id="now-lets-translate-with-our-trained-models">Now let’s translate with our trained models</h2>
<section id="blurr-top-3-translation-predictions" class="level3">
<h3 class="anchored" data-anchor-id="blurr-top-3-translation-predictions">blurr top 3 translation predictions</h3>
<div class="cell" data-outputid="b8da2fae-a739-4fb1-8033-9e8c37030991" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">test_text <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"How are you doing"</span></span>
<span id="cb28-2"></span>
<span id="cb28-3"></span>
<span id="cb28-4">outputs <span class="op" style="color: #5E5E5E;">=</span> learn.blurr_generate(</span>
<span id="cb28-5">    test_text, key<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"translation_texts"</span>, num_return_sequences<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb28-6">)</span>
<span id="cb28-7">outputs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>[{'translation_texts': ['എന്തൊക്കെയുണ്ട്?',
   'എങ്ങനെയുണ്ട്?',
   'എന്തൊക്കെയുണ്ട്.']}]</code></pre>
</div>
</div>
</section>
<section id="saving-trained-ml-model" class="level3">
<h3 class="anchored" data-anchor-id="saving-trained-ml-model">Saving trained ML model</h3>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">export_fname <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"saved_model"</span></span>
<span id="cb30-2"></span>
<span id="cb30-3"></span>
<span id="cb30-4">learn.metrics <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb30-5">learn.export(fname<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>export_fname<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.pkl"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> push_to_hub_fastai</span>
<span id="cb31-2"></span>
<span id="cb31-3">push_to_hub_fastai(</span>
<span id="cb31-4">    learn,</span>
<span id="cb31-5">    <span class="st" style="color: #20794D;">"kurianbenoy/kde_en_ml_translation_model"</span>,</span>
<span id="cb31-6">    commit_message<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"New version with 15 epoch of training"</span>,</span>
<span id="cb31-7">)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/kde_en_ml_translation_model is already a clone of https://huggingface.co/kurianbenoy/kde_en_ml_translation_model. Make sure you pull the latest changes with `repo.git_pull()`.
W0511 16:57:02.992604 140162781013824 repository.py:685] /home/kurianbenoy/kde_en_ml_translation_model is already a clone of https://huggingface.co/kurianbenoy/kde_en_ml_translation_model. Make sure you pull the latest changes with `repo.git_pull()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"01955814005849b0b5318dc34ee191d3","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>remote: Enforcing permissions...        
remote: Allowed refs: all        
To https://huggingface.co/kurianbenoy/kde_en_ml_translation_model
   62f36f9..766c8a0  main -&gt; main

W0511 16:58:04.917035 140162781013824 repository.py:1144] remote: Enforcing permissions...        
remote: Allowed refs: all        
To https://huggingface.co/kurianbenoy/kde_en_ml_translation_model
   62f36f9..766c8a0  main -&gt; main
</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>'https://huggingface.co/kurianbenoy/kde_en_ml_translation_model/commit/766c8a06c07bb6352d0537ac1972d3c70360fd53'</code></pre>
</div>
</div>
</section>
<section id="prediction-with-our-trained-model" class="level3">
<h3 class="anchored" data-anchor-id="prediction-with-our-trained-model">Prediction with our trained model</h3>
<section id="correct-prediction" class="level4">
<h4 class="anchored" data-anchor-id="correct-prediction">Correct Prediction</h4>
<div class="cell" data-outputid="2c91e3f8-2099-4b06-ab38-19ba1744eb6d" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">test_text <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"How are you doing"</span></span>
<span id="cb35-2"></span>
<span id="cb35-3">inf_learn <span class="op" style="color: #5E5E5E;">=</span> load_learner(fname<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>export_fname<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.pkl"</span>)</span>
<span id="cb35-4">inf_learn.blurr_translate(test_text)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>[{'translation_texts': 'എന്തൊക്കെയുണ്ട്?'}]</code></pre>
</div>
</div>
<div class="cell" data-outputid="f26663cb-38fc-4fa7-8742-63f7f675a2e2" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">test_text1 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Add All Found Feeds to Akregator."</span></span>
<span id="cb37-2"></span>
<span id="cb37-3">inf_learn <span class="op" style="color: #5E5E5E;">=</span> load_learner(fname<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>export_fname<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.pkl"</span>)</span>
<span id="cb37-4">inf_learn.blurr_translate(test_text1)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>[{'translation_texts': 'എല്ലാ ഫീഡുകളും അക്രിഗേറ്ററില്꠱ കൂട്ടിച്ചേര് പശ്ചാത്തപിക്കുകക്കുക.'}]</code></pre>
</div>
</div>
</section>
<section id="wrong-prediction" class="level4">
<h4 class="anchored" data-anchor-id="wrong-prediction">Wrong Prediction</h4>
<div class="cell" data-outputid="af05d344-d92e-482f-fac7-53f1de3e3e9a" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">test_text2 <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Subscribe to site updates (using news feed)."</span></span>
<span id="cb39-2"></span>
<span id="cb39-3">inf_learn <span class="op" style="color: #5E5E5E;">=</span> load_learner(fname<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>export_fname<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.pkl"</span>)</span>
<span id="cb39-4">inf_learn.blurr_translate(test_text2)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>[{'translation_texts': 'സൈറ്റുകളിലെ പുതുമകളറിയാന്꠱ വരിക്കാരനാകുക (വാര്꠱ത്താ ഫീഡുകള്♬ ഉപയോഗിച്ചു്).'}]</code></pre>
</div>
</div>
<p>Expected: ’സൈറ്റുകളിലെ പുതുമകളറിയാന്00d വരിക്കാരനാകുക (വാര്00dത്താ ഫീഡുകള്00d ഉപയോഗിച്ചു്</p>
</section>
</section>
</section>
<section id="thanks-to" class="level2">
<h2 class="anchored" data-anchor-id="thanks-to">Thanks to</h2>
<ul>
<li>Wayde Gilliam - for creating blurr, and helping with doubts in translation bits</li>
<li>Kevin Bird - for helping in editing the article.</li>
<li>Ashwin Jayaprakash - for trying out notebook and reporting issues which was later fixed by Wayde in blurr.</li>
</ul>
<p>fin.</p>


</section>
</section>

 ]]></description>
  <category>fastai</category>
  <category>huggingface</category>
  <category>translation</category>
  <category>fine tuning</category>
  <category>malayalam</category>
  <guid>https://kurianbenoy.com/posts/2022-03-13-hfenml-translate.html</guid>
  <pubDate>Sun, 13 Mar 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/translate.png" medium="image" type="image/png" height="83" width="144"/>
</item>
</channel>
</rss>
