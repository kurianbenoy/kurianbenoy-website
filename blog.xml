<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kurian Benoy</title>
<link>https://kurianbenoy.com/blog.html</link>
<atom:link href="https://kurianbenoy.com/blog.xml" rel="self" type="application/rss+xml"/>
<description>Recent posts on kurianbenoy.com</description>
<generator>quarto-1.3.361</generator>
<lastBuildDate>Sun, 04 Jun 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Learning how to install malayalam fonts</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/malayalam_fonts/index.html</link>
  <description><![CDATA[ 




<p>I was working on Malayalam Speech to text models and the malayalam letters where not getting rendered properly. I was a bit irritated by it and I asked my friend <a href="https://thottingal.in/">Santhosh Thottingal</a> why <code>?</code> comes this way.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/malayalam_fonts/malayalam_font2.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Malayalam rendered in Nirmala font.</figcaption>
</figure>
</div>
<p>Santhosh told me basically malayalam letters take 3 bytes compared to 1 byte for latin and if the text is broken in the middle of those 3 byte clusters, you will get invalid character and will be displayed as <code>?</code>.</p>
<p>Then he told me I was using one of the worst Malayalam fonts ie Nirmala by Microsoft which is the reason why I am seeing lot of rendering mistakes.</p>
<p>So I stopped working on Mayalam ASR models and thought of studying how to install Malayalam fonts.</p>
<p>I found personally two ways to install fonts and I want to share that here. There maybe another thousand different ways to install fonts which won’t be covered in this blogpost.</p>
<ol type="1">
<li>Installing with Malayalam Fonts - firefox plugins</li>
</ol>
<ul>
<li>Install the <a href="https://addons.mozilla.org/en-US/firefox/addon/malayalam-fonts/">plugin</a></li>
<li>Choose the fonts you want to use by selecting it firefox.</li>
</ul>
<p><img src="https://kurianbenoy.com/posts/2023/malayalam_fonts/firefox_plugin.png" class="img-fluid"></p>
<ol start="2" type="1">
<li>Installing on Microsoft Windows</li>
</ol>
<p>I just asked ChatGPT and it gave me the following steps to install fonts by SMC in Windows.</p>
<pre><code>To download SMC (Swathanthra Malayalam Computing) fonts for your Windows operating system, follow these steps:

1. Visit the SMC website: Go to the SMC website at https://smc.org.in/fonts/
using your web browser.

2. Choose the font: Browse through the available fonts and select the one you
want to download. SMC offers a variety of fonts for different purposes.

3. Download the font: Click on the download link or button associated with the
selected font. The font file will be downloaded to your computer as a
compressed (ZIP) file.

4. Extract the font: Locate the downloaded ZIP file and extract its contents.
Right-click on the file and select "Extract All" or use a third-party compression
tool like WinRAR or 7-Zip to extract the font files.

5. Install the font: After extracting the font files, double-click on the font file
with the extension ".ttf" or ".otf." A preview of the font will appear, and a dialog
box will open. Click on the "Install" button to install the font on your Windows system.

6. Font installation completion: Once the font is installed, you can start using it
in various applications such as word processors, graphic design software, or
web browsers. The font will be available for selection in the font menu
of compatible applications.

By following these steps, you should be able to download and install SMC fonts on your Windows
operating system. Remember to respect font licensing terms and only use the fonts
for their intended purposes.</code></pre>
<p><img src="https://kurianbenoy.com/posts/2023/malayalam_fonts/malayalam_font3.jpg" class="img-fluid" alt="Malayalam rendered in Manjari font."> <img src="https://kurianbenoy.com/posts/2023/malayalam_fonts/malayalam_font1.jpg" class="img-fluid" alt="Malayalam rendered in Manjari font."></p>
<p>After all this I asked Santhosh whether I have installed Manjari font correctly and he said it’s correct. It’s not every day you get to ask the person who built that font whether I have installed the font correctly or not.</p>
<blockquote class="blockquote">
<p>Note: For linux, all these fonts are preinstalled by default as it’s packaged as part of linux distros.</p>
</blockquote>
<p>I am glad to have friends like <a href="https://thottingal.in/">Santhosh Thottingal</a> to ask questions like this. Santhosh has written lot of popular fonts in Malayalam like <a href="https://smc.org.in/fonts/manjari">Manjari</a>, <a href="https://smc.org.in/fonts/gayathri">Gayathri</a> and with his latest font <a href="https://smc.org.in/fonts/nupuram">Nupuram</a> he has created almost 100+ fonts.</p>
<p>In my opinion SMC creates the best fonts in Malayalam and check their website section on <a href="https://smc.org.in/fonts">fonts to learn more</a>. If you are interested to learn more about Malayalam Computing I had previously written a <a href="../../../posts/2019/2019-07-30-Malayalam_computing.html">blogpost</a> which is just a highlight of talk given by Santhosh on this topic.</p>



 ]]></description>
  <category>Malayalam</category>
  <category>myself</category>
  <category>SMC</category>
  <category>TIL</category>
  <guid>https://kurianbenoy.com/posts/2023/malayalam_fonts/index.html</guid>
  <pubDate>Sun, 04 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Malayalam Projects I am working at the moment!</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/delft-fastai-talk/index.html</link>
  <description><![CDATA[ 




<section id="links-to-talk" class="level2">
<h2 class="anchored" data-anchor-id="links-to-talk">Links to talk</h2>
<ul>
<li><p><a href="../../../talks/delft-fastai/index.html">Slides</a></p></li>
<li><p>Scheduled Time: Sunday, May 28, 2023, 3:30 PM IST</p></li>
<li><p><a href="https://youtu.be/c69VyJ16Mx4">Youtube Link</a></p></li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/c69VyJ16Mx4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><a href="https://forums.fast.ai/t/delft-study-group-talks-mojo-and-malayalam-benchmarking-low-resource-language/106126?u=kurianbenoy">fastai forums post</a></li>
</ul>
</section>
<section id="talk-in-30-seconds" class="level2">
<h2 class="anchored" data-anchor-id="talk-in-30-seconds">Talk in 30 seconds</h2>
<p>I talked about Malayalam language and what makes it hard to work compared to other high resource languages like English. Then I highlighted some of the Malayalam models build during Whisper event and why I went ahead to benchmark these models. These models where benchmarked on two datasets mainly Common Voice and Malayalam Speech Corpus. I also shared more about the <a href="https://huggingface.co/models?other=vegam">Vegam Whisper model family</a> for making whisper models faster. Also I shared about Malayalam speech to text demo <a href="https://huggingface.co/spaces/kurianbenoy/Pallakku">Pallakku</a> which I am developing now with Vegam whisper weights.</p>


</section>

 ]]></description>
  <category>Malayalam</category>
  <category>SMC</category>
  <guid>https://kurianbenoy.com/posts/2023/delft-fastai-talk/index.html</guid>
  <pubDate>Sun, 28 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://i3.ytimg.com/vi/c69VyJ16Mx4/maxresdefault.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Visiting main campus of Indian Institute of Information Technology, Kottayam</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/iiit_visit/index.html</link>
  <description><![CDATA[ 




<p>I have been staying in Indian Institute of Information Technology (IIIT), Kottayam for the past three days in order to partake in my 4th semester M.Tech exams. I absolutely loved my stay in campus.</p>
<p>During my stay I had some interesting conversations with faculties, students who are doing PHD, UG and my fellow professional classmates who are pursuing MTech program. Some of these conversations were around latest advances of AI, AI hype etc.</p>
<p>The campus boasts excellent amenities. I am thankful to all the warm smiles and kindness received from everyone in campus specifically the ex-jawans who are working there.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/iiit_visit/morning.jpeg" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">Early morning selfie with mist in background</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/iiit_visit/campus.jpeg" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">Full campus view. <a href="https://www.iiitkottayam.ac.in/#!/home">credits</a></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/iiit_visit/campus1.jpeg" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Campus buildings being constructed</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/iiit_visit/classmates.jpeg" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Class-mates attending tea party hosted by our class-rep</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/iiit_visit/tea.jpeg" class="img-fluid figure-img" width="500"></p>
</figure>
</div>



 ]]></description>
  <category>myself</category>
  <category>academic</category>
  <guid>https://kurianbenoy.com/posts/2023/iiit_visit/index.html</guid>
  <pubDate>Mon, 08 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/2023/iiit_visit/campus.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>OpenAI Whisper and it’s amazing power to do finetuning</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/fossasia2023talk/index.html</link>
  <description><![CDATA[ 




<section id="links-to-talk" class="level2">
<h2 class="anchored" data-anchor-id="links-to-talk">Links to talk</h2>
<ul>
<li><p><a href="../../../talks/fossasia2023.html">Slides</a></p></li>
<li><p>Scheduled Time: Saturday, April 15, 2023, 9:30 AM SGT</p></li>
<li><p><a href="https://www.youtube.com/live/sGWiXzsLGtI">Youtube live video stream</a></p></li>
</ul>
<blockquote class="blockquote">
<p>Please note mine was the first session of the day. I noticed there was a audio issue at the start of talk, so you can <a href="https://www.youtube.com/live/sGWiXzsLGtI?feature=share&amp;t=149">start listening from 2:30 minutes</a>.</p>
</blockquote>
<ul>
<li>Talk Page: <a href="https://eventyay.com/e/7cfe0771/session/8074">Session Details</a></li>
<li><a href="https://github.com/kurianbenoy/malayalam_asr_benchmarking">Malayalam ASR Benchmarking project</a></li>
</ul>
</section>
<section id="pictures-from-session" class="level2">
<h2 class="anchored" data-anchor-id="pictures-from-session">Pictures from Session</h2>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/fossasia2023talk/IMG_20230415_094452682_HDR.jpg" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">During the talk</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/fossasia2023talk/IMG_20230415_090740256_HDR.jpg" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">Last minute preparation before talk</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/fossasia2023talk/IMG_20230415_092949649.jpg" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">Volunteers helping me with the talk</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/fossasia2023talk/youtube_livestream.png" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">A snap from live stream session of my talk</figcaption>
</figure>
</div>
</section>
<section id="talk-in-30-seconds" class="level2">
<h2 class="anchored" data-anchor-id="talk-in-30-seconds">Talk in 30 seconds</h2>
<p>I talked about what is OpenAI whisper and some of it’s amazing feature. I highlighted the importance of fine-tuning Whisper in low-resource language like Malayalam which is able to get almost 90% accuracy compared to -10% accuracy of OpenAI whisper model weights. The results where calculated with a new github project called <a href="https://github.com/kurianbenoy/malayalam_asr_benchmarking">malayalam_asr_benchmarking created by me</a>.</p>
</section>
<section id="thanks-to" class="level2">
<h2 class="anchored" data-anchor-id="thanks-to">Thanks to</h2>
<p>In my talk I mentioned <a href="https://kurianbenoy.com/talks/fossasia2023.html#/thanks-to">the following people and organizations</a>. Beyond that first of all, I would like to thank FOSSASIA team for giving me this opportunity to talk in FOSSASIA Summit 2023. I would like to thank <a href="https://abhijithpa.me/">Abhijit PA</a> for taking pictures of my talk and Thorsen for moderating my session. <a href="https://www.linkedin.com/in/karunakar-vanama-182702145/">Karuankar Vanama</a> pointed out a typo in a slide which was corrected. I got a lot of support after this talk when I posted in <a href="https://www.linkedin.com/posts/kurianbenoy_fossasia-activity-7052803823953739776-KmkL?utm_source=share&amp;utm_medium=member_desktop">LinkedIn</a> and <a href="https://twitter.com/kurianbenoy2/status/1647246814410682368">Twitter</a> and few folks reached out to me after this talk. I am really thankful to all of you.</p>
</section>
<section id="questions-received" class="level2">
<h2 class="anchored" data-anchor-id="questions-received">Questions received</h2>
<ol type="1">
<li>Someone was curious to know the relationship between Malayalam language and the Sanskrit language?</li>
</ol>


</section>

 ]]></description>
  <category>conference</category>
  <category>fossasia</category>
  <category>Audio</category>
  <category>Deep learning</category>
  <category>SMC</category>
  <guid>https://kurianbenoy.com/posts/2023/fossasia2023talk/index.html</guid>
  <pubDate>Sat, 15 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/2023/fossasia2023talk/IMG_20230415_094452682_HDR.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Four super powers of Jeremy Howard</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/jeremy_habits/index.html</link>
  <description><![CDATA[ 




<section id="about-podcast-interview" class="level2">
<h2 class="anchored" data-anchor-id="about-podcast-interview">About Podcast interview</h2>
<p>I recently stumbled upon a podcast interview with Jeremy Howard hosted by one of my fast.ai friends Alex Strick van Linschoten, around 4 years back. I am a big fan of watching interview featuring Jeremy and some unique question were asked by the interviewer which I haven’t seen anyone asking.</p>
<p>I would defenitely recommend everyone to <a href="https://www.sourcesandmethods.com/podcast/2019/6/28/sources-and-methods-44-deep-learning-with-fastais-jeremy-howard">give a watch to the podcast interview</a>. In this interview, Jeremy shared four super powers which he learned over the years. I am going to briefly summarize them.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/jeremy_habits/https:/images.squarespace-cdn.com/content/v1/53e7b388e4b0b09d128a62b1/1561718846748-5KLJ2OZF4ZFVQOG9UNU3/jh-head.jpg?format=500w" class="img-fluid figure-img" alt="Jeremy Howard"></p>
<figcaption class="figure-caption">Jeremy Howard</figcaption>
</figure>
</div>
</section>
<section id="four-super-powers" class="level2">
<h2 class="anchored" data-anchor-id="four-super-powers">Four super powers</h2>
<ol type="1">
<li>Spaced Repetition and learning how to learn</li>
</ol>
<p>Alex was very curious about how Jeremy learned chinese and his approach to learning. Jeremy answered as following:</p>
<p>I started learning Chinese not because I had any interest in Chinese, but because I was such a bad language learner in highschool. I did six months of French, I got 28% and I quit. When I wanted to dig into machine learning, I thought one of the things that might be better to understand was human learning, so I used myself as a subject. A hopeless subject. If I can come up with a way that even I can learn a language, that would be great. And to make sure that was challenging enough, I tried to pick the hardest language I could. So according to according to CIA guidelines, Arabic and Chinese are the hardest languages for people to pick up. Then I spent three months studying learning theory, and language learning theory, and then software to help me with that process.</p>
<p>It turns out that even I can learn Chinese. After a year of this - by no means a full time thing, an hour or two a day - I went to China to a top language learning program and based on the results of my exam got placed with all these language PhDs, and I thought wow. Studying smart is important. It’s all about how you do it.</p>
<p>Spaced repetition is such an easy thing that anyone can do, for free, you can start using it.<a href="https://www.youtube.com/watch?v=HwH7bJibmdM">Jeremy’s amazing Anki talk</a></p>
<p>If you’re not using Anki, you’re many orders of magnitude less likely to remember a piece of vocab. So you come away like I did, thinking you can’t learn a language. But once you learn vocab, the rest is really not that hard. Don’t try to learn grammar, just spend all your time reading.</p>
<blockquote class="blockquote">
<p>Recently, Rachel Thomas wrote a blog post about <a href="https://rachel.fast.ai/posts/2023-02-21-anki/">How to remember anything</a>.</p>
</blockquote>
<ol start="2" type="1">
<li>Doing Regular exercises</li>
</ol>
<p>Ten years back Jeremy suffered a injury because of which he lost almost 6 months. After that he is doing regular yoga and exercises.</p>
<ol start="3" type="1">
<li>Note taking</li>
</ol>
<p>Lot of times Jeremy have seen whenever someone is discussing about a particular topic, or issue. Those who take the notes on the topic immediately are the one to follow up even later and perform much better. Exceptional people take a lot of notes. Less exceptional people assume they’re going to remember.</p>
<p>Taking notes in class is kind of a waste of time. I don’t really see the point of going to class most of the time honestly, it’s probably being videotaped</p>
<ol start="4" type="1">
<li>Tenacity</li>
</ol>
<p>People who are successful practitioners in deep learning are the ones who have highest level of tenacity. He has found lot of people stopping midway and people who are world-class practitioners are always tenatious.</p>
</section>
<section id="two-critical-skills-in-ai-era" class="level2">
<h2 class="anchored" data-anchor-id="two-critical-skills-in-ai-era">Two critical skills in AI era</h2>
<p>The two critical skills going forward is:</p>
<ul>
<li>One is knowing how to use machine learning.</li>
<li>And the other is knowing how to interact with it and care for human beings.</li>
</ul>
<p>Because the latter one can’t be replaced by AI. The former one will gradually replace everything. Back in the early days of the commercial internet, being an internet expert was extremely useful and you could have a job as an internet expert and be in a company of internet experts, and sell yourself as an internet expert company. Today, very few people do that, because on the whole the internet is what it is, and there’s a relatively few number of people who need such a level of expertise that they can go in and change the way your router operates and such. I think we’re going to see the same thing with AI.</p>
<blockquote class="blockquote">
<p>Thanks to <a href="https://forums.fast.ai/u/strickvl/">Alex Strick van Linschoten</a> who posted it in fast.ai forums and for writing <a href="https://www.sourcesandmethods.com/podcast/2019/6/28/sources-and-methods-44-deep-learning-with-fastais-jeremy-howard">wonderful show notes</a>, some of which I have used in this post.</p>
</blockquote>


</section>

 ]]></description>
  <category>fastai</category>
  <category>Life</category>
  <category>myself</category>
  <guid>https://kurianbenoy.com/posts/2023/jeremy_habits/index.html</guid>
  <pubDate>Tue, 04 Apr 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>🐦Learning more about birds and bird calls with Merlin app</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/BirdCLEF2023/index.html</link>
  <description><![CDATA[ 




<p>I recently went for a bird watching adventure in <a href="https://en.wikipedia.org/wiki/Salim_Ali_Bird_Sanctuary">Salim Ali Bird Sanctuary</a>, Thattekad Kerala, India. During that time, my guide was very proficient in identifying birds by just hearing sounds. In Salim Ali bird sanctuary itself there are almost 300 species of land birds and another 100+ species of water birds.</p>
<p>I was genuinely curious, how they learned about all these birds and memorized all these. This is when my guide talked about the Merlin app, which can help in learning more about various species of bird.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xmSUOLxyatY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Video Explaining functionality of Merlin</p>
<p>You can download it from <a href="https://apps.apple.com/us/app/merlin-bird-id-by-cornell-lab/id773457673">Apple App store</a> or <a href="https://play.google.com/store/apps/details?id=com.labs.merlinbirdid.app&amp;hl=en&amp;gl=US">Google Playstore</a> for your android phones. Learn more about Merlin app in this <a href="https://merlin.allaboutbirds.org/.">link</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/BirdCLEF2023/https:/www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1310697%2Fc0fa9ac858406ddcc9f644fc53054642%2FWhatsApp%20Image%202023-03-20%20at%209.25.36%20AM.jpeg?generation=1679301145365560&amp;alt=media" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">A photo during my bird walking trek</figcaption>
</figure>
</div>
<p><a href="https://en.wikipedia.org/wiki/Sri_Lanka_frogmouth">The below image is Ceylon Frogmouth which is a rare bird in my region</a></p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/BirdCLEF2023/https:/www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1310697%2F2e84ee1ef3b246d9bcee2cd5757f4a05%2FWhatsApp%20Image%202023-03-20%20at%209.25.45%20AM.jpeg?generation=1679301247043893&amp;alt=media" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">Ceylon Frogmouth</figcaption>
</figure>
</div>
<p>Note: This article was originally published in <a href="https://www.kaggle.com/competitions/birdclef-2023/discussion/396029#2188836">Kaggle discussion here</a></p>



 ]]></description>
  <category>kaggle</category>
  <category>experience</category>
  <category>Travel</category>
  <guid>https://kurianbenoy.com/posts/2023/BirdCLEF2023/index.html</guid>
  <pubDate>Mon, 20 Mar 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Everything is about to be changed and launch of GPT-4</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/gpt4/index.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Update: April 20, 2023</p>
</blockquote>
<blockquote class="blockquote">
<p>I found this <a href="https://world.hey.com/dhh/how-to-continue-making-kerosene-lamps-on-the-eve-of-electricity-5a8b8e1a">brillant article</a> on not to be too afraid of latest AI advances by David Heinemeir Hanson who is the creator of Ruby on Rails and co-owner of Basecamp. I think it’s a must read for anyone who is a bit worried about latest changes as well as for anyone who is excited about the changes.</p>
</blockquote>
<section id="buzz-about-chatgpt" class="level2">
<h2 class="anchored" data-anchor-id="buzz-about-chatgpt">Buzz about ChatGPT</h2>
<p>There has been a lot of buzz about GPT and ChatGPT in specific. Tom Scott, a youtuber recently published a video on how he used ChatGPT to fix a problem in his email backup program. He said it’s beginning of something new like how internet had literally changed everything 20-30 years back.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/jPhJbKBuNnA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<blockquote class="blockquote">
<p>AI is the new electricity - Andrew NG</p>
</blockquote>
<p>When I was writing this article, I forget the syntax of how to embed youtube videos in quarto markdown. I solved this issue by asking this <a href="https://quarto-bot.onrender.com/">question to Quarto Help Bot</a> which was made by <a href="https://hamel.dev/">Hamel Husain</a>.</p>
<p>I have seen chatbots, yet the way ChatGPT interacts and communicates is insane to be honest. You can ask it literally anything and these Large Language models are becoming incredibly useful. Hamel had used <a href="https://github.com/hwchase17/langchain/">LangChain</a> which is like a framework for building applications with LLMs specifically for quarto.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/gpt4/https:/www.gsb.stanford.edu/sites/default/files/styles/1630x_variable_tinypng/public/resources/ng-ai-1630_1.jpg.webp?itok=9_DYUOPs" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">An Image from gsb.stanford.edu article on Andrew NG remark</figcaption>
</figure>
</div>
</section>
<section id="how-has-the-ai-landscape-been-going-in-the-past-one-year" class="level2">
<h2 class="anchored" data-anchor-id="how-has-the-ai-landscape-been-going-in-the-past-one-year">How has the AI landscape been going in the past one year?</h2>
<p>Personally I have been following ML/AI for the past five years atleast. Last year really was hyped up. Initially there was this releases in DALL-E and it’s open source alternative Craiyon(then named DALLE mini) being viral. During this time so many trending things like Stable Diffusion, Whisper etc came.</p>
<p>One month back, I started seeing my cousins, parents etc. discussing about ChatGPT and how awesome it is. Some of the application apps like <a href="https://www.roamaround.io">Roamaround.ai</a> build on top of ChatGPT was being used. The final nail was last Sunday, when my grandfather called me to read about ChatGPT article in news.</p>
<p>I have seen people get hyped up about advances in ML. Yet I have never heard about the new technology being discussed by any of my family member like this. Hamel Hussein put this really well in his tweet about what is different in this wave of ML advances.</p>
<p></p><div id="tweet-83446"></div><script>tweet={"url":"https:\/\/twitter.com\/HamelHusain\/status\/1636513242041442305","author_name":"Hamel Husain","author_url":"https:\/\/twitter.com\/HamelHusain","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EThis wave of ML advances feels different than all others before it.  Usually, lots of people sleep on it or just pay lip service to ML.  \u003Cbr\u003E\u003Cbr\u003EThis time, people are rushing to ship ML products, and successfully doing so at breakneck speed.\u003C\/p\u003E&mdash; Hamel Husain (@HamelHusain) \u003Ca href=\"https:\/\/twitter.com\/HamelHusain\/status\/1636513242041442305?ref_src=twsrc%5Etfw\"\u003EMarch 16, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-83446").innerHTML = tweet["html"];</script><p></p>
</section>
<section id="release-of-gpt-4" class="level2">
<h2 class="anchored" data-anchor-id="release-of-gpt-4">Release of GPT-4</h2>
<p>The GPT-4 model was released by OpenAI today IST. It’s been a hectic week already TBH, with so many releases already.</p>
<p></p><div id="tweet-43181"></div><script>tweet={"url":"https:\/\/twitter.com\/iScienceLuvr\/status\/1635747429839671300","author_name":"Tanishq Mathew Abraham","author_url":"https:\/\/twitter.com\/iScienceLuvr","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"ro\" dir=\"ltr\"\u003EGPT-4 release\u003Cbr\u003EMed-PaLM2 announcement\u003Cbr\u003EPaLM API release\u003Cbr\u003EClaude API release \u003Ca href=\"https:\/\/t.co\/Oef6qw6uhf\"\u003Epic.twitter.com\/Oef6qw6uhf\u003C\/a\u003E\u003C\/p\u003E&mdash; Tanishq Mathew Abraham (@iScienceLuvr) \u003Ca href=\"https:\/\/twitter.com\/iScienceLuvr\/status\/1635747429839671300?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-43181").innerHTML = tweet["html"];</script><p></p>
<p>The initial reaction to this model has been awesome, and lot of people have been reacting about this.</p>
<p></p><div id="tweet-29166"></div><script>tweet={"url":"https:\/\/twitter.com\/Suhail\/status\/1635704809725767680","author_name":"Suhail","author_url":"https:\/\/twitter.com\/Suhail","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EWe tried GPT-4 internally over the past few months and it is *a lot* better than meets the eye. I encourage folks to try it. World changing technology.\u003C\/p\u003E&mdash; Suhail (@Suhail) \u003Ca href=\"https:\/\/twitter.com\/Suhail\/status\/1635704809725767680?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-29166").innerHTML = tweet["html"];</script><p></p>
<p>You can read more about this release in below resources:</p>
<p><a href="https://openai.com/research/gpt-4">Research document</a></p>
<p><a href="https://openai.com/product/gpt-4">Product details</a></p>
<p>Check out the summary of what was highlights of GPT-4 and it’s developer livestream in this tweet thread by FSDL.</p>
<p></p><div id="tweet-74581"></div><script>tweet={"url":"https:\/\/twitter.com\/full_stack_dl\/status\/1635734384463745024","author_name":"The Full Stack","author_url":"https:\/\/twitter.com\/full_stack_dl","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003ELive-tweeting the GPT-4 livestream from OpenAI ⤵️\u003C\/p\u003E&mdash; The Full Stack (@full_stack_dl) \u003Ca href=\"https:\/\/twitter.com\/full_stack_dl\/status\/1635734384463745024?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-74581").innerHTML = tweet["html"];</script><p></p>
</section>
<section id="how-can-we-try-gpt-4-now" class="level2">
<h2 class="anchored" data-anchor-id="how-can-we-try-gpt-4-now">How can we try GPT-4 now?</h2>
<p>According to OpenAI, you can try the latest GPT-4 via Chat GPT Plus Membership.</p>
<p>Two more options seems to be available for normal users without mulimodal search:</p>
<ol type="1">
<li>BingGPT</li>
<li>Poe App from Quora</li>
</ol>
</section>
<section id="is-binggpt-really-using-gpt-4" class="level2">
<h2 class="anchored" data-anchor-id="is-binggpt-really-using-gpt-4">Is BingGPT really using GPT-4?</h2>
<p>To be honest, at the moment we can’t be really sure about that. Even though as Microsoft <a href="https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4">Bing team confirmed today that they are using GPT-4</a>.</p>
<p>In lot of user tests, it doesn’t really seem to be the same. I tested a trick question:</p>
<blockquote class="blockquote">
<p>Which is heavier, two pounds of brick or one pound of feathers?</p>
</blockquote>
<p>GPT-4 seems to give the correct answer at time of writing.</p>
<p></p><div id="tweet-41248"></div><script>tweet={"url":"https:\/\/twitter.com\/charles_irl\/status\/1635699547023482880","author_name":"Charles \uD83C\uDF89 Frye","author_url":"https:\/\/twitter.com\/charles_irl","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003Egpt-4 passes the &quot;two pounds of bricks&quot; adversarial question without prompt fiddling \u003Ca href=\"https:\/\/t.co\/jRcYzxSr38\"\u003Epic.twitter.com\/jRcYzxSr38\u003C\/a\u003E\u003C\/p\u003E&mdash; Charles \uD83C\uDF89 Frye (@charles_irl) \u003Ca href=\"https:\/\/twitter.com\/charles_irl\/status\/1635699547023482880?ref_src=twsrc%5Etfw\"\u003EMarch 14, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-41248").innerHTML = tweet["html"];</script><p></p>
<p>Bing-GPT seems to give wrong answer.</p>
<p></p><div id="tweet-12991"></div><script>tweet={"url":"https:\/\/twitter.com\/kurianbenoy2\/status\/1636066002843627523","author_name":"Kurian Benoy \uD83D\uDC4D","author_url":"https:\/\/twitter.com\/kurianbenoy2","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EIs it really GPT-4 though? \u003Ca href=\"https:\/\/t.co\/UZXvapfM6k\"\u003Epic.twitter.com\/UZXvapfM6k\u003C\/a\u003E\u003C\/p\u003E&mdash; Kurian Benoy \uD83D\uDC4D (@kurianbenoy2) \u003Ca href=\"https:\/\/twitter.com\/kurianbenoy2\/status\/1636066002843627523?ref_src=twsrc%5Etfw\"\u003EMarch 15, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-12991").innerHTML = tweet["html"];</script><p></p>
<p>Chat-GPT seems to now give correct answer, it was previously giving wrong answer.</p>
<p></p><div id="tweet-78020"></div><script>tweet={"url":"https:\/\/twitter.com\/1littlecoder\/status\/1636069386699022336","author_name":"1LittleCoder\uD83D\uDCBB","author_url":"https:\/\/twitter.com\/1littlecoder","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EOlder ChatGPt corrected \u003Ca href=\"https:\/\/t.co\/RNXgq5bL8K\"\u003Epic.twitter.com\/RNXgq5bL8K\u003C\/a\u003E\u003C\/p\u003E&mdash; 1LittleCoder\uD83D\uDCBB (@1littlecoder) \u003Ca href=\"https:\/\/twitter.com\/1littlecoder\/status\/1636069386699022336?ref_src=twsrc%5Etfw\"\u003EMarch 15, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-78020").innerHTML = tweet["html"];</script><p></p>
<p>Charles seems to have come with an explaination to this problem, at the time I was writing this article.</p>
<p><em>“GPT-4” is really a series of models, and the one live in chat now is likely the 0314 checkpoint available via the API. BingChat can’t’ve launched with that checkpoint and likely has branched off in the intervening weeks.”</em></p>
<p></p><div id="tweet-97248"></div><script>tweet={"url":"https:\/\/twitter.com\/charles_irl\/status\/1636071852593549312","author_name":"Charles \uD83C\uDF89 Frye","author_url":"https:\/\/twitter.com\/charles_irl","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003ENice find! &quot;GPT-4&quot; is really a series of models, and the one live in chat now is likely the 0314 checkpoint available via the API. BingChat can&#39;t&#39;ve launched with that checkpoint and likely has branched off in the intervening weeks.\u003C\/p\u003E&mdash; Charles \uD83C\uDF89 Frye (@charles_irl) \u003Ca href=\"https:\/\/twitter.com\/charles_irl\/status\/1636071852593549312?ref_src=twsrc%5Etfw\"\u003EMarch 15, 2023\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-97248").innerHTML = tweet["html"];</script><p></p>


</section>

 ]]></description>
  <category>Deep learning</category>
  <category>NLP</category>
  <category>coding</category>
  <guid>https://kurianbenoy.com/posts/2023/gpt4/index.html</guid>
  <pubDate>Wed, 15 Mar 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>My daily fitness routine</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/fitness_journey/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/fitness_journey/https:/user-images.githubusercontent.com/24592806/223161083-1a5cfc9b-03f0-4425-a1d6-ebc398542727.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Stable diffusion image generated with prompt Very muscular man, photograph quality, ultra detailed</figcaption>
</figure>
</div>
<p>Hello everyone, I just thought of sharing my daily fitness routine which I have been following for the past 1 month. Previously I had written about <a href="https://kurianbenoy.com/posts/2020/2020-11-22-weightloss.html">How I lost almost 4Kgs in 3 weeks - my wegiht loss Journey</a>. I want to continue this journey, even though just after writing that post I gained a lot of kilos and I couldn’t follow everything I mentioned in that article.</p>
<p>So this time, I am with a new routine:</p>
<p>During morning I go to gym and do High Intensity Interval Training (HIIT) for 30-45 minutes. In the gym I go, this usually consists of 8 stations of 3 minutes exercises followed by 30 seconds rest. The first four stations are vary day after day, followed by a challenge which changes every week. After this I do boxing, followed by two more stations of 3 minutes exercises which usually are floor exercises.</p>
<p>In evening I go for a walk for 45-60 minutes after my work. I usually try to walk almost 4 kilometers and monitor my progress in Strava app. I usually walk in the roads near my home till a paddy field and then return back. My usual pace is 4.5-6 km/h and I cover one kilometer in approximately 11-12 minutes.</p>
<p>Some of you might be wondering why I am sharing this, well I am sharing this as I want to document my fitness progress. Looking back, I myself can look at things I did and see how I progressed. I also want to share this with others who are interested.</p>



 ]]></description>
  <category>myself</category>
  <guid>https://kurianbenoy.com/posts/2023/fitness_journey/index.html</guid>
  <pubDate>Mon, 06 Mar 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Attending MBIFL 2023, a literature festival</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/mbifl2023/index.html</link>
  <description><![CDATA[ 




<p>Since I am a frequent book purchaser from Mathrubhumi book, in January I got a notification to buy early bird tickets for <a href="https://www.mbifl.com/speakers-2023/">MBIFL 2023</a>. I immediately bought 4 day’s tickets to attend the literature festival. When it came to February, I realised due to some commitments at home and work, I couldn’t attend all the days of this literature festival despite having a ticket.</p>
<p>MBIFL had almost 300+ speakers, with famous speakers like Nobel prize winners, Brooker prize winners, politicians etc.</p>
<p>Yet I had just one wish. <a href="https://en.wikipedia.org/wiki/Benyamin_(writer)">Benyamin</a> is an author who has written lot of thriller novels like അൽ - അറേബ്യൻ നോവൽ ഫാക്‌ടറി and മുല്ലപ്പു നിറമുള്ള പകലുകൾ(which is a dual novel) along with the famous ആടു ജീവിതം(Goat Days). I just wanted to meet him in person and get an autograph on my copy of my favourite novel.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/mbifl2023/book.jpg" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">My favourite novel</figcaption>
</figure>
</div>
<p>I travelled early morning from my house and reached the venue by almost 10:30 AM. During this time, there was a conversational session about പ്രവാസിയുടെ അക്ഷരകാലം with P Sreeramkrishan, Benyamin, Shabini Vasudev and KV Mohan Kumar. After the session, there was a huge fan base to meet author Benyamin. I first went to get a signature from another author KV Mohan Kumar in the panel, and then waited in the queue to get a signature from Benyamin.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/mbifl2023/benyamin_session.jpg" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">Session on പ്രവാസിയുടെ അക്ഷരകാലം</figcaption>
</figure>
</div>
<p>After lot of books were signed by Benyamin which was bought by his fans with some of his famous works like ആടു ജീവിതം, മാന്തളിരിലെ ഇരുപത് കമ്മ്യൂണിസ്ററ് വർഷങ്ങൾ, അൽ - അറേബ്യൻ നോവൽ ഫാക്‌ടറി. I got my copy also signed with a salutation of snehattode(with love). I just asked my favourite author does a person named Sameera Parveen who was a character in Jasmine Days really exist or not. Benyam answered that it’s a mixture of multiple people who he had seen in his life, yet there is no one such person who doesn’t exist as Sameera Parveen like Najeeb in ആടു ജീവിതം.</p>
<p>My mission was just completed in one hour and I got a few more signatures like Shabini Vasudev who is an author from Bahrain and from Vinu V John, who is the star anchor of Asianet news(who kindly reminded me he is not famous to be giving autograph).</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/mbifl2023/book_signature.jpg" class="img-fluid figure-img" width="300"></p>
<figcaption class="figure-caption">All the signature I got</figcaption>
</figure>
</div>
<p>After that, I attended the talk with Aparna Balamurali and Captian GR Gopinath. Shashi Tharoor talked about his book Pride, Prejudice and Punditry. Seeing Tharoor answer a question to a student reminded me of India’s former people’s president APJ. I wish him all the success as a politician.</p>
<p>One of the last sessions I attended that day was by Polish author Justi Guziak on Know yourself to express yourself. This session talked about improvising and was a hands-on workshop to learn this art. During the session, the speakers gave me a chit with the question <code>what was the best gift you have ever received?</code>. This question was to be asked to someone who was at the other end of the audience. I gave my question and Janaki who was from Thiruvananthapuram told me the best gift she ever received was a dog she received when she was in her 7th standard. This dog has been living with her for the past 15 years as a constant when she went through her school, then college and even after her marriage. Another situation which was given during the workshop was to convince Mr Karun to give something valuable in his hand. After a lot of convincing, I was able to share the lunch with Karun.</p>
<p>That winded up MBIFL 2023, a literature festival for me a data scientist who doesn’t have anything related to it. It was cool to interact and meet with so many cool people. I am looking forward to MBIFL 2024 soon…</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2023/mbifl2023/tharoor.jpg" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Session by Shashi Tharoor</figcaption>
</figure>
</div>
<p><em>Update 1(March 5, 2023)</em></p>
<p>I found a very cool video in 360 degree which showed how the MBIFL 2023 venue atmosphere is. It was a very cool video and I thought of including this also with this blogpost.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ZrbFzIFu-d0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>



 ]]></description>
  <category>Life</category>
  <category>Travel</category>
  <category>conference</category>
  <guid>https://kurianbenoy.com/posts/2023/mbifl2023/index.html</guid>
  <pubDate>Sun, 05 Feb 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Welcome To My Quarto Website</title>
  <dc:creator>Tristan O&#39;Malley</dc:creator>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2023/welcome/index.html</link>
  <description><![CDATA[ 




<p><img src="https://kurianbenoy.com/posts/2023/welcome/thumbnail.jpg" class="img-fluid"></p>
<p>This is my first post in a Quarto blog. Welcome everyone to my new blog.</p>
<p>I have been wanting for a long time to unify <a href="https://github.com/kurianbenoy/ml-blog">my existing Machine learning blog</a> based on fast-pages together with <a href="https://github.com/kurianbenoy/kurianbenoy.github.io/tree/4b5246ada3190dbdd73dc96d266a5ade7ef078a3">my main blog website</a>.</p>
<p>The unification process is a bit challenging:</p>
<ol type="1">
<li>All my previous blog post in main website was written with <a href="https://github.com/daattali/beautiful-jekyll">beautiful jekyll</a> format using markdown.</li>
<li>Need support for jupyter-notebook, which beautiful jekyll doesn’t support</li>
</ol>
<p>This is where Quarto comes as a saviour. It has wide support for various formats like markdown, jupyter notebook, rmarkdown. The goal, JJ and team is looking to have a single source of publication is really interesting. I was already familiar with nbdev with few of the projects I previously made.</p>
<p>I converted all of my existing blog post in markdown to fastpages markdown format. Then I leveraged <a href="https://nbdev.fast.ai/migrating.html">nbdev 1 migration scripts</a> to move it to quarto.</p>



 ]]></description>
  <category>TIL</category>
  <category>coding</category>
  <category>Webdev</category>
  <guid>https://kurianbenoy.com/posts/2023/welcome/index.html</guid>
  <pubDate>Mon, 16 Jan 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How well does CLIP models classify corn seeds?</title>
  <link>https://kurianbenoy.com/posts/2022/2022-11-07-clip_experiments.html</link>
  <description><![CDATA[ 




<p>The OpenAI CLIP model are really impressive and how it’s a foundation for stuff like stable diffusion is awesome. The thing about CLIP models which I am most impressed by is the wide range of applications it be used for like <a href="https://huggingface.co/spaces/YiYiXu/it-happened-one-frame-2">Semantic Video Search</a>, <a href="https://github.com/openai/CLIP#zero-shot-prediction">Zero shot image classification</a>, <a href="https://wandb.ai/pcuenq/photo-finder/reports/Creating-a-Semantic-Search-Engine-for-My-Photos--VmlldzoyMDE2NzQ3">searching images in your gallery</a> etc.</p>
<p>I recently <a href="https://arxiv.org/abs/2103.00020">started reading CLIP paper</a> and paper claims to have very high accuracy in image clssification accuracy. To test that claim, I thought of trying it out that in a kaggle competition I had recently participated.</p>
<p>The kaggle competition is a Corn image classification competition and is asking to classify images of corn seeds into following categories:</p>
<ul>
<li>pure</li>
<li>broken</li>
<li>discolored</li>
<li>silkcut</li>
</ul>
<p>I used <code>open_clip</code>, an open source implementation of CLIP which is having higher accuracy compared to model weights released by OpenAI.</p>
<p>Even after using one of the best accuracy CLIP models available( ViT-H-14), it got me a classification accuracy score of 27.95% in private LB whereas Resnet or Convnext models could have given easily above 75% score.</p>
<table class="table">
<thead>
<tr class="header">
<th>Model</th>
<th>Public LB</th>
<th>Private LB</th>
<th>Notebook link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ViT-B-32-quickgelu</td>
<td>0.16666</td>
<td>0.18397</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/playing-with-clip-model?scriptVersionId=108925854">link</a></td>
</tr>
<tr class="even">
<td>ViT-H-14</td>
<td>0.28591</td>
<td>0.27955</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/playing-with-clip-model?scriptVersionId=109012620">link</a></td>
</tr>
<tr class="odd">
<td>Convnext model</td>
<td>0.76149</td>
<td>0.75386</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/fastai-baseline-albumentations?scriptVersionId=106051045">link</a></td>
</tr>
</tbody>
</table>
<p><strong>UPDATE</strong></p>
<p>When I shared this results in twitter, <a href="https://twitter.com/YiYiMarz">YiYi Xu</a> suggested to try out <a href="https://github.com/openai/CLIP#linear-probe-evaluation">linear probing in CLIP</a>. She mentioned that, I was not comparing apples to apples, as I was using a zero-shot model with CLIP to compared with a fine tuned model of convnext. In order to level up, I should use linear probing which is using training data to kind of fine tune with a logistic regression model leveraging features in CLIP model.</p>
<p>Based on this, I leveraged using linear probing on the dataset. As a result my updated result are the following:</p>
<table class="table">
<thead>
<tr class="header">
<th>Model</th>
<th>Public LB</th>
<th>Private LB</th>
<th>Notebook link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Zero Shot ViT-B-32-quickgelu</td>
<td>0.16666</td>
<td>0.18397</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/playing-with-clip-model?scriptVersionId=108925854">link</a></td>
</tr>
<tr class="even">
<td>Zero Shot ViT-H-14</td>
<td>0.28591</td>
<td>0.27955</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/playing-with-clip-model?scriptVersionId=109012620">link</a></td>
</tr>
<tr class="odd">
<td>Linear probing w/ ViT-H-14</td>
<td>0.71982</td>
<td>0.72583</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/playing-with-clip-model?scriptVersionId=109012620">link</a></td>
</tr>
<tr class="even">
<td>Convnext model</td>
<td>0.76149</td>
<td>0.75386</td>
<td><a href="https://www.kaggle.com/code/kurianbenoy/fastai-baseline-albumentations?scriptVersionId=106051045">link</a></td>
</tr>
</tbody>
</table>
<p>Note: This article was originally published in <a href="https://www.kaggle.com/competitions/kaggle-pog-series-s01e03/discussion/362326">Kaggle discussion here</a></p>



 ]]></description>
  <category>coding</category>
  <category>Deep learning</category>
  <category>experience</category>
  <category>kaggle</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-11-07-clip_experiments.html</guid>
  <pubDate>Mon, 07 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/clip.png" medium="image" type="image/png" height="98" width="144"/>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Paddy Disease Classification competition</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-08-04-fastai56.html</link>
  <description><![CDATA[ 




<section id="lesson-notebooks" class="level2">
<h2 class="anchored" data-anchor-id="lesson-notebooks">Lesson Notebooks</h2>
<p>There are four notebook covering Paddy Disease Competition, and I feel each of these notebooks are excellent:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/paddy.JPG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Image of Paddy crop</figcaption>
</figure>
</div>
<ol type="1">
<li><a href="https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1">Road to Top Part 1</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2">Road to Top Part 2</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3">Road to Top Part 3</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/multi-target-road-to-the-top-part-4">Road to Top Part 4</a></li>
</ol>
</section>
<section id="how-was-paddy-competiton-for-me" class="level2">
<h2 class="anchored" data-anchor-id="how-was-paddy-competiton-for-me">How was Paddy competiton for me?</h2>
<p>This competition is still ongoing at the time of writing. Yet during one month break during which <a href="https://www.youtube.com/playlist?list=PLfYUBJiXbdtSLBPJ1GMx-sQWf6iNhb8mM">Jeremy’s live-coding sessions</a> were held. I got some time to play with Paddy disease classification competition with this competition with other fastai friends also.</p>
<p>At the start of lesson 7, Jeremy said some kind words to Nick and me which can be found in below youtube video. I am extremely lucky to learn from such a great teacher. Without these four notebooks and <a href="https://www.youtube.com/playlist?list=PLfYUBJiXbdtSLBPJ1GMx-sQWf6iNhb8mM">Jeremy’s live-coding sessions</a>, it wouldn’t have been possible.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/jeremy_class_shoutout.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Jeremy showing leaderboard in class</figcaption>
</figure>
</div>
<p><a href="https://youtube.com/clip/Ugkx5ItB_l5CnUy-T5tpfEXuqB9GR6f-bvZi">A clip from original video</a></p>
<p>I am not going in detail on this lesson, as I feel the introduction notebooks have covered everything so well. So signing off early this time.</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-08-04-fastai56.html</guid>
  <pubDate>Thu, 04 Aug 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Practical Deep Learning for Coders Course - Tabular Models (Linear Regression &amp; Random Forests)</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-07-28-fastai55.html</link>
  <description><![CDATA[ 




<section id="what-is-important-for-an-ml-practitioner" class="level2">
<h2 class="anchored" data-anchor-id="what-is-important-for-an-ml-practitioner">What is important for an ML practitioner</h2>
<p>Most of the time as a practitioner, your job is to connect a set of inputs to the sets of outputs you want with machine learning algorithm together in a framework. According to Jeremy what is important is how you tweak on first layer and last layer of neural network. The middle layer is usually not that important.</p>
</section>
<section id="remind-yourself-these-concepts" class="level2">
<h2 class="anchored" data-anchor-id="remind-yourself-these-concepts">Remind yourself these concepts</h2>
<p>Before getting started with this lesson, let’s remind ourselves <strong>What is matrix &amp; vector?</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/182064940-f5723473-d393-4a16-ab86-a7baf1ed0f8b.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
<p>In this chaper, you may stumble into terms like matrix-vector multiplication, matrix matrix products etc. So it’s a good idea to remind yourself with the concept of <a href="http://matrixmultiplication.xyz/">matrix multiplication</a> and <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">broadcasting</a>.</p>
<p>In this chapter three notebooks where covered, so it’s bit more hectic compared to the previous chapters to be honest. The notebooks covered were:</p>
<ul>
<li><a href="https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch">Linear Models and Neural net from Scratch</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework">Why you should use a framework?</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/how-random-forests-really-work/">How random forests really work</a></li>
</ul>
<p>For the course there was close to one month gap between fifth and sixth lesson, because of exams in University of Queenzland.</p>
</section>
<section id="linear-model-neural-network-from-scratch-notebook" class="level2">
<h2 class="anchored" data-anchor-id="linear-model-neural-network-from-scratch-notebook">Linear model &amp; neural network from scratch notebook</h2>
<p>In this notebook first few sections covers on data cleaning and feature engineering with pandas. A few notes which I jotted down, when I started looking into the lesson at first.</p>
<ul>
<li>In pandas never delete columns</li>
<li>You can replace missing values using mode of column</li>
<li>We can have multiple modes, so choose the first element as 0</li>
<li>In first baseline model, don’t do complicated things at the start.</li>
<li>for categorical variables we can set dummy variables for Pclass with <code>pd.get_dummies</code></li>
</ul>
<p>Then the notebook progresses first into building:</p>
<ol type="1">
<li>Linear models</li>
<li>Neural networks</li>
<li>Deep Learning</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This notebook is a pre-requisite for lesson 7 when we are covering collabrative filtering also.</p>
</div>
</div>
</section>
<section id="why-you-should-use-a-framework" class="level2">
<h2 class="anchored" data-anchor-id="why-you-should-use-a-framework">Why you should use a framework?</h2>
<p>This notebook, does some interesting feature engineering followed by building models with fastai framework. It also shows how to use ensembling with fastai library and to get in the top 25% of accuracy.</p>
<p>I have seen this cliche argument that for learning ML, you need to go into details and using frameworks is a step down. Jeremy emphasises always use good frameworks on top of it. Rather than re-inventing from scratch. Lot of the success of fast.ai comes from it not asking practitioners to go into details. One of the reasons I like frameworks like blurr, Icevision is also because of that and it’s helping users who are familiar with fastai to easily build complex computer vision and NLP models.</p>
<p>During a conversation with Icevision core-developer, <a href="https://dicksonneoh.com/">Dickson Neoh</a>:</p>
<blockquote class="blockquote">
<p>In icevision, within 10 minutes I can train an object detection model with any dataset. It may not be most accurate, yet I can iterate so quickly.</p>
</blockquote>
</section>
<section id="how-random-forests-really-work" class="level2">
<h2 class="anchored" data-anchor-id="how-random-forests-really-work">How random forests really work?</h2>
<p>Jeremy was know as the random forest guy before he became know as the Deep learning person. One of the cool things about random forest is it’s very hard to get something wrong unlike logistic regression.</p>
<p>Random forests are really intereptables, and helps in getting good accuracy. He also covered about gradient boosted trees during this lesson.</p>
</section>
<section id="homework-dataset" class="level2">
<h2 class="anchored" data-anchor-id="homework-dataset">Homework dataset</h2>
<p>To practise these techniques, I feel a good place to start is by participating in Kaggle <a href="https://www.kaggle.com/competitions/tabular-playground-series-aug-2022">Tabular Playground dataset competition</a> or <a href="https://www.kaggle.com/competitions?listOption=completed">previous tabular competitions in Kaggle</a>.</p>


</section>

 ]]></description>
  <category>fastai</category>
  <category>fastaicourse</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-07-28-fastai55.html</guid>
  <pubDate>Thu, 28 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>A strange bug when using fastai library with Weights &amp; Biases</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-07-26-wandbbug.html</link>
  <description><![CDATA[ 




<p>After attending an introduction to using weights &amp; biases along with fastai session conducted by <a href="https://twitter.com/capetorch">Thomas Capaballe</a>. I was excited to use weights and biases library along with a few of my hobby projects. I was working on training an Image classification models on the Kaggle competition dataset <a href="https://www.kaggle.com/competitions/tpu-getting-started">Petal to Metal</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/wblogo.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image info</figcaption>
</figure>
</div>
<p>In general, whenever I am passing a code to any fastai learner objects with callback. I usually directly pass it along with <code>vision_learner</code> as shown in below code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">arch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convnext_tiny_in22k"</span></span>
<span id="cb1-2">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(</span>
<span id="cb1-3">    data,</span>
<span id="cb1-4">    arch,</span>
<span id="cb1-5">    metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>error_rate,</span>
<span id="cb1-6">    cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb1-7">        WandbCallback(log_preds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, log_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb1-8">        SaveModelCallback(monitor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accuracy"</span>),</span>
<span id="cb1-9">    ],</span>
<span id="cb1-10">)</span>
<span id="cb1-11">learn.fine_tune(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span></code></pre></div>
</div>
<p>I exported this model, as I was trying to create a <a href="https://huggingface.co/spaces/kurianbenoy/Identify_which_flower">hugging face spaces to identify various flowers species</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">learn.export()</span></code></pre></div>
</div>
<p>Now I went ahead creating the inference code with requirements for this model. This is when I noticed that the model exported requires <code>wandb</code> library to run the inference code. I was totally surprised, why it was happening at first.</p>
<p><strong>Why this annoying behaviour?</strong></p>
<p>It’s because when passing the callbacks to <code>Learner</code> class or it’s variants like in case of computer vision fastai uses <code>vision_learner</code> class makes it stick around. In my case, I don’t want the callback to hang around the <code>Learner</code> class forever, as it’s just for training job monitoring only.</p>
<p>After a bit of googling, I found this solution from one of the forum posts written by <a href="twitter.com/waydegilliam">Wayde Gilliam</a>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Instead of adding your callback to <code>Learner</code> … if it is simply used for training, just include it in your call(s) to <code>fit or fit_one_cycle</code>. As the callback is no longer associated to your Learner, they won’t interfere with your call to <code>get_preds()</code>.</p>
</div>
</div>
<p><a href="https://forums.fast.ai/t/is-there-anyway-to-call-learn-get-preds-without-triggering-any-of-the-callbacks/64753/10">Original answer</a>.</p>
<p>So inorder to fix it, I just passed the callbacks I am using directly with <code>fine_tune</code> method directly. Let’s check the code to pass callbacks this way.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">arch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convnext_tiny_in22k"</span></span>
<span id="cb3-2">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(data, arch, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[accuracy, error_rate])</span>
<span id="cb3-3">learn.fine_tune(</span>
<span id="cb3-4">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb3-5">    cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb3-6">        WandbCallback(log_preds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, log_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb3-7">        SaveModelCallback(monitor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accuracy"</span>),</span>
<span id="cb3-8">    ],</span>
<span id="cb3-9">)</span></code></pre></div>
</div>
<p>Hence I learned this valuable lesson, which fixed my bug in inferencing code for <a href="https://twitter.com/kurianbenoy2/status/1543985447441145856">huggingface spaces which I was creating</a>.</p>
<p></p><div id="tweet-75543"></div><script>tweet={"url":"https:\/\/twitter.com\/kurianbenoy2\/status\/1543985447441145856","author_name":"Kurian Benoy \uD83D\uDC4D","author_url":"https:\/\/twitter.com\/kurianbenoy2","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003E\u003Ca href=\"https:\/\/twitter.com\/hashtag\/TIL?src=hash&amp;ref_src=twsrc%5Etfw\"\u003E#TIL\u003C\/a\u003E: It’s better to pass callbacks to fine_tune() and fit_one_cycle() method instead of passing directly to the learner object, to avoid unwanted effects when using your models for inference.\u003C\/p\u003E&mdash; Kurian Benoy \uD83D\uDC4D (@kurianbenoy2) \u003Ca href=\"https:\/\/twitter.com\/kurianbenoy2\/status\/1543985447441145856?ref_src=twsrc%5Etfw\"\u003EJuly 4, 2022\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-75543").innerHTML = tweet["html"];</script><p></p>
<p><a href="https://twitter.com/TheZachMueller">Zach Mueller</a> also confirmed this is the case.</p>
<p></p><div id="tweet-95905"></div><script>tweet={"url":"https:\/\/twitter.com\/TheZachMueller\/status\/1544297503771746309","author_name":"Zach Mueller","author_url":"https:\/\/twitter.com\/TheZachMueller","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EYup! Unless it&#39;s a callback designed to hang around, you should almost never tie it directly to the Learner\u003C\/p\u003E&mdash; Zach Mueller (@TheZachMueller) \u003Ca href=\"https:\/\/twitter.com\/TheZachMueller\/status\/1544297503771746309?ref_src=twsrc%5Etfw\"\u003EJuly 5, 2022\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-95905").innerHTML = tweet["html"];</script><p></p>



 ]]></description>
  <category>fastai</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-07-26-wandbbug.html</guid>
  <pubDate>Tue, 26 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Getting featured in Spaces of the week and my latest two gradio spaces</title>
  <link>https://kurianbenoy.com/posts/2022/2022-07-06-gradio_spaces.html</link>
  <description><![CDATA[ 




<p>I recently created two gradio based webapps, and one of my spaces - Paddy Doctor got featured in list of hugging face Spaces of the week.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/177607850-eed39c76-51b5-4b00-aad1-804e699540d2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
<p>Both gradio apps based on two kaggle competitions which I have been participating in. Both are on computer vision models with one to identify the type of disease in the paddy crop and another to identify the name of flowers(which I am terribly bad at remembering names).</p>
<p>Do checkout the links below for the spaces</p>
<p><a href="https://huggingface.co/spaces/hugginglearners/Paddy-Doctor">Paddy Doctor</a></p>
<p><a href="https://huggingface.co/spaces/hugginglearners/Identify_which_flower">Identify which flower</a></p>



 ]]></description>
  <category>huggingface</category>
  <category>Deep learning</category>
  <category>fastai</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-07-06-gradio_spaces.html</guid>
  <pubDate>Wed, 06 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to approach learning Vim - tips from two monks</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-06-27-tipstolearnvim.html</link>
  <description><![CDATA[ 




<p>Early morning, the disciple woke up to learn from a monk’s session at 6:30 AM to advance his skills. Today the monk was teaching about how to use vim, which is a great text editor.</p>
<p>Monk said Vim is powerful and specifically data scientists should learn Vim because interactive text munching is what we do with input data files and output data files all the time.</p>
<section id="showing-the-power-of-vim" class="level2">
<h2 class="anchored" data-anchor-id="showing-the-power-of-vim">💪Showing the power of Vim</h2>
<p>The monk then went ahead and showed how he made Youtube chapter markers from the posts as shown below. The monk wanted to convert this comment to a format which is suitable for youtube to add chapter markers, so folks can easily watch it in future.</p>
<pre><code>00:00 Create a total empty notebook
- How to be lazy and a great programmer? 03:02


04:13 Create an empty notebook and symlink from persistence storage
-  Why open a new window to use jupyter lab? to keep paperspace interface for shutting down when finished
-  Why should you read paperspace docs? What did Jeremy find out? 05:16
-  What are the interesting folders inside the root directory?
-  How is storage folder different from notebooks directory? Why both of them exist for good reason? 06:32
-  Should we worry about using pip install when paperspace uses conda a lot? 08:02
-  How to pip upgrade packages into the home directory with --user? pip install -U --user fastcore 13:14
-  What folder we want to be there next time when we open notebook? .local/
-  How to save this .local/ into persistence storage? mv .local /storage/

19:24 Create pre-run.sh from scratch to automate .local symlink from storage


-  How to create a python file to setup the symlink first before running jupyter lab 
-  Does Jeremy think paperspace is the way to have easy to use GPU for fastai in 
-  How to make a symlink from /storage/ back to this notebook’s /notebooks director
-  What does this step above do? to link the /storage/ folder back into /notebook
-  Why to access the /storage/ folder inside notebooks is useful?
-  How to create a text file, edit it and save it inside /storage/ with jupyter lab?
</code></pre>
<p>The monk opened his Vim editor and showed a bunch of ways he can easily do this task very quickly with ex commands as shown in the gif below.</p>
<p>Finally, the output will be like in this format:</p>
<pre><code>00:00 Create an notebook
04:13 Symlink from persistence storage
19:24 Create pre-run.sh from scratch to automate .local symlink from storage</code></pre>
<p>If you are curious to learn the trick, follow the below three steps:</p>
<ol type="1">
<li>To delete and move to the start of the next digit type <code>d /^\d</code></li>
<li>Then move down a row using <code>j (or down arrow)</code> and type dot ‘.’ to repeat the movement: <code>j.</code></li>
<li>When it’s almost over with no more chapter markers, type <code>dG</code> to delete till the end of the file.</li>
</ol>
</section>
<section id="disciple-asks-how-to-approach-learning-vim" class="level2">
<h2 class="anchored" data-anchor-id="disciple-asks-how-to-approach-learning-vim">Disciple asks how to approach learning Vim❓</h2>
<p>This disciple was really impressed, yet intimidated at the same time seeing this and asked to the monk <strong>how can someone learn Vim and lot’s of keyboard shortcuts he showed when someone is a beginner at this topic.</strong></p>
</section>
<section id="first-monk-speaks" class="level2">
<h2 class="anchored" data-anchor-id="first-monk-speaks">First Monk speaks</h2>
<p>The trained monk replied as following:</p>
<p>The trick with learning something new is try and like learn in small chunks. So don’t expect to learn all of Vim. At this point:</p>
<p>Start by learning i to start inserting text, arrow keys to move around, escape to go back to command mode, and :wq to close and save. At that point you can use vim to edit your shell scripts and stuff. Then try and learn maybe one or two new commands each day like motion commands w and b are useful to move forward and backward a word.</p>
<p>There are lot of tutorials out there in internet like openvim.com is very helpful to learn Vim. You can work through tutorial like this.</p>
<p>Yeah honestly we all get intimidated, when we see an expert working with something that we don’t know yet and at first it’s like WOW that’s powerful I wish i could do that. You will be like my god you know how would i ever get to that point … the goal is not to be an expert at Vim the goal is to like be able to use Vim to like slowly do something that you want to be able to do.</p>
<p>This is one of the things the I really had to practice for myself in my late teens and early 20s was to repeatedly put myself in a position where I was intentionally doing things slowly by using a tool that I wanted to know and I was pretty sure at some point would be useful but I didn’t know it well enough to do it faster than with other than some other tools.</p>
<p>So I’ve always you know since like 16 been pretty good at using Lotus 1-2-3 and Excel spreadsheets. I tended to turn to them for everything and then I wanted to learn SQL databases. So I kind of forced myself to do things involving lists with databases for a while even though I got slower and then I was like … I’m going to start doing more stuff with VBA macros and stop doing stuff manually and again it was kind of slower for a while and then became faster.</p>
<p>Particularly like you know things like cleaning up that Youtube timestamp thing to create chapter markers. I could have done that manually you know and and the first ten times it would be faster to do it manually but don’t do it manually right because each time you do it manually you know you’re missing out on the opportunity to get better at the thing that’s going to make you faster.</p>
<p>The thing about practicing what you think might eventually be the fast way is that those fast ways accumulate together in kind of these multiplicative ways. So you know I’ve been kind of using this approach of always trying to do things the way I suspect would be the fastest if i was an expert at it. I have been doing that for like 30 years now.</p>
<p>Now most people who watch me work go WOW you’re very fast at doing stuff. You must be really smart you know. I am like Oh no I’m not really smart like you should have seen me when I started, I was terrible… Yet now these things have all accumulated right.</p>
<p>If anybody finds you know good tutorials let me know honestly it’s been a long time since I’ve run a vim tutorial. So I don’t know any good tutorials and don’t know the first one that came up in google is good or bad. I am sure though openvim.com is pretty good though.</p>
<section id="thoughts-of-vim-plugins" class="level3">
<h3 class="anchored" data-anchor-id="thoughts-of-vim-plugins">Thoughts of Vim plugins</h3>
<p>I recommend don’t install lots of plugins there’s lots of plugins you can install. After using vim for well over 20 years, I don’t use any plugins at all. It’s not to say that there are none that are of any use … but like they’re not that useful honestly and you can get lost in that whole like customizing things thing. I just wanted to make it clear to say that actually out of the box Vim works fine and you customize with vimrc configurations.</p>
</section>
</section>
<section id="second-monk-speaks" class="level2">
<h2 class="anchored" data-anchor-id="second-monk-speaks">Second monk speaks</h2>
<p>This when another monk who is working in NVIDIA chimed in with tips to learn vim.</p>
<p>According to me the best tutorial for learning Vim is in terminal. The vimtutor is a excellent tutorial. The first time I looked vimtutor is intimidating, it took me only on like third or fourth try does it start to make sense and was able to complete the entire thing.</p>
<p>When i was learning the basics of them I realized Vim has a steep learning curve. I like to make things appealing, attractive and simple for me. So there is this game called vim-adventures.com.</p>
<p>When I had my corporate job and instead of whatever people do on calls which is just you know browse Reddit. I would do play with website vim-adventures to learn more.</p>
<p>Another resource, which is really great is the Vim book: Practical Vim, Edit Text at the Speed of Thought. It is really well written and there’s a similar book for tmux so that’s that’s two book which made the really big difference for me personally.</p>


</section>

 ]]></description>
  <category>opensource</category>
  <category>fastaicourse</category>
  <category>terminal</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-06-27-tipstolearnvim.html</guid>
  <pubDate>Mon, 27 Jun 2022 00:00:00 GMT</pubDate>
  <media:content url="https://kurianbenoy.com/posts/images/monk.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Building a baseline model for Malayalam Text Classification</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-06-04-baselinemodel.html</link>
  <description><![CDATA[ 




<section id="why-trying-out-simple-baseline-models" class="level2">
<h2 class="anchored" data-anchor-id="why-trying-out-simple-baseline-models">Why trying out simple baseline models?</h2>
<p>I have been working on open source project to work on Malayalam text classification approaches. If you want to follow along the previous blogs check the <a href="https://kurianbenoy.com/ml-blog/categories/#malayalamtextmodels">tag #malayalamtextmodels</a></p>
<p>One of the most under-rated advices which I actually learned from the Approaching almost any Machine learning Problem(AAAMLP) by <a href="https://twitter.com/abhi1thakur">Abhishek Thakur</a> was to start always with simple models and to create a baseline first. This is something <a href="https://twitter.com/jeremyphoward">Jeremy</a> also repeatedly emphasises:</p>
<blockquote class="blockquote">
<p>So we should always be careful to benchmark simple models, as see if they’re good enough for our needs. In practice, you will often find that simple models will have trouble providing adequate accuracy for more complex tasks, such as recommendation systems, NLP, computer vision, or multivariate time series. But there’s no need to guess – it’s so easy to try a few different models, there’s no reason not to give the simpler ones a go too!</p>
</blockquote>
<p><a href="https://github.com/fastai/course22/blob/master/07-how-random-forests-really-work.ipynb">source: 7-how-random-forests-really-work</a></p>
</section>
<section id="doing-modeling-with-simple-approaches" class="level2">
<h2 class="anchored" data-anchor-id="doing-modeling-with-simple-approaches">Doing modeling with simple approaches</h2>
<p>Instead of directly trying out transformers models, I first thought of working with some simple models and see how well they perform. Since I had previously read AAAMLP and seen Abhisheks chapter on how trying out simple techniques in IMDB dataset have him impressive results. I also thought of trying the same approaches.</p>
<p>What follows is my attempt to follow steps initially outlined in AAAMLP book.My code doesn’t depart from the original code in book much.</p>
<p>Let’s start off by importing libraries:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> nltk</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk.tokenize <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> word_tokenize</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> linear_model</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> naive_bayes</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> metrics</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> model_selection</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> preprocessing</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.feature_extraction.text <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CountVectorizer</span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.feature_extraction.text <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TfidfVectorizer</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"punkt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to
[nltk_data]     /home/kurianbenoy/nltk_data...
[nltk_data]   Package punkt is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>True</code></pre>
</div>
</div>
<p>For training, I used a privately shared dataset with me which contained news articles with their associated labels. It contained almost 9000+ sentences labelled in 6 categories of news like Sports, Kerala, Business, Gulf, India, Entertainment.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"labels"</span>].value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Kerala           3847
Entertainment    1968
Sports           1061
Gulf             1034
India             881
Business          572
Name: labels, dtype: int64</code></pre>
</div>
</div>
<section id="logistic-regression-countvectorizer" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-countvectorizer">Logistic regression + CountVectorizer</h3>
<p>One of the first models shared was about using Logistic regression and Count Vectorizer model in AAAMLP book. Let’s see how well it performs in our dataset.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">count_vec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CountVectorizer(tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb8-2">count_vec.fit(df.text)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 15.3 s, sys: 196 ms, total: 15.5 s
Wall time: 15.5 s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CountVectorizer(token_pattern=None,
                tokenizer=&lt;function word_tokenize at 0x7f940dc34d30&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">CountVectorizer</label><div class="sk-toggleable__content"><pre>CountVectorizer(token_pattern=None,
                tokenizer=&lt;function word_tokenize at 0x7f940dc34d30&gt;)</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb10-2">xtrain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(df.text)</span>
<span id="cb10-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model.LogisticRegression()</span>
<span id="cb10-4">model.fit(xtrain, df.labels)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 4min 27s, sys: 7.5 s, total: 4min 35s
Wall time: 1min 2s</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked=""><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression()</pre></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb13-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: [</span>
<span id="cb13-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"സ്കൂബാഡൈവിങ്ങ്, സ്നോർക്കേലിങ്ങ്, സ്പീഡ്ബോട്ടിങ്ങ്, സർഫിങ്ങ് തുടങ്ങിയ കടൽവിനോദങ്ങൾക്കു പേരുകേട്ട ബാലിയിൽ പോയിട്ടും ഇതൊന്നും പരീക്ഷിച്ചില്ല.ധൈര്യം വരാത്തതുകൊണ്ടാണ്. ഇപ്പോൾ ആലോചിക്കുമ്പോൾ ഒരുകൈ നോക്കാമായിരുന്നെന്നുോന്നുന്നു. സാരമില്ല, ബാക്കിവെച്ച ആഗ്രഹങ്ങളാണല്ലോ മുന്നോട്ടുനീങ്ങാനുള്ള പ്രേരണ. അവസരങ്ങൾ ഇനിയുമുണ്ടാകുമെന്ന് കരുതുന്നു."</span></span>
<span id="cb13-4">    ],</span>
<span id="cb13-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"labels"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sport"</span>],</span>
<span id="cb13-6">}</span>
<span id="cb13-7">data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>{'text': ['സ്കൂബാഡൈവിങ്ങ്, സ്നോർക്കേലിങ്ങ്, സ്പീഡ്ബോട്ടിങ്ങ്, സർഫിങ്ങ് തുടങ്ങിയ കടൽവിനോദങ്ങൾക്കു പേരുകേട്ട ബാലിയിൽ പോയിട്ടും ഇതൊന്നും പരീക്ഷിച്ചില്ല.ധൈര്യം വരാത്തതുകൊണ്ടാണ്. ഇപ്പോൾ ആലോചിക്കുമ്പോൾ ഒരുകൈ നോക്കാമായിരുന്നെന്നുോന്നുന്നു. സാരമില്ല, ബാക്കിവെച്ച ആഗ്രഹങ്ങളാണല്ലോ മുന്നോട്ടുനീങ്ങാനുള്ള പ്രേരണ. അവസരങ്ങൾ ഇനിയുമുണ്ടാകുമെന്ന് കരുതുന്നു.'],
 'labels': ['sport']}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(data)</span>
<span id="cb15-2">test_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">labels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>സ്കൂബാഡൈവിങ്ങ്, സ്നോർക്കേലിങ്ങ്, സ്പീഡ്ബോട്ടിങ...</td>
<td>sport</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.sample(frac<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-2">test_df.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(936, 2)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">xtest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(test_df.text)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(xtest)</span>
<span id="cb19-2">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> metrics.accuracy_score(test_df.labels, preds)</span>
<span id="cb19-3">accuracy</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>0.9989316239316239</code></pre>
</div>
</div>
<p>You may be wondering, why I haven’t deleted all these code piece even after experimenting. This is something, which recently picked up following fastai v5 course. Instead of always deleting after experimenting, keep your experiments also public. But after experimentation is done, wrap it up as function like the one below so you can reuse it in future experiments as well.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> vectorize_evaluate_loop(train_df, test_df):</span>
<span id="cb21-2">    count_vec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CountVectorizer(tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb21-3">    count_vec.fit(train_df.text)</span>
<span id="cb21-4">    dependent_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(train_df.text)</span>
<span id="cb21-5">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model.LogisticRegression()</span>
<span id="cb21-6">    model.fit(dependent_train, train_df.labels)</span>
<span id="cb21-7">    dependent_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(test_df.text)</span>
<span id="cb21-8">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(dependent_test)</span>
<span id="cb21-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> metrics.accuracy_score(test_df.labels, predictions)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>time</span>
<span id="cb22-2">vectorize_evaluate_loop(df, test_df)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 4min 37s, sys: 6.69 s, total: 4min 43s
Wall time: 1min 17s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.9989316239316239</code></pre>
</div>
</div>
<p>The function to create k-folds for calculating validation accuracy across K folds of data. It’s very important to create <a href="https://www.fast.ai/2017/11/13/validation-sets/">good validation sets</a>.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kfold"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb26-2">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.sample(frac<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">df.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(9363, 3)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">Y_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.labels.values</span>
<span id="cb29-2">kf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_selection.StratifiedKFold(n_splits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb29-3"></span>
<span id="cb29-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> fold, (text_, value_) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(kf.split(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Y_value)):</span>
<span id="cb29-5">    df.loc[value_, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kfold"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fold</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> fold_ <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb30-2">    train_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-3">    test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb30-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Fold value: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fold_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb30-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>vectorize_evaluate_loop(train_df, test_df)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold value: 0
Accuracy: 0.8873465029364656
Fold value: 1
Accuracy: 0.8777362520021356
Fold value: 2
Accuracy: 0.8916177255739456
Fold value: 3
Accuracy: 0.875
Fold value: 4
Accuracy: 0.8669871794871795</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
</div>
</section>
<section id="naive-bayes-classifier" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes-classifier">Naive Bayes Classifier</h3>
<p>A bit faster to complete training, yet only difference is it’s having less accuracy compared to previous approach.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> naive_bayes_evaluate_loop(train_df, test_df):</span>
<span id="cb33-2">    count_vec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CountVectorizer(tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb33-3">    count_vec.fit(train_df.text)</span>
<span id="cb33-4">    dependent_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(train_df.text)</span>
<span id="cb33-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># changing different model name for function</span></span>
<span id="cb33-6">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> naive_bayes.MultinomialNB()</span>
<span id="cb33-7">    model.fit(dependent_train, train_df.labels)</span>
<span id="cb33-8">    dependent_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(test_df.text)</span>
<span id="cb33-9">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(dependent_test)</span>
<span id="cb33-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> metrics.accuracy_score(test_df.labels, predictions)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> fold_ <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb34-2">    train_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb34-3">    test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb34-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Fold value: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fold_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb34-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>naive_bayes_evaluate_loop(train_df, test_df)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold value: 0
Accuracy: 0.8441003737319808
Fold value: 1
Accuracy: 0.8227442605445809
Fold value: 2
Accuracy: 0.8296849973304858
Fold value: 3
Accuracy: 0.8269230769230769
Fold value: 4
Accuracy: 0.8183760683760684</code></pre>
</div>
</div>
</section>
<section id="logistic-regression-tfidf-vectorizer" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-tfidf-vectorizer">Logistic Regression + Tfidf Vectorizer</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> tf_idf_evaluate_loop(train_df, test_df):</span>
<span id="cb36-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># note we are using TfidfVectorizer instead of CountVectorizer</span></span>
<span id="cb36-3">    count_vec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TfidfVectorizer(tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>word_tokenize, token_pattern<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb36-4">    count_vec.fit(train_df.text)</span>
<span id="cb36-5">    dependent_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(train_df.text)</span>
<span id="cb36-6">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model.LogisticRegression()</span>
<span id="cb36-7">    model.fit(dependent_train, train_df.labels)</span>
<span id="cb36-8">    dependent_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> count_vec.transform(test_df.text)</span>
<span id="cb36-9">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(dependent_test)</span>
<span id="cb36-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> metrics.accuracy_score(test_df.labels, predictions)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> fold_ <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb37-2">    train_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb37-3">    test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df.kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> fold_].reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb37-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Fold value: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fold_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb37-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tf_idf_evaluate_loop(train_df, test_df)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold value: 0
Accuracy: 0.8478376935397758
Fold value: 1
Accuracy: 0.8344901227976508
Fold value: 2
Accuracy: 0.8489054991991457
Fold value: 3
Accuracy: 0.8290598290598291
Fold value: 4
Accuracy: 0.8253205128205128</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluating-and-looking-results" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-and-looking-results">Evaluating and looking results</h2>
<p>I am genuinely surprised by the following:</p>
<ol type="1">
<li>A simple linear regression on this text classification tasks get’s close to 87-89% accuracy when evaluated using K-fold validation approach. We haven’t done any complex fine tuning or even label_encoding at the moment. Based on improving with some more tweaks, I am trying a <a href="https://github.com/smc/malayalam-text-classifier/tree/main/notebooks">few things here</a>.</li>
<li>The state of art model for Text classification in Malayalam claims to have got 92% accuracy based on training only on validation dataset, like we have done in sklearn it seems.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/171474436-2e9a25d5-5e62-41a0-b249-e65a2df57585.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
<p><a href="https://github.com/adamshamsudeen/Vaaku2Vec/blob/master/train_classifier.ipynb">Source</a></p>
<p><strong>What is the difference between Vaaku2Vec and this simple model if it’s just less than 3% more accurate?</strong></p>
<blockquote class="blockquote">
<p>Yet there is a huge difference between ULMFiT approach which Vaaku2Vec and our baseline model. The Vaaku2Vec model has been trained on base model of Malayalam Wikipedia text, so more text corpus will be present and the model has learned from it. In case of our simple baseline model, it has learned just from 9000+ data points only. Now in case of a new word which is not in this dataset, there is a probability it maybe found in Vaaku2Vec model. Yet it’s not always true, because words like Covid will defenitely be not recognized by Vaaku2Vec model also.</p>
</blockquote>
</section>
<section id="using-simple-models-for-labelling" class="level2">
<h2 class="anchored" data-anchor-id="using-simple-models-for-labelling">Using simple models for labelling</h2>
<p>One of the best things about using simple models to train is also that you can use it for data labelling efforts. To be honest, I am still learning more about data-annotation and labelling. My friend Alex is an expert though here and checkout his awesome blog <a href="https://blog.zenml.io/data-labelling-annotation">How to get the most out of data annotation</a>. I really loved this image showing 5 steps of datalabelling.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/171987028-11d5e564-f292-4478-8273-749c5d280045.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
<p><a href="https://blog.zenml.io/data-labelling-annotation/">Source and credits: Alex</a></p>
<p>I see more work on data annotation coming soon as part of this project also. With that have a nice day.</p>


</section>

 ]]></description>
  <category>malayalamtextmodels</category>
  <category>Malayalam</category>
  <category>NLP</category>
  <category>opensource</category>
  <category>ML</category>
  <category>Deep learning</category>
  <category>SMC</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-06-04-baselinemodel.html</guid>
  <pubDate>Sat, 04 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Starting an open-source project - Malayalam Text Classifier</title>
  <link>https://kurianbenoy.com/posts/2022/2022-05-30-malayalamtext-0.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/malayalam.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">malayalam letters</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>TLDR: Kurian has committed to start an <a href="https://github.com/smc/malayalam-text-classifier">open-source project for Text classification</a> tasks in Malayalam which is going to build as an open-source project under <a href="https://smc.org.in/">SMC community</a>.</p>
</blockquote>
<section id="why-i-am-starting-this-project" class="level2">
<h2 class="anchored" data-anchor-id="why-i-am-starting-this-project">Why I am starting this project?</h2>
<p>I have been doing the fastai course since 2018. Yet I have been taking it seriously probably, only after I bought the book <a href="https://kurianbenoy.com/2021-06-10-Fast-group/">Deep Learning for Coders with FastAI &amp; Pytorch</a> almost one year back. This year I took the <a href="https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai">fastai v5 course</a>, and I feel it’s time to follow a piece of advice which I have heard multiple times.</p>
<blockquote class="blockquote">
<p>Important: Jeremy Howard, who is teaching this course and wrote the book prompts you to take what you learned and apply it to something that has meaning for you. (This is something that most of those who’ve found any success with the course <a href="https://sanyambhutani.com/how-not-to-do-fast-ai--or-any-ml-mooc-/">emphasise repeatedly</a>.)</p>
</blockquote>
</section>
<section id="problem-domain" class="level2">
<h2 class="anchored" data-anchor-id="problem-domain">Problem Domain</h2>
<p>According to <a href="https://huggingface.co/tasks/text-classification">huggingface tasks page</a>:</p>
<blockquote class="blockquote">
<p>Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness.</p>
</blockquote>
<p>Malayalam is a highly inflectional and agglutinative language compared to other languages. The quantitative complexity of Malayalam classification was <a href="https://kavyamanohar.com/documents/tsd_morph_complexity_ml.pdf">explained in this paper</a>. The computer still doesn’t seem to have understood the basic behaviour of the language to do text classification. Malayalam is a language which morphologically complex making it even more difficult.</p>
<p>Very few people seem to have applied techniques in deep learning in Malayalam, and it seems to be a good place to see if really deep learning techniques can be applied in my mother tongue, Malayalam. A lot of progress in other languages has happened and in general NLP, yet it’s a good time to see if it works in Indic languages like Malayalam.</p>
</section>
<section id="why-text-classification-is-interesting" class="level2">
<h2 class="anchored" data-anchor-id="why-text-classification-is-interesting">Why Text classification is interesting?</h2>
<p>I believe working on tasks like <code>Text classification</code> is way more difficult when we are working in low-resource languages like Malayalam. Yet when working on problems like this, you realize what are things you take for granted in the English language.</p>
<p>In the English language, there are plenty of labelled datasets on any problem set you to want. A lot of articles and blogs have been written on how to apply various NLP techniques in English. When it comes to Malayalam, there is just a handful of people who have tried and applied this in Malayalam.</p>
<blockquote class="blockquote">
<p>Note to myself: Will is more important than Skill and it’s important to be tenacious here.</p>
</blockquote>
<p>I believe this is here, it’s very important to believe in one’s tenacity and try out new things in a field where very less research happening, and there are no proper open datasets for researchers to work on. This is why I feel this project can be challenging, and my approach is to see if the latest transformer approaches can do something or not.</p>
</section>
<section id="previous-work-vaaku2vec" class="level2">
<h2 class="anchored" data-anchor-id="previous-work-vaaku2vec">Previous work: Vaaku2Vec</h2>
<p>The most important work in Malayalam text classification as far as I know is <a href="https://github.com/adamshamsudeen/Vaaku2Vec">Vaaku2Vec project - State-of-the-Art Language Modeling and Text Classification in the Malayalam Language</a>.</p>
<p>According to their Github README:</p>
<blockquote class="blockquote">
<p>We trained a Malayalam language model on the Wikipedia article dump from Oct, 2018. The Wikipedia dump had 55k+ articles. The difficulty in training a Malayalam language model is text tokenization since Malayalam is a highly inflectional and agglutinative language. In the current model, we are using an nltk tokenizer (will try better alternative in the future) and the vocab size is 30k. The language model was used to train a classifier which classifies a news into 5 categories (India, Kerala, Sports, Business, Entertainment). Our classifier came out with a whooping 92% accuracy in the classification task.</p>
</blockquote>
<p>It was revolutionary at that time, to see deep learning techniques applied to get SOTA in Malayalam. IndicNLP as an organisation did a lot of work, from working on projects like Word2vec, Vaakk2vec etc. They worked on creating a Named entity recognition dataset for Malayalam etc. They conducted Devsprints in colleges like Model Engineering college… and presented their work in Pycon India and Kochi Python. Most of the work was done by <a href="https://www.linkedin.com/in/adamshamsudeen/">Adam Shamsudeen</a> and <a href="https://www.linkedin.com/in/kamalkraj/">Kamal K Raj</a>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rgCXWaKzMKU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="whats-the-plan-for-the-project" class="level2">
<h2 class="anchored" data-anchor-id="whats-the-plan-for-the-project">What’s the plan for the project?</h2>
<blockquote class="blockquote">
<p>Important: Cervantes once wrote that “the journey is better than the inn”, which means that the process is more valuable than the destination.</p>
</blockquote>
<p>At moment, the project doesn’t have any concrete goals and it’s just me who is working in my free time.</p>
<p>I have created a <a href="https://github.com/smc/malayalam-text-classifier/issues">few issues</a> and my next blog post will be on creating a baseline model on a private dataset that a few kind folks shared with me. I expect the dataset creation to be an iterative task. I am looking forward to blogging about what I work on and stumble upon in each stage of the project.</p>
<p>When I was looking for where I wanted to create this as an open-source project obviously, I choose <a href="https://smc.org.in/">Swathanthra Malayalam Community</a> because:</p>
<ul>
<li>I feel SMC as an organization played a pivotal part in revolutionizing Malayalam computing and has a strong community presence. They have made a lot of work by creating fonts, helping in internationalization efforts, …</li>
<li>People like <a href="https://thottingal.in/">Santhosh Thottingal</a> and <a href="https://kavyamanohar.com/">Kavya Manohar</a> have helped me a lot in my previous failed attempt to <a href="https://github.com/kurianbenoy/MTTS">build TTS with deep learning in Malayalam</a>.</li>
<li>Some of the open-source projects made by SMC still survive like the website of <a href="https://msc.smc.org.in/">Malayalam Speech Corpus</a> which is impressive to me.</li>
</ul>
<p>I would like to thank the following people for all the support and motivation they have given me in starting this open-source project on this occasion:</p>
<ol type="1">
<li><a href="https://twitter.com/strickvl/">Alex Strick van Linschoten</a></li>
<li><a href="https://twitter.com/santhoshtr">Santhosh Thottingal</a> and <a href="https://twitter.com/kavya_manohar">Kavya Manohar</a></li>
<li><a href="https://twitter.com/fanbyprinciple">Ashwin Jayaprakash</a></li>
</ol>


</section>

 ]]></description>
  <category>malayalamtextmodels</category>
  <category>Malayalam</category>
  <category>NLP</category>
  <category>opensource</category>
  <category>ML</category>
  <category>Deep learning</category>
  <category>SMC</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-05-30-malayalamtext-0.html</guid>
  <pubDate>Mon, 30 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Installing Python Packages &amp; setting up libraries for Data Science - the right way</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-05-28-fastai-walthrus1.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p><a href="https://forums.fast.ai/u/jeremy">Jeremy</a> has been conducting these official course walk-thrus which started on May 27, 2022 for students of <a href="https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai">fastaiv5 course</a>. The idea of these course walk-thrus were “going to explain exactly how to do every step, and why we do things the way we do”.</p>
<p>We in the sense <code>fastai</code> approach of development. It was very useful to me and it covered answers to some of things which I was searching for a long time. I will use it again and again, so thought of writing it down to refer later. The first walk thrus was on the topic: <code>Introduction to the terminal. How to install Python and libraries</code> and I felt I got more value out of these walk-thrus than some of lessons in course</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The right way here means the way Jeremy does stuff. Obiviously there as thousand of way to do thing, yet going through each ways has it’s own pros/cons.</p>
</div>
</div>
</section>
<section id="whats-terminal-how-to-work-with-it" class="level2">
<h2 class="anchored" data-anchor-id="whats-terminal-how-to-work-with-it">🚖 What’s terminal, how to work with it?</h2>
<section id="terminal-vs-shell" class="level3">
<h3 class="anchored" data-anchor-id="terminal-vs-shell">Terminal vs Shell</h3>
<p>A terminal is a program which can display console window to run program. Yet thing inside is not strictly a terminal, but called a shell. The black coloured stuff, which you see in movies used by hackers is Terminal as shown in image below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/170852543-17bdb268-7ace-43c6-b1a0-a2b5b0a9ac43.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
<p>Usually in a <strong>terminal there can be multiple shells</strong>, which can have different colours, shells etc. So terminal and shell are totally different in meaning. You can think shell as the a ship which does main things it’s supposed to do like running program, while terminal is like the a group of ships which is usually controlled by a parent like a corporal.</p>
<p>In a windows terminal it can start no of shells like <code>PowerShell, Command Prompt, Ubuntu</code> etc… Most of the time we use both terminal and shell interchangebly which is ok.</p>
</section>
<section id="installing-terminal-shell" class="level3">
<h3 class="anchored" data-anchor-id="installing-terminal-shell">Installing Terminal &amp; Shell</h3>
<p>You can install terminal in Windows by downloading <a href="https://apps.microsoft.com/store/detail/windows-terminal/9N0DX20HK701?hl=en-us&amp;gl=US">Windows terminal</a>. In case of linux/MacOS, you can just search for terminal as it will come with a terminal pre-installed.</p>
<p>In Windows, Jeremy recommends to use <a href="https://docs.microsoft.com/en-us/windows/wsl/install">WSL</a>, which install a linux distribution within windows and then install <a href="https://apps.microsoft.com/store/detail/ubuntu/9PDXGNCFSCZV">Ubuntu from Microsoft Store</a>.</p>
</section>
<section id="handy-tips" class="level3">
<h3 class="anchored" data-anchor-id="handy-tips">Handy Tips</h3>
<p>It’s a good idea to change the default shell from <code>Power shell to Ubuntu</code> for easy usage. Also learn some keyboard shortcuts.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Learning Keyboard shortcuts can be immensely valuable.</p>
</div>
</div>
</section>
<section id="keyboard-shortcuts" class="level3">
<h3 class="anchored" data-anchor-id="keyboard-shortcuts">Keyboard shortcuts</h3>
<p>Some of the useful keyboard shortcuts shared during lesson and in forums are as follows:</p>
<p><strong>Shared by <a href="https://forums.fast.ai/u/jeremy/summary">Jeremy</a></strong></p>
<p><kbd>Ctrl+Shift+1</kbd> - Open shell set for default profile.</p>
<p><kbd>Ctrl+Shift+3</kbd> - Open shell listed as number 3 in WSL.</p>
<p><kbd>Alt+Enter</kbd> - Enter terminal in full screen.</p>
<p><kbd> Ctrl + r </kbd> - Recursvie back search to search the previous typed commands.</p>
<p><kbd>Ctrl-a</kbd> - Move to the start of the current line.</p>
<p><kbd>Ctrl-e</kbd> - Move to the end of the line.</p>
<p><kbd>Tab</kbd> Autocomplete.</p>
<p><strong>Shared by <a href="https://forums.fast.ai/u/miwojc/summary">miwojc</a></strong></p>
<p><kbd>Ctrl-f</kbd> - Move forward a character.</p>
<p><kbd>Ctrl-b</kbd> - Move back a character.</p>
<p><kbd>Alt-f</kbd> - Move forward to the end of the next word. Words are alphanumeric.</p>
<p><kbd>Alt-b</kbd> - Move back to the start of the current or previous word. Words are alphanumeric.</p>
<p><kbd>Ctrl-l</kbd> - Clear the screen.</p>
<p><kbd>Ctrl-p</kbd> - Fetch the previous command from the history list (same as up but easier to reach).</p>
<p><kbd>Ctrl-n</kbd> - Fetch the next command from the history list (same as down).</p>
<p><kbd>Ctrl-r</kbd> - Search backward through history.</p>
<p><kbd>Ctrl-d</kbd> - Delete the character under the cursor.</p>
<p><kbd>Ctrl-k </kbd> - Kill (cut) forwards to the end of the line.</p>
<p><kbd>Ctrl-u</kbd> - Kill (cut) backwards to the start of the line.</p>
<p><kbd>Alt-d</kbd> - Kill (cut) forwards to the end of the current word.</p>
<p><kbd>Ctrl-w</kbd> - Kill(cut) backwards to the start of the current word.</p>
<p><strong>Shared by <a href="https://forums.fast.ai/u/kurianbenoy/summary">Kurian</a></strong></p>
<p><kbd>Alt Shift + </kbd> - Open a new vertical pane</p>
<p><kbd>Alt Shift -</kbd> - Open a new horizontal pane</p>
<p><kbd>Ctrl Shift w</kbd> - Closing a Pane</p>
</section>
</section>
<section id="how-to-install-python-packages-for-datascience" class="level2">
<h2 class="anchored" data-anchor-id="how-to-install-python-packages-for-datascience">🔰 How to install Python Packages for datascience</h2>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Never use the python which comes by default with operating system, always use a differnt python to work on stuff you want, else it will become really messy… ⚠️.</p>
</div>
</div>
<section id="installation-with-mamba" class="level3">
<h3 class="anchored" data-anchor-id="installation-with-mamba">Installation with mamba</h3>
<p>To follow this advice, this let’s go ahead and install python seperately with packaging manager called <a href="https://github.com/mamba-org/mamba">mamba</a> which is a Fast Cross-Platform Package Manager. It’s aka. faster version of conda.</p>
<p>So go to the <a href="https://github.com/conda-forge/miniforge#mambaforge">mambaforge installer</a>. Based on your operating system, download the shell script to install with:</p>
<pre><code>wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh
bash Mambaforge-Linux-x86_64.sh</code></pre>
<p>After downloading and installation is complete. To refresh terminal either close and reopen terminal or typing below command:</p>
<pre><code>. ~/.bashrc</code></pre>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Jeremy recommends to install popular libraries which are supported in conda from mamba. If it’s not there in conda, or something which requires editable install use pip.</p>
</div>
</div>
</section>
<section id="uninstalling-mambaconda" class="level3">
<h3 class="anchored" data-anchor-id="uninstalling-mambaconda">🐛 Uninstalling mamba/conda</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you are a beginner, working with virtual environments is intimidating. So jeremy recommends whenever you face any issues as a beginner, it’s important to know how to delete your setup.</p>
</div>
</div>
<p>These are steps to see if conda/mamba is properly uninstalled in a linux environment:</p>
<ul>
<li>Check if ipython, jupyter is installed. If yes, first uninstall it.</li>
</ul>
<p><strong>Note: You can uninstall via:</strong></p>
<pre><code>pip uninstall jupyter
pip uninstall ipython3</code></pre>
<p><strong>You can check the path of program by typing the command, to see if was installed by system python or mamba</strong></p>
<pre><code>(base) kurianbenoy@Lap-34:~/blog/ml-blog$ which jupyter
/home/kurianbenoy/mambaforge/bin/jupyter</code></pre>
<ul>
<li>Then remove mamabaforge folder. In linux usually, mambaforge is installed in /home/username.</li>
</ul>
<p>So to delete the mambaforge package:</p>
<pre><code>(base) kurianbenoy@Lap-34:~$ ls
blog  downloads  mambaforge
(base) kurianbenoy@Lap-34:~$ rm -rf mambaforge/</code></pre>
<ul>
<li>Then delete conda package also.</li>
</ul>
</section>
<section id="using-fastsetup" class="level3">
<h3 class="anchored" data-anchor-id="using-fastsetup">Using fastsetup</h3>
<p><a href="github.com/fastai/fastsetup">Goto github repository</a> and download the <a href="https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh">setup-conda.sh file</a>.</p>
<pre><code>wget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh</code></pre>
<p>This is a normal shell script, so just run the shellscript to install mamba as follows:</p>
<pre><code>source setup-conda.sh
. ~/.bashrc
conda install -yq mamba</code></pre>
</section>
<section id="my-question-to-jeremy" class="level3">
<h3 class="anchored" data-anchor-id="my-question-to-jeremy">My question to Jeremy</h3>
<p>❓I asked to Jeremy about: which version of python is using and how to use for a different python version</p>
<p>Jeremy on checking Mambaforge repository, realised that python version which we are using now is python 3.9. It’s always a good idea to know, which kind of python versions are near their end of life and <a href="https://endoflife.date/python">can be here</a>. At the time of writing any version above python 3.7 to python3.10 is recommended to use. Yet according to Jeremy, he usually prefers to use latest python only 1 year after it’s released, but fastai do support the latest version.</p>
<p><a href="https://twitter.com/radekosmulski/">Radek</a> who is a engineer at Nvidia, told he usually prefer mamba because with just one line of code you can switch to any python version you want. Afer the session in forums, Radek shared how to do this as shown in below screenshot.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/170855465-1f74f66e-8238-43a2-b9f3-dcbff67a547b.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
</section>
<section id="installing-datascience-packages---pytorch-and-jupyter" class="level3">
<h3 class="anchored" data-anchor-id="installing-datascience-packages---pytorch-and-jupyter">Installing datascience packages - pytorch and jupyter</h3>
<p>Since for fastai course, we are using pytorch. Let’s install pytorch based on <a href="https://pytorch.org/">official page instructions</a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/170853841-9ed4763c-4969-40fd-9db9-01b6f06e612e.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>One of the advantages of installing libraries like pytorch in Anaconda is that if you are using conda, it install all the packages and drivers for GPU setup as well. In a normal pip based installation, there are lot more steps required for installing correctly in GPU.</p>
</div>
</div>
<p><strong>Go ahead and install python packages in this manner, by just replacing conda with mamba.</strong></p>
<pre><code>mamba install pytorch torchvision torchaudio cpuonly -c pytorch</code></pre>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s always a good idea to google and find the correct conda packages before installation, as conda requires some specifications like setting the correct channel to install.</p>
</div>
</div>
<p><strong>Now let’s install <code>jupyter lab</code> to do our experiments quickly:</strong></p>
<pre><code>mamba install jupyterlab</code></pre>
<p>Then run the jupyter lab, with the following command:</p>
<pre><code>jupyter lab --no-browser</code></pre>
<p>This opens up jupyterlab in localhost:8888</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/2022/https:/user-images.githubusercontent.com/24592806/170855155-67d3167c-e635-40a6-a0cb-bd12d6d81d0d.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image</figcaption>
</figure>
</div>
</section>
<section id="installing-packages-with-fastchan" class="level3">
<h3 class="anchored" data-anchor-id="installing-packages-with-fastchan">Installing packages with fastchan</h3>
<p>Even though Jeremy didn’t cover this topic during walk-thrus. I came to know about <code>fastchan</code> when I wanted to install <code>pytorch and huggingface transformers</code> in a gpu based system. What is fastchan and the problem it solves is covered by <a href="https://wandb.ai/wandb_fc/pytorch-image-models/reports/A-faster-way-to-get-working-and-up-to-date-conda-environments-using-fastchan---Vmlldzo2ODIzNzA">detailed blogpost</a> by the <a href="https://wandb.ai/aarora">Aman Arora</a>.</p>
<p>To install both <code>pytorch and huggingface transformers</code> in a GPU, I used the following command:</p>
<pre><code>mamba install pytorch transformers cudatoolkit=11.4 -c fastchan</code></pre>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>One of fastai students, during the start of lesson talked about the need of a quick setup, which just works as expected. One of biggest takeaways for me, personally is a quick and fastsetup to do my experiments in DataScience. Sometimes installing packages in data science can take hours of effort, and that’s why I really loved this setup.</p>
<p>Thanks to <a href="twitter.com/jeremyphoward/">Jeremy Howard</a> for creating this quick setup and for starting the project <a href="https://www.fast.ai/2021/07/15/fastconda/">fastchan</a>.</p>


</section>

 ]]></description>
  <category>fastaicourse</category>
  <category>terminal</category>
  <category>Python</category>
  <category>setup</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-05-28-fastai-walthrus1.html</guid>
  <pubDate>Sat, 28 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Quickly trying out a NLP model for Kaggle Competition</title>
  <dc:creator>Kurian Benoy</dc:creator>
  <link>https://kurianbenoy.com/posts/2022/2022-05-23-nlpkagglecomp.html</link>
  <description><![CDATA[ 




<p>This is my attempt to see how well we can build a NLP model for <a href="https://www.kaggle.com/competitions/nlp-getting-started/overview">Natural Language Processing with Disaster Tweets</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kurianbenoy.com/posts/images/nlp_random.jpeg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">NLP random competition</figcaption>
</figure>
</div>
<p>According to competition you are required to :</p>
<blockquote class="blockquote">
<p>In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we’ve created a quick tutorial to get you up and running.</p>
</blockquote>
<section id="downloading-data" class="level2">
<h2 class="anchored" data-anchor-id="downloading-data">Downloading Data</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">creds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb2-2"></span>
<span id="cb2-3">cred_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"~/.kaggle/kaggle.json"</span>).expanduser()</span>
<span id="cb2-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> cred_path.exists():</span>
<span id="cb2-5">    cred_path.parent.mkdir(exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-6">    cred_path.write_text(creds)</span>
<span id="cb2-7">    cred_path.chmod(<span class="bn" style="color: #AD0000;
background-color: null;
font-style: inherit;">0o600</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span> kaggle competitions download <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>c nlp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>getting<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>started</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>nlp-getting-started.zip: Skipping, found more recently modified local copy (use --force to force download)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span> unzip nlp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>getting<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>started.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train.csv"</span>)</span>
<span id="cb7-2">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>NaN</td>
<td>NaN</td>
<td>Our Deeds are the Reason of this #earthquake M...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>NaN</td>
<td>NaN</td>
<td>Forest fire near La Ronge Sask. Canada</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>5</td>
<td>NaN</td>
<td>NaN</td>
<td>All residents asked to 'shelter in place' are ...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>6</td>
<td>NaN</td>
<td>NaN</td>
<td>13,000 people receive #wildfires evacuation or...</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>7</td>
<td>NaN</td>
<td>NaN</td>
<td>Just got sent this photo from Ruby #Alaska as ...</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">df.describe(include<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>7552</td>
<td>5080</td>
<td>7613</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">unique</td>
<td>221</td>
<td>3341</td>
<td>7503</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">top</td>
<td>fatalities</td>
<td>USA</td>
<td>11-Year-Old Boy Charged With Manslaughter of T...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">freq</td>
<td>45</td>
<td>104</td>
<td>10</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>]</span></code></pre></div>
</div>
</section>
<section id="tokenization" class="level2">
<h2 class="anchored" data-anchor-id="tokenization">Tokenization</h2>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset, DatasetDict</span>
<span id="cb10-2"></span>
<span id="cb10-3">ds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Dataset.from_pandas(df)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">ds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>Dataset({
    features: ['id', 'keyword', 'location', 'text', 'target', 'input'],
    num_rows: 7613
})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">model_nm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"microsoft/deberta-v3-small"</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForSequenceClassification, AutoTokenizer</span>
<span id="cb14-2"></span>
<span id="cb14-3">tokz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_nm)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> tok_func(x):</span>
<span id="cb15-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tokz(x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>])</span>
<span id="cb15-3"></span>
<span id="cb15-4"></span>
<span id="cb15-5">tok_ds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ds.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(tok_func, batched<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Parameter 'function'=&lt;function tok_func at 0x7f28da60b8b0&gt; of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fba50529948f4c4ab381839eebbba5d4","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># collapse_output</span></span>
<span id="cb17-2">row <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tok_ds[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb17-3">row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>], row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input_ids"</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>('Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',
 [1,
  581,
  65453,
  281,
  262,
  18037,
  265,
  291,
  953,
  117831,
  903,
  4924,
  17018,
  43632,
  381,
  305,
  2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">tok_ds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tok_ds.rename_columns({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"target"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"labels"</span>})</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">tok_ds</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>Dataset({
    features: ['id', 'keyword', 'location', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],
    num_rows: 7613
})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># collapse_output</span></span>
<span id="cb22-2">tok_ds[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>{'id': 1,
 'keyword': None,
 'location': None,
 'text': 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',
 'labels': 1,
 'input': 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',
 'input_ids': [1,
  581,
  65453,
  281,
  262,
  18037,
  265,
  291,
  953,
  117831,
  903,
  4924,
  17018,
  43632,
  381,
  305,
  2],
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
</section>
<section id="validation-traning-testing" class="level2">
<h2 class="anchored" data-anchor-id="validation-traning-testing">Validation, Traning, Testing</h2>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">eval_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test.csv"</span>)</span>
<span id="cb24-2">eval_df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>Just happened a terrible car crash</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>NaN</td>
<td>NaN</td>
<td>Heard about #earthquake is different cities, s...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>NaN</td>
<td>NaN</td>
<td>there is a forest fire at spot pond, geese are...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>9</td>
<td>NaN</td>
<td>NaN</td>
<td>Apocalypse lighting. #Spokane #wildfires</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>11</td>
<td>NaN</td>
<td>NaN</td>
<td>Typhoon Soudelor kills 28 in China and Taiwan</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">eval_df.describe(include<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"object"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>3237</td>
<td>2158</td>
<td>3263</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">unique</td>
<td>221</td>
<td>1602</td>
<td>3243</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">top</td>
<td>deluged</td>
<td>New York</td>
<td>11-Year-Old Boy Charged With Manslaughter of T...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">freq</td>
<td>23</td>
<td>38</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">model_dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tok_ds.train_test_split(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>, seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">34</span>)</span>
<span id="cb26-2">model_dataset</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['id', 'keyword', 'location', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 5709
    })
    test: Dataset({
        features: ['id', 'keyword', 'location', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1904
    })
})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">eval_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>]</span>
<span id="cb28-2">eval_ds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Dataset.from_pandas(eval_df).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(tok_func, batched<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4dfb22c0225740138052bbef2b6de946","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
<section id="training-models" class="level2">
<h2 class="anchored" data-anchor-id="training-models">Training Models</h2>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TrainingArguments, Trainer, DataCollatorWithPadding</span></code></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb30-2">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">data_collator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataCollatorWithPadding(tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokz)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">training_args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TrainingArguments(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test-trainer"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias']
- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">trainer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Trainer(</span>
<span id="cb35-2">    model,</span>
<span id="cb35-3">    training_args,</span>
<span id="cb35-4">    train_dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_dataset[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train"</span>],</span>
<span id="cb35-5">    eval_dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_dataset[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>],</span>
<span id="cb35-6">    data_collator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data_collator,</span>
<span id="cb35-7">    tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokz,</span>
<span id="cb35-8">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">trainer.train()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: location, text, id, input, keyword. If location, text, id, input, keyword are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 5709
  Num Epochs = 3
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed &amp; accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 2142
Saving model checkpoint to test-trainer/checkpoint-500
Configuration saved in test-trainer/checkpoint-500/config.json
Model weights saved in test-trainer/checkpoint-500/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-500/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-500/special_tokens_map.json
Saving model checkpoint to test-trainer/checkpoint-1000
Configuration saved in test-trainer/checkpoint-1000/config.json
Model weights saved in test-trainer/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-1000/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-1000/special_tokens_map.json
Saving model checkpoint to test-trainer/checkpoint-1500
Configuration saved in test-trainer/checkpoint-1500/config.json
Model weights saved in test-trainer/checkpoint-1500/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-1500/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-1500/special_tokens_map.json
Saving model checkpoint to test-trainer/checkpoint-2000
Configuration saved in test-trainer/checkpoint-2000/config.json
Model weights saved in test-trainer/checkpoint-2000/pytorch_model.bin
tokenizer config file saved in test-trainer/checkpoint-2000/tokenizer_config.json
Special tokens file saved in test-trainer/checkpoint-2000/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)

</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="2142" max="2142" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [2142/2142 03:04, Epoch 3/3]
    </div>
    
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>500</td>
<td>0.491000</td>
</tr>
<tr class="even">
<td>1000</td>
<td>0.406300</td>
</tr>
<tr class="odd">
<td>1500</td>
<td>0.323600</td>
</tr>
<tr class="even">
<td>2000</td>
<td>0.265800</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>TrainOutput(global_step=2142, training_loss=0.3674473464210717, metrics={'train_runtime': 184.9649, 'train_samples_per_second': 92.596, 'train_steps_per_second': 11.581, 'total_flos': 222000241127892.0, 'train_loss': 0.3674473464210717, 'epoch': 3.0})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trainer.predict(eval_ds).predictions.astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>)</span>
<span id="cb39-2">preds</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: location, text, id, input, keyword. If location, text, id, input, keyword are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Prediction *****
  Num examples = 3263
  Batch size = 8</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="408" max="408" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [408/408 00:05]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>array([[-2.78964901,  3.02934074],
       [-2.77013326,  3.00309706],
       [-2.74731326,  2.972296  ],
       ...,
       [-2.8556931 ,  3.08512282],
       [-2.7085278 ,  2.88177919],
       [-2.7887187 ,  3.00746083]])</code></pre>
</div>
</div>
<pre><code>1. Just happened a terrible car crash
2. Heard about #earthquake is different cities, stay safe everyone.
3. There is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all.</code></pre>
<p>The above are samples from our Test set, looks all disaster tweets which seems to have been predicted correctly. This is my first iteration in which I tried mostly editing from <a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">Jeremy’s notebook on getting started with NLP</a> in about 1 hour.</p>


</section>

 ]]></description>
  <category>kaggle</category>
  <category>fastaicourse</category>
  <category>NLP</category>
  <category>huggingface</category>
  <guid>https://kurianbenoy.com/posts/2022/2022-05-23-nlpkagglecomp.html</guid>
  <pubDate>Mon, 23 May 2022 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
