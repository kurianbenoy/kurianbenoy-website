---
title: OpenAI Whisperâ€™s amazing power to do fine-tuning demonstrated on Malayalam
subtitle: Summit 2023 @ Indian Institute of Information Technology, Kottayam (IIIT-K)
date: 2023-06-10
date-format: full
comments: false
format:
  revealjs:
    theme: solarized
    slide-number: true
    footer: "[Kurian Benoy](https://kurianbenoy.com/) || OpenAI Whisperâ€™s amazing power to do fine-tuning demonstrated on Malayalam"
---

## OpenAI Whisper

![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/OpenAI_Logo.svg/1024px-OpenAI_Logo.svg.png){width=500 fig-align="center"}

- <span style="color:red">I think Whisper^[According to [research paper](https://cdn.openai.com/papers/whisper.pdf) p.2, the name Whisper is an abbrevation for WSPR: `Web-scale Supervised Pretraining for Speech Recognition`.] is the most `under-rated model` released by OpenAI.</span>
- <span style="color:green">It was open-sourced on September 21, 2022 by releasing the inference code and pre-trained model weights.</span>

## About OpenAI Whisper Model

- Whisper is a computer program which can listen to people talking and write down what they say. <span style="color:red">(Automatic Speech Recognition Model)</span>
- Whisper can understand people speaking different languages and can even translate what they say into English. <span style="color:green">(Supports transcription and translation to English)</span>

> Note: This was generated with GPT-4 with prompt: explain what is openai whisper to a 5 year old kid?

## Malayalam is a complex language

![Comparison of Malayalam TTR with that of European Union Constitution Corpus and DoE-CIIL Corpus from K. Manohar et al.](../delft-fastai/morphology_ttr.png){width="800"}

::: aside
Picture from [Quantitative Analysis of the Morphological
Complexity of Malayalam Language by K. Manohar et al](https://link.springer.com/chapter/10.1007/978-3-030-58323-1_7). For more information check this paper.
:::

## Whisper Event

- <span style="color:red">HuggingFace Team conducted a whisper fine tuning event for 2 weeks from 5th December 2022 to 19th December 2022. The results were out on 23rd December 2022.</span>
- <span style="color:blue">The goal was to to fine-tune the Whisper model to build state-of-the-art speech recognition systems in the languages of our choice ðŸ—£ </span>

::: aside
[Whisper Event huggingface page](https://huggingface.co/whisper-event)
:::

## Malayalam models produced in Whisper Event

- <span style="color:red">For the language Malayalam, the results are as follows:</span>

![Malayalam models performance in whisper event according [to leaderboard](https://huggingface.co/spaces/whisper-event/leaderboard?dataset=mozilla-foundation%2Fcommon_voice_11_0&config=ml&split=test)](https://user-images.githubusercontent.com/24592806/222974236-44f047ec-e072-4f6a-b49f-ed88afb02999.png){width=700 fig-align="center"}

## Winning models in Malayalam in Whisper Event {.nonincremental}

- <span style="color:red">The winning model for Common voice</span>: `thennal/whisper-medium-ml`
- <span style="color:blue">The winning model for Fleurs</span>: `parambharath/whisper-small-ml`

## I was not convinced

- <span style="color:red">Didn't trust the Hugging Face way of evaluating models.</span>

![thennal/whisper-medium-ml model card readme](../fossasia2023/thennal_model_card.png)


## I was not convinced

- <span style="color:red">Didn't trust the Hugging Face way of evaluating models.</span>

![Last commit in thennal/whisper-medium-ml](../fossasia2023/thennal_commit.png)

## Objective of my benchmarking

- <span style="color:red">To test whether 10% WER was possible in available academic datasets.</span>

**Datasets**

- <span style="color:blue">Common Voice 11 malayalam subset</span>
- <span style="color:blue">SMC Malayalam Speech Corpus</span>

## Metrics for evaluating ASR models

- ASR evaulation relies on comparission between <span style="color:red">ground-truth</span> and <span style="color:red">ASR output</span>.
- <span style="color:blue">Common metrics for ASR evaluation which are popular and enough^[According to Rethinking evaluation in asr: Are our models robust enough? by Likhomanenko T, Xu, Q., Pratap etc.] are</span> :

<span style="color:green">1. Word Error Rate(WER)</span>

<span style="color:green">2. Character Error Rate(CER)</span>

::: aside
To learn more check this [blogpost by AWS](https://aws.amazon.com/blogs/machine-learning/evaluating-an-automatic-speech-recognition-service/)
:::

## I wanted to build something new

- <span style="color:red">New github project for [Malayalam ASR Benchmarking](https://github.com/kurianbenoy/malayalam_asr_benchmarking)</span>

![Time for a new adventure](../fossasia2023/adventure_talk.jpg)

## Methadology for benchmarking

1. <span style="color:red">Create as a python library so further whisper-based transformer models can be benchmark.</span>
2. <span style="color:blue">Calculate WER, CER, model size and time taken to benchmark the model for the listed datasets.</span>
3. <span style="color:green">Build a reproducible approach, so results of benchmarking is stored as dataset.</span>


## Benchmarked models

- <span style="color:red">Started with 6 fine-tuned models in Malayalam and compared it with [6 model versions released by OpenAI](https://github.com/openai/whisper).</span>

1. thennal/whisper-medium-ml
2. parambharat/whisper-tiny-ml
3. parambharat/whisper-base-ml
4. parambharat/whisper-small-ml
5. anuragshas/whisper-large-v2-ml
6. DrishtiSharma/whisper-large-v2-malayalam


## Results on benechmarking in Common Voice dataset

![Output from benchmarking tool](https://user-images.githubusercontent.com/24592806/230587218-96f1c95b-abaf-4c09-866c-0538d7105239.png)

## WER in Common Voice dataset

![Word Error Rate in Common Voice-9 test split](https://user-images.githubusercontent.com/24592806/230526272-cadd5443-5316-40e1-a356-46c993cb174d.png)

## CER in Common Voice dataset

![Character Error Rate in Common Voice-9 test split](https://user-images.githubusercontent.com/24592806/230526282-f6018629-1aa0-4c6c-9b9a-66b4f04e3355.png)

##

{{< tweet kurianbenoy2 1633647128059969536 >}}

##

{{< tweet kavya_manohar 1633755478818959372 >}}

## Results on benechmarking in Malayalam Speech Corpus dataset

![Output from benchmarking tool](https://user-images.githubusercontent.com/24592806/230657721-4e98b75b-4641-4047-8d51-5bd098b76fc8.png)

## WER in Malayalam Speech Corpus

![Word Error Rate in MSC](https://user-images.githubusercontent.com/24592806/230658615-5db73907-764f-42db-8f2c-88f1089ac1ea.png)

## CER in Malayalam Speech Corpus

![Character Error rate in MSC](https://user-images.githubusercontent.com/24592806/230658625-d3a9541c-facf-4f4c-83f8-f93ffa4c5c7a.png)

## Links to Project

<span style="color:red">Github project</span>

 - https://github.com/kurianbenoy/malayalam_asr_benchmarking

## Links to Project 

<span style="color:blue">Benchmarking results</span>

 - <span style="color:orange">Results on SMC Malayalam Speech corpus</span>
 
 https://huggingface.co/datasets/kurianbenoy/malayalam_msc_benchmarking/tree/main
 
 - <span style="color:orange">Results on Common Voice 11</span>
 
 https://huggingface.co/datasets/kurianbenoy/malayalam_common_voice_benchmarking

## Future Ideas for Benchmarking

- <span style="color:red">Something very similar to OpenLLM Leaderboard with results of latest malayalam speech models.</span>
- <span style="color:blue">Should include results for Kaldi, Meta's MMS, Wav2Vec etc.</span>

![Open LLM leaderboard in [huggingface spaces](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)](../delft-fastai/openllm.png)

## Conclusion

- <span style="color:red">In Malayalam we have achieved phenomenal results for fine tuned whisper models.
- <span style="color:blue">The best model is: `thennal/whisper-medium-ml`
- <span style="color:green">I think their seems to be a good ASR model suitable for production use-cases.</span>
- <span style="color:orange">You can also do it in your own language especially if it is a low resource language.</span>

## Thanks to

:::: {.columns}
::: {.column width="70%"}
1. [OpenAI team](https://openai.com/) - Alec Radford, [Jong Wook Kim](https://github.com/jongwook), [Christine McLeavey](https://www.linkedin.com/in/mcleavey) etc. other authors of [Whisper paper](https://cdn.openai.com/papers/whisper.pdf)
2. [HuggingFace team](https://huggingface.co/) - [Sanchit Gandhi](https://huggingface.co/sanchit-gandhi), [Nicolas Patry](https://huggingface.co/Narsil), [Vaibhav Srivastav](https://github.com/Vaibhavs10) etc.
3. [Kavya Manohar](https://kavyamanohar.com/)
4. [Santhosh Thottingal](https://thottingal.in/)
:::

::: {.column width="30%"}
5. [Thennal D K](https://huggingface.co/thennal)
6. Other members in [Swathanthra Malayalam Computing community](https://smc.org.in/).
7. [Jarvis Labs](cloud.jarvislabs.ai/)
:::
::::
