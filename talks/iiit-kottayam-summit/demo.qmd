---
title: Vegam Whisper Family of Models and demoing Malayalam Speech to Text
subtitle: Summit 2023 @ Indian Institute of Information Technology, Kottayam (IIIT-K)
date: 2023-06-10
date-format: full
comments: false
format:
  revealjs:
    theme: solarized
    slide-number: true
    footer: "[Kurian Benoy](https://kurianbenoy.com/) || Vegam Whisper Family of Models and demoing Malayalam Speech to Text"
---

## Inspired by

::: {.incremental}
- <span style="color:red">[faster-whisper](https://github.com/guillaumekln/faster-whisper) is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models.</span>
- <span style="color:blue">This implementation is up to 4 times faster than openai/whisper for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.</span>
:::

::: aside
<span style="color:blue">Information from [faster-whisper github README](https://github.com/guillaumekln/faster-whisper)</span>
:::

## CTranslate2

- <span style="color:red">An awesome library for optimizing ML models for production.</span>
- CTranslate2 is a C++ and Python library for efficient inference with Transformer models.
- The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU. 


## CTranslate2 Whisper converter

- <span style="color:red">It had this utility for converting any `whisper` based model to faster-whisper like models.</span>

```shell
ct2-transformers-converter \
 --model openai/whisper-tiny \
 --output_dir whisper-tiny-ct2
```

## CTranslate2 Quantization formats

<span style="color:red">CTranslate2 supports various quantization formats like:</span>

- float16
- int16
- float8
- int8_float8
- No quantization

::: aside
For more details check [CTranslate2 quantization docs](https://opennmt.net/CTranslate2/quantization.html)
:::

## Vegam Whisper models released

- <span style="color:red">I used `thennal/whisper-medium-ml` to convert it to faster-whisper based models for Malayalam:</span>

1. [kurianbenoy/vegam-whisper-medium-ml](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml)
2. [kurianbenoy/vegam-whisper-medium-ml-fp16](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-fp16)
3. [kurianbenoy/vegam-whisper-medium-ml-int16](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-int16)
4. [kurianbenoy/vegam-whisper-medium-ml-fp8](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-fp8)
5. [kurianbenoy/vegam-whisper-medium-ml-int8_float8](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-int8_float8)

## Vegam Whisper models released

![Vegam Whisper models hosted in huggingface](./huggingface.png)

## Demo Video -1 

{{< video https://www.youtube.com/embed/zm1gU8hRHxA width="2000" height="600"  >}}

## Demo Video -1 Output

![Output of video 1](./25s_audio.png)

## Demo Video -2

{{< video https://www.youtube.com/embed/fZZFCOkWquY width="2000" height="600" >}}

## Demo Video - 2 Output

![Output of video 2](./10s_audio.png)

## Pallakku

- <span style="color:red">Pallakku is a Malayalam speech to text demo leveraging the model-weights of vegam-whisper-medium-ml.</span>
- <span style="color:blue">Two options to try it out</span>:

1. [ðŸ¤— spaces](https://huggingface.co/spaces/kurianbenoy/Pallakku)
2. GPU-based microservice (coming soon.)

## ðŸ¤— spaces

- Try it out in link: 

<span style="color:red">https://huggingface.co/spaces/kurianbenoy/Pallakku</span>

![](../delft-fastai/pallakku.png)

