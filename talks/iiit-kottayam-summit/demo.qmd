---
title: Vegam Whisper Family of Models and demoing Malayalam Speech to Text
subtitle: Summit 2023 @ Indian Institute of Information Technology, Kottayam (IIIT-K)
date: 2023-06-10
date-format: full
comments: false
format:
  revealjs:
    theme: solarized
    slide-number: true
    footer: "[Kurian Benoy](https://kurianbenoy.com/) || Vegam Whisper Family of Models and demoing Malayalam Speech to Text"
---

## Inspired by

::: {.incremental}
- <span style="color:red">[faster-whisper](https://github.com/guillaumekln/faster-whisper) is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models.</span>
- <span style="color:blue">This implementation is up to 4 times faster than openai/whisper for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.</span>
:::

::: aside
<span style="color:blue">Information from [faster-whisper github README](https://github.com/guillaumekln/faster-whisper)</span>
:::

## CTranslate2

- An awesome library for optimizing ML models for production.
- Supports translation models like Opus MT, OpenNMT
- Supports huggingface transformers based packages like GPTJ, BLOOM, Whisper etc.

## CTranslate2 Whisper converter

- <span style="color:red">It had this utility for converting any `whisper` based model to faster-whisper like models.</span>

```shell
ct2-transformers-converter \
 --model openai/whisper-tiny \
 --output_dir whisper-tiny-ct2
```

<!-- ## Malayalam ASR Benchmarking

- <span style="color:red">To test whether 10% WER was possible in available academic datasets.</span>

**Datasets**

- <span style="color:blue">Common Voice 11 malayalam subset</span>
- <span style="color:blue">SMC Malayalam Speech Corpus</span>

## Results on benechmarking in Common Voice dataset

![Output from benchmarking tool](https://user-images.githubusercontent.com/24592806/230587218-96f1c95b-abaf-4c09-866c-0538d7105239.png)

##

{{< tweet kavya_manohar 1633755478818959372 >}}

## Results on benechmarking in Malayalam Speech Corpus dataset

![Output from benchmarking tool](https://user-images.githubusercontent.com/24592806/230657721-4e98b75b-4641-4047-8d51-5bd098b76fc8.png) -->

## CTranslate2 Quantization formats

CTranslate2 supports various quantization formats like:

- float16
- int16
- float8
- int8_float8
- No quantization

::: aside
For more details check CTranslate2 quantization page
:::

## Vegam Whisper models released

- <span style="color:red">I used `thennal/whisper-medium-ml` to convert it to faster-whisper based models for Malayalam:</span>

1. [kurianbenoy/vegam-whisper-medium-ml](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml)
2. [kurianbenoy/vegam-whisper-medium-ml-fp16](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-fp16)
3. [kurianbenoy/vegam-whisper-medium-ml-int16](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-int16)
4.[kurianbenoy/vegam-whisper-medium-ml-fp8](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-fp8)
5. [kurianbenoy/vegam-whisper-medium-ml-int8_float8](https://huggingface.co/kurianbenoy/vegam-whisper-medium-ml-int8_float8)

## Vegam Whisper models released

[Vegam Whisper models hosted in huggingface](./huggingface.png)

## Demo Video -1 

{{video }}

## Demo Video -1 Output

[Output of video 1](./25s_audio.png)

## Demo Video -2

{{video }}

## Demo Video - 2 Output

[Output of video 2](./10s_audio.png)

## Pallakku

- <span style="color:red">Pallakku is a Malayalam speech to text demo leveraging the model-weights of vegam-whisper-medium-ml.</span>
- Now hosted as:

1. [ðŸ¤— spaces](https://huggingface.co/spaces/kurianbenoy/Pallakku)
2. GPU-based microservice (coming soon.)

## ðŸ¤— spaces

- Try it out in link: <span style="color:red">https://huggingface.co/spaces/kurianbenoy/Pallakku</span>

![](../delft-fastai/pallakku.png)

