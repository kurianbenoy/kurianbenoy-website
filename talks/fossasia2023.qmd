---
title: OpenAI Whisper and it's amazing power to do finetuning.
author: Kurian Benoy
subtitle: FOSSASIA Summit, Singapore
date: 2023-04-15
date-format: full
comments: false
format:
  revealjs:
    footer: "You can access slides @ [kurianbenoy.com/talks/fossasia2023.html](https://kurianbenoy.com/talks/fossasia2023.html)"
    slide-number: true
---

## Outline

- OpenAI Whisper and it's awesome features
- Fine-tuning and how to fine-tune Whisper?
- Results on fine-tuning whisper in Malayalam
- Conclusion

::: {.notes}
Originial Idea
- OpenAI Whisper(under appreciated model) - 1littecoder video
- Why it's awesome(whisper.cpp, long form transcription, lot of languages, whisper_normalizer)
- What is fine tuning? (Jeremy way of explaining)
- Fine tuning whisper in my language
- Results on fine tuning
- You can also achieve SOTA in your language
:::

## $whoami

- AI Engineer & Team Lead @ Sentient.io
- Volunteer @ Swathanthra Malayalam Computing(SMC)
- Open-source enthusiast
- Not affiliated to OpenAI

## OpenAI Whisper

![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/OpenAI_Logo.svg/1024px-OpenAI_Logo.svg.png){width=500 fig-align="center"}

- Whisper is the most `under-rated models` released by OpenAI.
- It open-sourced on September 21, 2022 by releasing the inference code and pre-trained model weights.

::: aside
According to [research paper](https://cdn.openai.com/papers/whisper.pdf) p.2, the name Whisper is an abbrevation for WSPR:

`Web-scale Supervised Pretraining for Speech Recognition`.
:::

## About OpenAI Whisper Model

- Whisper is a computer program which can listen to people talking and write down what they say.
- Whisper can understand people speaking different languages and can even translate what they say into English.

::: {.notes}
Last 2 points are generated by BingGPT.

- The model is robust general purpose speech recognition system aka ASR.
- It is trained on large dataset of 680,000 hours of audio recordings

Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.

A Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.
:::

## Whisper Models {.scrollable}


|  Size  | Parameters |Required VRAM | Relative speed |
|------:|----------:|:----------:|:------------:|
|  tiny  |    39 M    |     ~1 GB    |      ~32x      |
|  base  |    74 M    |     ~1 GB    |      ~16x      |
| small  |   244 M    |    ~2 GB     |      ~6x       |
| medium |   769 M    |    ~5 GB     |      ~2x       |
| large  |   1550 M   |   ~10 GB     |       1x       |


::: {.notes}
Below are the names of the available models and their approximate memory requirements and relative speed. Large itself has two version: large-v1 and large-v2.

The `.en` models for English-only applications tend to perform better, especially for the `tiny.en` and `base.en` models. We observed that the difference becomes less significant for the `small.en` and `medium.en` models.
:::

## English Speech Recognition

![Whisper is competitive with state of art commercial and open source systems. Diagram from [whisper research paper]([research paper](https://cdn.openai.com/papers/whisper.pdf)) p.9](fossasia2023/Whisper_english.png)

::: {.notes}
A list of ideas for how to use Whisper in your own applications.
- English Speech Recognition
- Multi-lingual speech recognition
- Support for multiple tasks
- Can run in almost any devices with whisper.cpp
- Awesome community plugins
:::

## Multi-lingual Speech recognition

- Whisper model is trained on 99 languages
- OpenAI Whisper API supports just 57 languages as some languages performance are not really good.

::: aside
- More details can be found in Section 3.4 of [Whisper research paper](https://cdn.openai.com/papers/whisper.pdf) pp.6 - 8.
- Zero-shot Whisper improves performance on Multilingual LibriSpeech(MLS) but is still significantly behind both Maestro, XLS-R, and mSLAM on VoxPopuli. ([Whisper research paper](https://cdn.openai.com/papers/whisper.pdf) p.7)
:::

::: {.notes}
- Room for fine-tuning models to improve
Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Maori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh.
:::

## Runs in almost any device

- Since Whisper followed the open source route, [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
developed by [Georgi Gerganov](https://github.com/ggerganov) which is a port of Port of OpenAI's 
Whisper model in C/C++.

- It supports the below platforms:

1. Mac OS (Intel and ARM)
2. iOS
3. Android
4. Linux/Free BSD
5. Web Assembly etc.

## Awesome community plugins

- Word-level time stamps with [whisper-timestamped](https://github.com/linto-ai/whisper-timestamped),[whisperX](https://github.com/m-bain/whisperX)
- Fine-Tune Whisper is achieving SOTA in lot of languages
- [Speaker diarization](https://huggingface.co/spaces/dwarkesh/whisper-speaker-recognition)
- [Audio classification using OpenAIâ€™s Whisper](https://github.com/jumon/zac)

::: aside
[Thanks to Ramsri Goutham article on 7 must know libraries and addons on Whisper](https://ramsrigoutham.medium.com/openais-whisper-7-must-know-libraries-and-add-ons-built-on-top-of-it-10825bd08f76)
:::

## What is fine tuning?

Given a pre-trained model, which is a large model which is trained
on a very specific task. If we want to fit it into our specific dataset we will train
and use the pre-trained model to build a new model which works very well for our task.

![Steps in finetuning a text classifier model (picture from fast.ai course lesson)](https://raw.githubusercontent.com/fastai/fastbook/823b69e00aa1e1c1a45fe88bd346f11e8f89c1ff/images/att_00027.png){width=300 fig-align="center"}

## Fine tuning is still relevant

{{< tweet waydegilliam 1641228571611123712 >}}

## Why try fine-tuning in Whisper?

- In your problem, the open source Whisper model doesn't give good results.

::: {.notes}
Whisper is developed as a robust speech recognition system which is
intented to work in out of distribution dataset. While most of previous
approaches relied on training in a few open-source dataset and using them.

If we are working on a language/dataset domain where the out-of distribution
Whisper model doesn't give good result we can use whisper to get good
results.
:::

## What are steps for fine-tuning Whisper?

![[Fine-Tune Whisper For Multilingual ASR with ðŸ¤— Transformers](https://huggingface.co/blog/fine-tune-whisper)](fossasia2023/blogpost_image.png){width=700 fig-align="center"}

## What are steps for fine-tuning Whisper?

1. Preparing Environment
2. Load dataset
3. Prepare Feature Extractor, Tokenizer and Data
4. Training and evaluation
5. Building a demo(optional)

::: aside
- Based on article [Fine-Tune Whisper For Multilingual ASR with ðŸ¤— Transformers](https://huggingface.co/blog/fine-tune-whisper)
- [More details on fine tuning Whisper](https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event)
:::

## Whisper Event

- HuggingFace Team conducted a whisper fine tuning event for 2 weeks from Decemeber 5th to December 9th.
- The goal was to to fine-tune the Whisper model to build state-of-the-art speech recognition systems in the languages of our choice ðŸ—£

## Malayalam Speech Recognition models in Whisper Event

- For the language Malayalam, the results are as follows in Common Voice dataset subsection of Malayalam:

![Malayalam models performance in whisper event according [to leaderboard](https://huggingface.co/spaces/whisper-event/leaderboard?dataset=mozilla-foundation%2Fcommon_voice_11_0&config=ml&split=test)](https://user-images.githubusercontent.com/24592806/222974236-44f047ec-e072-4f6a-b49f-ed88afb02999.png)

## Winning models in Malayalam in Whisper Event

- The winning model was thennal/whisper-medium-ml in Common Voice dataset subsection of Malayalam testt split.

::: {.notes}
- I was sceptical about the results of the event
- The 10% WER was breath taking. In Malayalam there is not even a single yard stick to
compare.
- Most of evaluation in properietary datasets are not open source. So can't validate results
:::
## Tools for benchmarkings

- https://github.com/kurianbenoy/malayalam_asr_benchmarking

::: {.notes}
In Malayalam, the winners were:

- CommonVoice 11.0 - thennal/whisper-medium-ml
- Fleurs - parambharath/whisper-small-ml
:::

## Fine tuning whisper in Malayalam

The base-whisper model was trained on Malayalam:

- but just half an hour dataset was used to train the model

::: {.notes}
Thanks to Whisper event.
:::

## Results on benechmarking in Common Voice dataset

![Output from benchmarking tool](https://user-images.githubusercontent.com/24592806/230587218-96f1c95b-abaf-4c09-866c-0538d7105239.png)

## Results in Common Voice dataset

![WER in Common Voice-9 test split](https://user-images.githubusercontent.com/24592806/230526272-cadd5443-5316-40e1-a356-46c993cb174d.png)

::: {.notes}
Thennal model got the best results:

11.560000 WER, then rest of models got 21-40+ models. 
:::

## CER in Common Voice dataset

![CER in Common Voice-9 test split](https://user-images.githubusercontent.com/24592806/230526282-f6018629-1aa0-4c6c-9b9a-66b4f04e3355.png)

## Results on benechmarking in Malayalam Speech Corpus dataset

![Output from benchmarking tool](https://user-images.githubusercontent.com/24592806/230657721-4e98b75b-4641-4047-8d51-5bd098b76fc8.png)

## Results in Malayalam Speech Corpus dataset

![WER in MSC](https://user-images.githubusercontent.com/24592806/230658615-5db73907-764f-42db-8f2c-88f1089ac1ea.png)

::: {.notes}
Thennal model got the best results:

11.560000 WER, then rest of models got 21-40+ models. 
:::

## CER in Malayalam Speech Corpus

![Character Error rate in MSC](https://user-images.githubusercontent.com/24592806/230658625-d3a9541c-facf-4f4c-83f8-f93ffa4c5c7a.png)

::: {.notes}
in WER Malayalam CommonVoice9 dataset:

tiny - 102.7
base - 122.9
small - 104.8
medium - 137.8
large - 107.1
largev2 - 103.2
:::

## Conclusion


According to whisper in future work section:

**Studying fine-tuning **

>In this work, we have focused on
the robustness properties of speech processing systems and
as a result only studied the zero-shot transfer performance
of Whisper. While this is a crucial setting to study due to it
being representative of general reliability, for many domains
where high-quality supervised speech data does exist, it is
likely that results can be improved further by fine-tuning.
An additional benefit of studying fine-tuning is that it allows
for direct comparisons with prior work since it is a much
more common evaluation setting.

::: {.notes}
You maybe able to achieve SOTA in your own language with Whisper
:::

## Thanks to

1. [OpenAI team](https://openai.com/)
2. [HuggingFace](https://huggingface.co/)
3. Alec Radford, [Jong Wook Kim](https://github.com/jongwook), [Christine McLeavey](https://www.linkedin.com/in/mcleavey) etc. other authors of [Whisper paper](https://cdn.openai.com/papers/whisper.pdf)
4. [AbdulMajedRaja RS](https://www.youtube.com/@1littlecoder)
5. [Georgi Gerganov](https://github.com/ggerganov)
6. [Ramsri Goutham](https://ramsri.ai/)


## Tributes to Areeb Jamal

![Source: [Areeb Jamal Forever in our Hearts and our Memory](https://blog.fossasia.org/areeb-jamal-forever-in-our-hearts-and-our-memory/) - FOSSASIA blog](https://i0.wp.com/blog.fossasia.org/wp-content/uploads/2021/04/lastslide.png?w=1920&ssl=1)
